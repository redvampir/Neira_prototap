"""
Neira Code Cell v0.5 ‚Äî –ì–∏–±—Ä–∏–¥–Ω–∞—è —Ä–∞–±–æ—Ç–∞ —Å –∫–æ–¥–æ–º
–ü–æ–∑–≤–æ–ª—è–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ—â—å –æ–±–ª–∞–∫–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏, —Å–æ—Ö—Ä–∞–Ω—è—è –ª–æ–∫–∞–ª—å–Ω—É—é –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç—å.

–ê–†–•–ò–¢–ï–ö–¢–£–†–ê:
1. –ü–æ–ø—ã—Ç–∫–∞ Cloud (Qwen-480B/GPT-4 —É—Ä–æ–≤–µ–Ω—å)
2. Fallback –Ω–∞ Local (Qwen-7B) –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ —Å–µ—Ç–∏
"""

from logging import info
import os
import subprocess
import json
import requests
from typing import Optional, List, Dict, Any, Tuple
from dataclasses import dataclass
from datetime import datetime

def _env_int(name: str, default: int, min_value: int = 1, max_value: Optional[int] = None) -> int:
    raw = os.getenv(name)
    if raw is None:
        return default
    try:
        value = int(raw.strip())
    except ValueError:
        return default
    if value < min_value:
        return min_value
    if max_value is not None and value > max_value:
        return max_value
    return value


def _env_bool(name: str, default: bool = False) -> bool:
    raw = os.getenv(name)
    if raw is None:
        return default
    value = raw.strip().lower()
    if value in {"1", "true", "yes", "y", "on"}:
        return True
    if value in {"0", "false", "no", "n", "off"}:
        return False
    return default


def _merge_system_prompt(base_prompt: str, layer_prompt: Optional[str]) -> str:
    if not layer_prompt:
        return base_prompt
    if not base_prompt:
        return layer_prompt
    return f"{base_prompt}\n\n[–°–ª–æ–π –º–æ–¥–µ–ª–∏]\n{layer_prompt}"


try:
    from model_layers import ModelLayersRegistry

    _MODEL_LAYERS = ModelLayersRegistry("model_layers.json")
except Exception:
    _MODEL_LAYERS = None

try:
    from neira.core.llm_adapter import LLMClient, LLMResult, NullLLMClient, build_default_llm_client
    LLM_CLIENT_AVAILABLE = True
except ImportError:
    LLM_CLIENT_AVAILABLE = False

_CODE_LLM_CLIENT: Optional[LLMClient] = None


def _get_code_client() -> Optional[LLMClient]:
    global _CODE_LLM_CLIENT
    if not LLM_CLIENT_AVAILABLE:
        return None
    if _CODE_LLM_CLIENT is None:
        client = build_default_llm_client()
        if isinstance(client, NullLLMClient):
            return None
        _CODE_LLM_CLIENT = client
    return _CODE_LLM_CLIENT

# –ü—Ä–æ–±—É–µ–º –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∏–∑ –Ω–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏ (cells_v3), –∏–Ω–∞—á–µ –∏–∑ —Å—Ç–∞—Ä–æ–π (cells)
try:
    from cells_v3 import Cell, CellResult, MemoryCell, OLLAMA_URL, MODEL_CODE as LOCAL_MODEL, TIMEOUT # type: ignore
except ImportError:
    # Fallback –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    from cells import Cell, CellResult, MemoryCell, OLLAMA_URL
    # –ï—Å–ª–∏ MODEL_CODE –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –≤ cells, –∑–∞–¥–∞–µ–º –≤—Ä—É—á–Ω—É—é
    try:
        from cells import MODEL_CODE as LOCAL_MODEL
    except ImportError:
        LOCAL_MODEL = "qwen2.5-coder:7b"
    TIMEOUT = 120

DEFAULT_MAX_RESPONSE_TOKENS = _env_int("NEIRA_MAX_RESPONSE_TOKENS", 2048, min_value=128)
CODE_MAX_TOKENS = _env_int("NEIRA_CODE_MAX_TOKENS", DEFAULT_MAX_RESPONSE_TOKENS, min_value=128)
OLLAMA_NUM_CTX = _env_int("NEIRA_OLLAMA_NUM_CTX", 0, min_value=0)
OLLAMA_DISABLED = _env_bool("NEIRA_DISABLE_OLLAMA", False)

# === –ù–ê–°–¢–†–û–ô–ö–ò –û–ë–õ–ê–ö–ê ===
# –í–ù–ò–ú–ê–ù–ò–ï: Ollama —Ä–∞–±–æ—Ç–∞–µ—Ç –¢–û–õ–¨–ö–û –ª–æ–∫–∞–ª—å–Ω–æ (localhost:11434)
# –ù–µ—Ç –ø—É–±–ª–∏—á–Ω–æ–≥–æ –æ–±–ª–∞–∫–∞ api.ollama.ai ‚Äî —ç—Ç–æ –±—ã–ª –±–∞–≥
CLOUD_ENABLED = False  # –û—Ç–∫–ª—é—á–µ–Ω–æ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å

# –î–ª—è –æ–±–ª–∞—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –º–æ–∂–Ω–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å OpenRouter, Together.ai, Groq –∏ —Ç.–¥.
# –ü–æ–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –ª–æ–∫–∞–ª—å–Ω—ã–π Ollama
CLOUD_API_URL = ""  # –ó–∞–≥–ª—É—à–∫–∞ ‚Äî –æ–±–ª–∞–∫–æ –æ—Ç–∫–ª—é—á–µ–Ω–æ
CLOUD_API_KEY = os.getenv("OLLAMA_API_KEY", "")  # –ü—É—Å—Ç–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

# –õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –∫–æ–¥–∞
CLOUD_MODEL = LOCAL_MODEL  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å

# === –õ–û–ö–ê–õ–¨–ù–´–ï –ù–ê–°–¢–†–û–ô–ö–ò ===
ALLOWED_EXTENSIONS = [".py", ".json", ".txt", ".md", ".yaml", ".yml", ".toml"]
BACKUP_DIR = "backups"
MAX_FILE_SIZE = 100_000


@dataclass
class FileInfo:
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–∞–π–ª–µ"""
    path: str
    exists: bool
    size: int = 0
    extension: str = ""
    content: str = ""


class CodeCell(Cell): # pyright: ignore[reportGeneralTypeIssues]
    """–ö–ª–µ—Ç–∫–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∫–æ–¥–æ–º (–ì–∏–±—Ä–∏–¥–Ω–∞—è)"""
    
    name = "code"
    system_prompt = """–¢—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π Python-—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫. 
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø–∏—Å–∞—Ç—å —Ä–∞–±–æ—Ç–∞—é—â–∏–π, —á–∏—Å—Ç—ã–π –∏ –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –∫–æ–¥.
–í—Å–µ–≥–¥–∞ —Å–ª–µ–¥—É–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º PEP8. –ö–æ–º–º–µ–Ω—Ç–∏—Ä—É–π –Ω–µ–æ—á–µ–≤–∏–¥–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è."""
    
    def __init__(self, memory: Optional[MemoryCell] = None, work_dir: str = "."):
        super().__init__(memory)
        self.work_dir = os.path.abspath(work_dir)
        os.makedirs(BACKUP_DIR, exist_ok=True)
    
    def _call_cloud_api(self, messages: List[Dict]) -> str:
        """–í—ã–∑–æ–≤ –æ–±–ª–∞—á–Ω–æ–≥–æ API (OpenAI compatible)"""
        if not CLOUD_ENABLED or not CLOUD_API_KEY or "sk-..." in CLOUD_API_KEY:
            raise ValueError("–û–±–ª–∞–∫–æ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ (–ø—Ä–æ–≤–µ—Ä—å CLOUD_API_KEY –≤ code_cell.py)")

        headers = {
            "Authorization": f"Bearer {CLOUD_API_KEY}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": CLOUD_MODEL,
            "messages": messages,
            "temperature": 0.2, # –î–ª—è –∫–æ–¥–∞ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –Ω–∏–∂–µ
            "max_tokens": CODE_MAX_TOKENS
        }
        
        # –í–Ω–∏–º–∞–Ω–∏–µ: —Ç–∞–π–º–∞—É—Ç –¥–ª—è –æ–±–ª–∞–∫–∞ –±–æ–ª—å—à–µ, —Ç–∞–∫ –∫–∞–∫ –±–æ–ª—å—à–∏–µ –º–æ–¥–µ–ª–∏ –¥—É–º–∞—é—Ç –¥–æ–ª—å—à–µ
        response = requests.post(CLOUD_API_URL, headers=headers, json=payload, timeout=120)
        response.raise_for_status()
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –æ—Ç–≤–µ—Ç–∞ (–Ω–∞ —Å–ª—É—á–∞–π —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö API)
        data = response.json()
        if 'choices' in data and len(data['choices']) > 0:
             return data['choices'][0]['message']['content']
        else:
             raise ValueError(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç API: {data}")

    def _hybrid_generate(self, prompt: str, system: str = None) -> Tuple[str, str]: # pyright: ignore[reportArgumentType]
        """
        –ü—ã—Ç–∞–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–æ–∫–∞–ª—å–Ω—É—é Ollama —Å graceful degradation.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: (content, source_model_name)
        """
        base_system = system or self.system_prompt
        layer_prompt = _MODEL_LAYERS.get_active_prompt(LOCAL_MODEL) if _MODEL_LAYERS else None
        system_prompt = _merge_system_prompt(base_system, layer_prompt)

        client = _get_code_client()
        if client:
            try:
                response: LLMResult = client.generate(
                    prompt=prompt,
                    system_prompt=system_prompt,
                    temperature=0.2,
                    max_tokens=CODE_MAX_TOKENS
                )
                if response.success and response.content:
                    provider = response.provider or "unknown"
                    model = response.model or "default"
                    return response.content, f"{provider}:{model}"
            except (RuntimeError, ValueError, TypeError, OSError):
                pass

        if OLLAMA_DISABLED:
            return self._offline_response(prompt, "ollama_disabled"), "OFFLINE"

        # –û–±–ª–∞–∫–æ –æ—Ç–∫–ª—é—á–µ–Ω–æ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
        try:
            ollama_url = os.getenv("OLLAMA_URL", "http://localhost:11434/api/generate")
            options: Dict[str, Any] = {"temperature": 0.2, "num_predict": CODE_MAX_TOKENS}
            if OLLAMA_NUM_CTX:
                options["num_ctx"] = OLLAMA_NUM_CTX
            if _MODEL_LAYERS is not None:
                adapter = _MODEL_LAYERS.get_active_adapter(LOCAL_MODEL)
                if adapter:
                    options["adapter"] = adapter
            payload = {
                "model": LOCAL_MODEL,
                "prompt": f"{system_prompt}\n\n{prompt}",
                "stream": False,
                "options": options
            }
            response = requests.post(ollama_url, json=payload, timeout=TIMEOUT)
            if response.status_code != 200:
                raise Exception(f"–û—à–∏–±–∫–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏: {response.text}")
            content = response.json().get("response", "")
            return content, "LOCAL:" + LOCAL_MODEL
            
        except requests.exceptions.Timeout:
            return self._offline_response(prompt, "timeout"), "OFFLINE"
            
        except requests.exceptions.ConnectionError:
            return self._offline_response(prompt, "offline"), "OFFLINE"
            
        except Exception as e:
            return self._offline_response(prompt, f"error: {e}"), "OFFLINE"
    
    def _offline_response(self, prompt: str, reason: str) -> str:
        """–û—Ç–≤–µ—Ç –∫–æ–≥–¥–∞ Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞"""
        if reason == "ollama_disabled":
            return (
                "*[–ê–≤—Ç–æ–Ω–æ–º–Ω—ã–π —Ä–µ–∂–∏–º ‚Äî ollama_disabled]*\n\n"
                "Ollama –æ—Ç–∫–ª—é—á–µ–Ω–∞ —á–µ—Ä–µ–∑ NEIRA_DISABLE_OLLAMA. "
                "–ù–∞—Å—Ç—Ä–æ–π –¥—Ä—É–≥–æ–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä (LM Studio/llama.cpp/–æ–±–ª–∞–∫–æ) –∏ –ø–æ–≤—Ç–æ—Ä–∏ –∫–æ–º–∞–Ω–¥—É."
            )
        return (
            f"*[–ê–≤—Ç–æ–Ω–æ–º–Ω—ã–π —Ä–µ–∂–∏–º ‚Äî {reason}]*\n\n"
            f"–ù–µ –º–æ–≥—É –≤—ã–ø–æ–ª–Ω–∏—Ç—å –æ–ø–µ—Ä–∞—Ü–∏—é —Å –∫–æ–¥–æ–º ‚Äî Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.\n"
            f"–ó–∞–ø—É—Å—Ç–∏ `ollama serve` –∏ –ø–æ–≤—Ç–æ—Ä–∏ –∫–æ–º–∞–Ω–¥—É."
        )

    def _safe_path(self, path: str) -> str:
        full_path = os.path.abspath(os.path.join(self.work_dir, path))
        if not full_path.startswith(self.work_dir):
            raise ValueError(f"Path traversal attempt: {path}")
        return full_path
    
    def _check_extension(self, path: str) -> bool:
        return os.path.splitext(path)[1].lower() in ALLOWED_EXTENSIONS
    
    def read_file(self, path: str) -> FileInfo:
        try:
            full_path = self._safe_path(path)
            if not os.path.exists(full_path):
                return FileInfo(path=path, exists=False)
            
            size = os.path.getsize(full_path)
            if size > MAX_FILE_SIZE:
                return FileInfo(path=path, exists=True, size=size, content=f"[TOO LARGE: {size} bytes]")
            
            with open(full_path, "r", encoding="utf-8") as f:
                content = f.read()
            return FileInfo(path=path, exists=True, size=size, extension=os.path.splitext(path)[1], content=content)
        except Exception as e:
            return FileInfo(path=path, exists=False, content=f"Error: {e}")
    
    def write_file(self, path: str, content: str, backup: bool = True) -> bool:
        try:
            full_path = self._safe_path(path)
            if not self._check_extension(path):
                print(f"‚ùå –ó–∞–ø—Ä–µ—â–µ–Ω–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ: {path}")
                return False
            
            if backup and os.path.exists(full_path):
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                backup_path = os.path.join(BACKUP_DIR, f"{timestamp}_{os.path.basename(path)}")
                with open(full_path, "r", encoding="utf-8") as src, open(backup_path, "w", encoding="utf-8") as dst:
                    dst.write(src.read())
                print(f"üì¶ –ë—ç–∫–∞–ø —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {backup_path}")
            
            os.makedirs(os.path.dirname(full_path), exist_ok=True)
            with open(full_path, "w", encoding="utf-8") as f:
                f.write(content)
            print(f"‚úÖ –§–∞–π–ª –∑–∞–ø–∏—Å–∞–Ω: {path}")
            return True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏: {e}")
            return False
    
    def list_files(self, directory: str = ".") -> List[str]:
        try:
            full_path = self._safe_path(directory)
            return [f for f in os.listdir(full_path) 
                    if os.path.isfile(os.path.join(full_path, f)) and self._check_extension(f)]
        except Exception:
            return []

    def _extract_code(self, text: str) -> str:
        """–£–º–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–¥–∞ –∏–∑ Markdown"""
        if "```" not in text:
            return text
        
        # –ò—â–µ–º –±–ª–æ–∫–∏ –∫–æ–¥–∞
        lines = text.split('\n')
        code_lines = []
        in_block = False
        
        for line in lines:
            if line.strip().startswith("```"):
                in_block = not in_block
                continue
            if in_block:
                code_lines.append(line)
        
        return '\n'.join(code_lines) if code_lines else text

    def generate_code(self, task: str, language: str = "python") -> CellResult:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞ (–ì–∏–±—Ä–∏–¥–Ω–∞—è)"""
        prompt = f"–ù–∞–ø–∏—à–∏ –∫–æ–¥ –Ω–∞ {language} –¥–ª—è –∑–∞–¥–∞—á–∏:\n{task}\n\n–¢–æ–ª—å–∫–æ –∫–æ–¥, –±–µ–∑ –ª–∏—à–Ω–∏—Ö —Å–ª–æ–≤."
        
        content, source = self._hybrid_generate(prompt)
        code = self._extract_code(content)
        
        return CellResult(
            content=code,
            confidence=0.9 if "CLOUD" in source else 0.6,
            cell_name=self.name,
            metadata={"source": source, "language": language}
        )
    
    def analyze_code(self, code: str, language: str = "python") -> CellResult:
        """–ê–Ω–∞–ª–∏–∑ –∫–æ–¥–∞ (–ì–∏–±—Ä–∏–¥–Ω—ã–π)"""
        prompt = f"–ü—Ä–æ–≤–µ–¥–∏ —Ä–µ–≤—å—é —ç—Ç–æ–≥–æ –∫–æ–¥–∞ –Ω–∞ {language}:\n\n{code}\n\n–ò—â–∏ –æ—à–∏–±–∫–∏, —É—è–∑–≤–∏–º–æ—Å—Ç–∏ –∏ –ø–ª–æ—Ö–æ–π —Å—Ç–∏–ª—å."
        content, source = self._hybrid_generate(prompt, system="–¢—ã —Å—Ç—Ä–æ–≥–∏–π Senior Developer. –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞: –û–®–ò–ë–ö–ò, –°–¢–ò–õ–¨, –£–õ–£–ß–®–ï–ù–ò–Ø, –û–¶–ï–ù–ö–ê (1-10).")
        
        return CellResult(
            content=content,
            confidence=0.9 if "CLOUD" in source else 0.6,
            cell_name=self.name,
            metadata={"source": source}
        )

    def modify_code(self, file_path: str, instruction: str) -> CellResult:
        """–ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è —Ñ–∞–π–ª–∞ (–ì–∏–±—Ä–∏–¥–Ω–∞—è)"""
        info = self.read_file(file_path)
        if not info.exists:
            return CellResult(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}", 0.0, self.name)
        
        prompt = f"""–§–∞–π–ª: {file_path}\n–°–æ–¥–µ—Ä–∂–∏–º–æ–µ:\n{info.content}\n\n–ó–∞–¥–∞—á–∞: {instruction}

–í–µ—Ä–Ω–∏ –ü–û–õ–ù–´–ô –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –∫–æ–¥ —Ñ–∞–π–ª–∞. –ù–µ —Å–æ–∫—Ä–∞—â–∞–π –∫–æ–¥, –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.
–¢–û–õ–¨–ö–û –∫–æ–¥:"""
        
        content, source = self._hybrid_generate(prompt)
        new_code = self._extract_code(content)
        
        return CellResult(
            content=new_code,
            confidence=0.8 if "CLOUD" in source else 0.5,
            cell_name=self.name,
            metadata={"source": source, "file": file_path}
        )

    def run_python(self, code: str, timeout: int = 30) -> CellResult:
        """–í—ã–ø–æ–ª–Ω–∏—Ç—å Python –∫–æ–¥ (–õ–æ–∫–∞–ª—å–Ω–æ)"""
        temp_file = os.path.join(self.work_dir, "_temp_run.py")
        try:
            with open(temp_file, "w", encoding="utf-8") as f:
                f.write(code)
            
            result = subprocess.run(
                ["python", temp_file],
                capture_output=True,
                text=True,
                timeout=timeout,
                cwd=self.work_dir
            )
            
            output = result.stdout
            if result.stderr:
                output += f"\n\n–û–®–ò–ë–ö–ò:\n{result.stderr}"
            
            success = result.returncode == 0
            return CellResult(
                content=output if output else "(–Ω–µ—Ç –≤—ã–≤–æ–¥–∞)",
                confidence=0.9 if success else 0.3,
                cell_name=self.name,
                metadata={"returncode": result.returncode, "success": success}
            )
        except Exception as e:
            return CellResult(f"–û—à–∏–±–∫–∞ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è: {e}", 0.1, self.name)
        finally:
            if os.path.exists(temp_file):
                os.remove(temp_file)


class SelfModifyCell(CodeCell):
    name = "self_modify"
    MODIFIABLE_FILES = ["cells.py", "web_cell.py", "code_cell.py", "main.py"]
    
    def learn_from_self(self) -> CellResult:
        """–ê–Ω–∞–ª–∏–∑ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã"""
        report = []
        for f in self.MODIFIABLE_FILES:
            info = self.read_file(f)
            if info.exists:
                res = self.analyze_code(info.content)
                report.append(f"=== {f} ({res.metadata.get('source')}) ===\n{res.content}")
        
        return CellResult("\n\n".join(report), 1.0, self.name)


# === –¢–ï–°–¢ ===
if __name__ == "__main__":
    print("=" * 50)
    print("–¢–µ—Å—Ç CodeCell (Hybrid)")
    print("=" * 50)
    
    cell = CodeCell(work_dir=".")
    
    # –¢–µ—Å—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    print(f"\n–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞ —á–µ—Ä–µ–∑: {'CLOUD' if CLOUD_ENABLED else 'LOCAL'}...")
    result = cell.generate_code("–ù–∞–ø–∏—à–∏ —Ñ—É–Ω–∫—Ü–∏—é —Ñ–∏–±–æ–Ω–∞—á—á–∏ –Ω–∞ python")
    print(f"–ò—Å—Ç–æ—á–Ω–∏–∫: {result.metadata.get('source')}")
    print(result.content)
