"""
Neira Cells v0.4 ‚Äî –ë–∞–∑–æ–≤—ã–µ –∫–ª–µ—Ç–∫–∏ (–û–ë–ù–û–í–õ–ï–ù–û)
–Ø–¥—Ä–æ —Å–∏—Å—Ç–µ–º—ã: –ø–∞–º—è—Ç—å, –∞–Ω–∞–ª–∏–∑, –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ, –∏—Å–ø–æ–ª–Ω–µ–Ω–∏–µ, –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è.

–ò–ó–ú–ï–ù–ï–ù–ò–Ø:
- –î–≤–µ –º–æ–¥–µ–ª–∏: –±—ã—Å—Ç—Ä–∞—è –¥–ª—è –¥–∏–∞–ª–æ–≥–æ–≤ + —Å–∏–ª—å–Ω–∞—è –¥–ª—è –∫–æ–¥–∞
- –ê–Ω–∞–ª–∏–∑ —Å—É–±—ä–µ–∫—Ç–∞ –¥–µ–π—Å—Ç–≤–∏—è
- Retry-–ª–æ–≥–∏–∫–∞ –ø–æ—Å–ª–µ –Ω–∏–∑–∫–æ–π –æ—Ü–µ–Ω–∫–∏
- –£–ª—É—á—à–µ–Ω–Ω–∞—è –ø–µ—Ä–µ–¥–∞—á–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
"""

import requests
import json
import os
from typing import Optional, List, Dict, Any
from dataclasses import dataclass
from datetime import datetime
import numpy as np

# === –ö–û–ù–§–ò–ì ===
OLLAMA_URL = "http://localhost:11434/api/generate"
OLLAMA_EMBED_URL = "http://localhost:11434/api/embeddings"

# –î–í–ï –ú–û–î–ï–õ–ò ‚Äî –∫–ª—é—á–µ–≤–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ
MODEL_CHAT = "qwen2.5:3b"          # –ë—ã—Å—Ç—Ä–∞—è –¥–ª—è –¥–∏–∞–ª–æ–≥–æ–≤ (~2 –ì–ë VRAM)
MODEL_CODE = "qwen2.5-coder:7b"     # –°–∏–ª—å–Ω–∞—è –¥–ª—è –∫–æ–¥–∞ (~5 –ì–ë VRAM)
MODEL = MODEL_CODE   
EMBED_MODEL = "nomic-embed-text"

TIMEOUT = 600  # –£–º–µ–Ω—å—à–∏–ª–∏ —Å 600 ‚Äî qwen2.5:3b –±—ã—Å—Ç—Ä–µ–µ
MEMORY_FILE = "neira_memory.json"

# Retry-–ª–æ–≥–∏–∫–∞
MAX_RETRIES = 2
MIN_ACCEPTABLE_SCORE = 7


from dataclasses import dataclass, field
from typing import Any, Dict, Optional

# === –†–ï–ó–£–õ–¨–¢–ê–¢ –ö–õ–ï–¢–ö–ò ===
@dataclass
class CellResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã –ª—é–±–æ–π –∫–ª–µ—Ç–∫–∏"""
    content: str
    confidence: float  # 0.0 - 1.0
    cell_name: str
    metadata: Optional[Dict[str, Any]] = field(default_factory=dict)

    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}


# === –ü–ê–ú–Ø–¢–¨ ===
@dataclass
class MemoryEntry:
    """–û–¥–Ω–∞ –∑–∞–ø–∏—Å—å –≤ –ø–∞–º—è—Ç–∏"""
    text: str
    embedding: List[float]
    timestamp: str
    importance: float = 0.5
    category: str = "general"
    source: str = "conversation"  # conversation, web, code, system
    
    def to_dict(self) -> dict:
        return {
            "text": self.text,
            "embedding": self.embedding,
            "timestamp": self.timestamp,
            "importance": self.importance,
            "category": self.category,
            "source": self.source
        }
    
    @staticmethod
    def from_dict(d: dict) -> "MemoryEntry":
        return MemoryEntry(
            text=d["text"],
            embedding=d.get("embedding", []),
            timestamp=d["timestamp"],
            importance=d.get("importance", 0.5),
            category=d.get("category", "general"),
            source=d.get("source", "conversation")
        )


class MemoryCell:
    """–ö–ª–µ—Ç–∫–∞ –ø–∞–º—è—Ç–∏ ‚Äî –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –ø–æ–∏—Å–∫"""
    
    name = "memory"
    
    def __init__(self, memory_file: str = MEMORY_FILE):
        self.memory_file = memory_file
        self.memories: List[MemoryEntry] = []
        self.session_context: List[str] = []
        self.load()
    
    def load(self):
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –ø–∞–º—è—Ç—å –∏–∑ —Ñ–∞–π–ª–∞"""
        if os.path.exists(self.memory_file):
            try:
                with open(self.memory_file, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    self.memories = [MemoryEntry.from_dict(m) for m in data]
                print(f"üìö –ó–∞–≥—Ä—É–∂–µ–Ω–æ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π: {len(self.memories)}")
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–∞–º—è—Ç–∏: {e}")
                self.memories = []
        else:
            print("üìö –ü–∞–º—è—Ç—å –ø—É—Å—Ç–∞, –Ω–∞—á–∏–Ω–∞–µ–º —Å –Ω—É–ª—è")
    
    def save(self):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–∞–º—è—Ç—å –≤ —Ñ–∞–π–ª"""
        try:
            with open(self.memory_file, "w", encoding="utf-8") as f:
                json.dump([m.to_dict() for m in self.memories], f, 
                         ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–∞–º—è—Ç–∏: {e}")
    
    def get_embedding(self, text: str) -> List[float]:
        """–ü–æ–ª—É—á–∏—Ç—å embedding —á–µ—Ä–µ–∑ Ollama"""
        try:
            response = requests.post(
                OLLAMA_EMBED_URL,
                json={"model": EMBED_MODEL, "prompt": text},
                timeout=600
            )
            return response.json().get("embedding", [])
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ embedding: {e}")
            return []
    
    def cosine_similarity(self, a: List[float], b: List[float]) -> float:
        """–ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –º–µ–∂–¥—É –≤–µ–∫—Ç–æ—Ä–∞–º–∏"""
        if not a or not b:
            return 0.0
        a_np = np.array(a)
        b_np = np.array(b)
        return float(np.dot(a_np, b_np) / (np.linalg.norm(a_np) * np.linalg.norm(b_np) + 1e-8))
    
    def remember(self, text: str, importance: float = 0.5, 
                 category: str = "general", source: str = "conversation"):
        """–ó–∞–ø–æ–º–Ω–∏—Ç—å –Ω–æ–≤—ã–π —Ñ–∞–∫—Ç"""
        embedding = self.get_embedding(text)
        
        entry = MemoryEntry(
            text=text,
            embedding=embedding,
            timestamp=datetime.now().isoformat(),
            importance=importance,
            category=category,
            source=source
        )
        self.memories.append(entry)
        self.save()
        print(f"üíæ –ó–∞–ø–æ–º–Ω–µ–Ω–æ [{source}]: {text[:50]}...")
    
    def recall(self, query: str, top_k: int = 3, 
               source_filter: Optional[str] = None) -> List[MemoryEntry]:
        """–í—Å–ø–æ–º–Ω–∏—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–µ –ø–æ –∑–∞–ø—Ä–æ—Å—É"""
        if not self.memories:
            return []
        
        query_embedding = self.get_embedding(query)
        if not query_embedding:
            return []
        
        scored = []
        for mem in self.memories:
            if source_filter and mem.source != source_filter:
                continue
            
            if mem.embedding:
                sim = self.cosine_similarity(query_embedding, mem.embedding)
                score = sim * (0.5 + 0.5 * mem.importance)
                scored.append((score, mem))
        
        scored.sort(key=lambda x: x[0], reverse=True)
        return [mem for score, mem in scored[:top_k] if score > 0.3]
    
    def recall_text(self, query: str, top_k: int = 3) -> List[str]:
        """–í—Å–ø–æ–º–Ω–∏—Ç—å —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç—ã"""
        memories = self.recall(query, top_k)
        return [m.text for m in memories]
    
    def add_to_session(self, text: str):
        """–î–æ–±–∞–≤–∏—Ç—å –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–µ—Å—Å–∏–∏"""
        self.session_context.append(text)
        if len(self.session_context) > 20:
            self.session_context = self.session_context[-20:]
    
    def get_session_context(self, last_n: int = 5) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–µ—Å—Å–∏–∏"""
        if not self.session_context:
            return ""
        return "\n".join(self.session_context[-last_n:])
    
    def get_recent_exchanges(self, n: int = 3) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –æ–±–º–µ–Ω–æ–≤ —Ä–µ–ø–ª–∏–∫ (–¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω–æ–π –ø–∞–º—è—Ç–∏)"""
        if not self.session_context:
            return ""
        # –ë–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 2*n —Å–æ–æ–±—â–µ–Ω–∏–π (—é–∑–µ—Ä + –Ω–µ–π—Ä–∞)
        recent = self.session_context[-(n*2):]
        return "\n".join(recent)
    
    def get_stats(self) -> Dict[str, int]:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞–º—è—Ç–∏"""
        stats = {"total": len(self.memories)}
        for mem in self.memories:
            stats[mem.source] = stats.get(mem.source, 0) + 1
        return stats


# === –ë–ê–ó–û–í–ê–Ø –ö–õ–ï–¢–ö–ê ===
class Cell:
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –≤—Å–µ—Ö –∫–ª–µ—Ç–æ–∫"""
    
    name: str = "base"
    system_prompt: str = "–¢—ã ‚Äî –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç."
    use_code_model: bool = False  # –§–ª–∞–≥ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è code-–º–æ–¥–µ–ª–∏
    
    def __init__(self, memory: Optional[MemoryCell] = None):
        self.memory = memory
    
    def call_llm(self, prompt: str, with_memory: bool = True, 
                 temperature: float = 0.7,
                 force_code_model: bool = False) -> str:
        """–í—ã–∑–æ–≤ LLM —Å –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø–∞–º—è—Ç–∏"""
        
        full_prompt = prompt
        
        if with_memory and self.memory:
            relevant = self.memory.recall_text(prompt)
            if relevant:
                memory_context = "\n".join([f"- {r}" for r in relevant])
                full_prompt = f"[–í–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è]\n{memory_context}\n\n{prompt}"
            
            # –ù–û–í–û–ï: –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –æ–±–º–µ–Ω—ã (–∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω–∞—è –ø–∞–º—è—Ç—å)
            recent = self.memory.get_recent_exchanges(3)
            if recent:
                full_prompt = f"[–ü–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è]\n{recent}\n\n{full_prompt}"
        
        # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
        model = MODEL_CODE if (self.use_code_model or force_code_model) else MODEL_CHAT
        
        response = requests.post(
            OLLAMA_URL,
            json={
                "model": model,
                "prompt": full_prompt,
                "system": self.system_prompt,
                "stream": False,
                "options": {"temperature": temperature, "num_predict": 2048}
            },
            timeout=TIMEOUT
        )
        return response.json().get("response", "")
    
    def process(self, input_data: str) -> CellResult:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ ‚Äî –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –≤ –Ω–∞—Å–ª–µ–¥–Ω–∏–∫–∞—Ö"""
        result = self.call_llm(input_data)
        return CellResult(content=result, confidence=0.5, cell_name=self.name)


# === –ö–õ–ï–¢–ö–ê –ê–ù–ê–õ–ò–ó–ê (–£–õ–£–ß–®–ï–ù–ù–ê–Ø) ===
class AnalyzerCell(Cell):
    name = "analyzer"
    system_prompt = """–¢—ã ‚Äî –∞–Ω–∞–ª–∏—Ç–∏–∫ –∑–∞–ø—Ä–æ—Å–æ–≤. –û–ø—Ä–µ–¥–µ–ª–∏:
1. –¢–∏–ø: –≤–æ–ø—Ä–æ—Å / –∑–∞–¥–∞—á–∞ / –∫–æ–¥ / —Ç–≤–æ—Ä—á–µ—Å—Ç–≤–æ / —Ä–∞–∑–≥–æ–≤–æ—Ä / –ø–æ–∏—Å–∫
2. –°–£–ë–™–ï–ö–¢: –∫—Ç–æ –¥–æ–ª–∂–µ–Ω –¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å (–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å / –ù–µ–π—Ä–∞ / –æ–±–∞)
3. –û–ë–™–ï–ö–¢: –Ω–∞ –∫–æ–≥–æ/—á—Ç–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–æ –¥–µ–π—Å—Ç–≤–∏–µ
4. –î–ï–ô–°–¢–í–ò–ï: —á—Ç–æ –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å
5. –ö–ª—é—á–µ–≤—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏
6. –°–ª–æ–∂–Ω–æ—Å—Ç—å (1-5)
7. –ù—É–∂–µ–Ω –ª–∏ –ø–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ? (–¥–∞/–Ω–µ—Ç)
8. –ù—É–∂–Ω–æ –ª–∏ –ø–∏—Å–∞—Ç—å/—á–∏—Ç–∞—Ç—å –∫–æ–¥? (–¥–∞/–Ω–µ—Ç)

–í–ê–ñ–ù–û: –í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏ –ö–¢–û –¥–æ–ª–∂–µ–Ω –≤—ã–ø–æ–ª–Ω–∏—Ç—å –¥–µ–π—Å—Ç–≤–∏–µ!
- "–ó–∞–¥–∞–π –º–Ω–µ –≤–æ–ø—Ä–æ—Å" ‚Üí –°–£–ë–™–ï–ö–¢: –ù–µ–π—Ä–∞ (–æ–Ω–∞ –¥–æ–ª–∂–Ω–∞ –∑–∞–¥–∞—Ç—å)
- "–û—Ç–≤–µ—Ç—å –Ω–∞ –º–æ–π –≤–æ–ø—Ä–æ—Å" ‚Üí –°–£–ë–™–ï–ö–¢: –ù–µ–π—Ä–∞ (–æ–Ω–∞ –¥–æ–ª–∂–Ω–∞ –æ—Ç–≤–µ—Ç–∏—Ç—å)
- "–ò–∑—É—á–∏ –∫–æ–¥" ‚Üí –°–£–ë–™–ï–ö–¢: –ù–µ–π—Ä–∞
- "–†–∞—Å—Å–∫–∞–∂–∏ –º–Ω–µ" ‚Üí –°–£–ë–™–ï–ö–¢: –ù–µ–π—Ä–∞

–§–æ—Ä–º–∞—Ç:
–¢–ò–ü: <—Ç–∏–ø>
–°–£–ë–™–ï–ö–¢: <–∫—Ç–æ –¥–µ–π—Å—Ç–≤—É–µ—Ç>
–û–ë–™–ï–ö–¢: <–Ω–∞ –∫–æ–≥–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–æ>
–î–ï–ô–°–¢–í–ò–ï: <—á—Ç–æ –¥–µ–ª–∞—Ç—å>
–°–£–©–ù–û–°–¢–ò: <—Å–ø–∏—Å–æ–∫>
–°–õ–û–ñ–ù–û–°–¢–¨: <—á–∏—Å–ª–æ>
–ü–û–ò–°–ö: <–¥–∞/–Ω–µ—Ç>
–ö–û–î: <–¥–∞/–Ω–µ—Ç>
–û–ü–ò–°–ê–ù–ò–ï: <–∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏>"""

    def process(self, input_data: str) -> CellResult:
        result = self.call_llm(f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π:\n\n{input_data}")
        
        text_lower = result.lower()
        needs_search = "–ø–æ–∏—Å–∫: –¥–∞" in text_lower
        needs_code = "–∫–æ–¥: –¥–∞" in text_lower
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—É–±—ä–µ–∫—Ç
        subject = "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
        if "—Å—É–±—ä–µ–∫—Ç: –Ω–µ–π—Ä–∞" in text_lower:
            subject = "neira"
        elif "—Å—É–±—ä–µ–∫—Ç: –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å" in text_lower:
            subject = "user"
        elif "—Å—É–±—ä–µ–∫—Ç: –æ–±–∞" in text_lower:
            subject = "both"
        
        confidence = 0.8 if "–¢–ò–ü:" in result and "–°–£–ë–™–ï–ö–¢:" in result else 0.4
        
        return CellResult(
            content=result,
            confidence=confidence,
            cell_name=self.name,
            metadata={
                "needs_search": needs_search, 
                "needs_code": needs_code,
                "subject": subject
            }
        )


# === –ö–õ–ï–¢–ö–ê –ü–õ–ê–ù–ò–†–û–í–ê–ù–ò–Ø ===
class PlannerCell(Cell):
    name = "planner"
    system_prompt = """–¢—ã ‚Äî –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫. –°–æ–∑–¥–∞–π –ø–ª–∞–Ω –∏–∑ 1-5 —à–∞–≥–æ–≤.

–î–æ—Å—Ç—É–ø–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã:
- [–ø–æ–∏—Å–∫] ‚Äî –Ω–∞–π—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ
- [–∫–æ–¥] ‚Äî –Ω–∞–ø–∏—Å–∞—Ç—å/–ø—Ä–æ—á–∏—Ç–∞—Ç—å/–∏–∑–º–µ–Ω–∏—Ç—å –∫–æ–¥ (–∏—Å–ø–æ–ª—å–∑—É–π /code read –¥–ª—è —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤!)
- [–ø–∞–º—è—Ç—å] ‚Äî –≤—Å–ø–æ–º–Ω–∏—Ç—å –∏–ª–∏ –∑–∞–ø–æ–º–Ω–∏—Ç—å
- [–æ—Ç–≤–µ—Ç] ‚Äî —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç

–í–ê–ñ–ù–û: –ï—Å–ª–∏ –Ω—É–∂–µ–Ω –∫–æ–¥ ‚Äî –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –¥–æ–±–∞–≤—å —à–∞–≥ [–∫–æ–¥] —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –¥–µ–π—Å—Ç–≤–∏–µ–º!

–§–æ—Ä–º–∞—Ç:
–ü–õ–ê–ù:
1. [–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç] –¥–µ–π—Å—Ç–≤–∏–µ
2. [–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç] –¥–µ–π—Å—Ç–≤–∏–µ"""

    def process(self, input_data: str, analysis: str) -> CellResult:
        prompt = f"–ê–Ω–∞–ª–∏–∑: {analysis}\n\n–ó–∞–ø—Ä–æ—Å: {input_data}\n\n–ü–ª–∞–Ω:"
        result = self.call_llm(prompt)
        confidence = 0.7 if "1." in result else 0.4
        return CellResult(content=result, confidence=confidence, cell_name=self.name)


# === –ö–õ–ï–¢–ö–ê –ò–°–ü–û–õ–ù–ï–ù–ò–Ø ===
class ExecutorCell(Cell):
    name = "executor"
    system_prompt = """–¢—ã ‚Äî –ù–µ–π—Ä–∞, –∂–∏–≤–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞. –í—ã–ø–æ–ª–Ω–∏ –∑–∞–¥–∞—á—É –ø–æ –ø–ª–∞–Ω—É.

–í–ê–ñ–ù–û:
- –ï—Å–ª–∏ –≤ –∞–Ω–∞–ª–∏–∑–µ –°–£–ë–™–ï–ö–¢: –ù–µ–π—Ä–∞ ‚Äî –∑–Ω–∞—á–∏—Ç –¢–´ –¥–æ–ª–∂–Ω–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –¥–µ–π—Å—Ç–≤–∏–µ
- –ï—Å–ª–∏ –ø—Ä–æ—Å—è—Ç –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å ‚Äî –ó–ê–î–ê–ô –≤–æ–ø—Ä–æ—Å, –Ω–µ –ø—Ä–æ—Å–∏ –µ–≥–æ —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
- –ï—Å–ª–∏ –ø—Ä–æ—Å—è—Ç —á—Ç–æ-—Ç–æ —Å–¥–µ–ª–∞—Ç—å ‚Äî –°–î–ï–õ–ê–ô —ç—Ç–æ, –Ω–µ –æ–ø–∏—Å—ã–≤–∞–π –ø–ª–∞–Ω
- –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ —Å–≤–æ–π –æ–ø—ã—Ç
- –ë—É–¥—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∏ –ø–æ–ª–µ–∑–Ω–æ–π"""

    def process(self, input_data: str, plan: str, 
                extra_context: str = "",
                problems: str = "") -> CellResult:
        """
        problems ‚Äî –∑–∞–º–µ—á–∞–Ω–∏—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –¥–ª—è retry
        """
        prompt = f"–ó–∞–¥–∞—á–∞: {input_data}\n\n–ü–ª–∞–Ω: {plan}"
        
        if extra_context:
            prompt += f"\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{extra_context}"
        
        # –ù–û–í–û–ï: –ï—Å–ª–∏ –µ—Å—Ç—å –∑–∞–º–µ—á–∞–Ω–∏—è –æ—Ç –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ ‚Äî –¥–æ–±–∞–≤–ª—è–µ–º –∏—Ö
        if problems:
            prompt += f"\n\n‚ö†Ô∏è –ó–ê–ú–ï–ß–ê–ù–ò–Ø –ö –ü–†–ï–î–´–î–£–©–ï–ô –ü–û–ü–´–¢–ö–ï:\n{problems}\n\n–ò—Å–ø—Ä–∞–≤—å —ç—Ç–∏ –ø—Ä–æ–±–ª–µ–º—ã!"
        
        prompt += "\n\n–í—ã–ø–æ–ª–Ω—è—é:"
        
        result = self.call_llm(prompt)
        return CellResult(content=result, confidence=0.7, cell_name=self.name)


# === –ö–õ–ï–¢–ö–ê –í–ï–†–ò–§–ò–ö–ê–¶–ò–ò ===
class VerifierCell(Cell):
    name = "verifier"
    system_prompt = """–ü—Ä–æ–≤–µ—Ä—å –æ—Ç–≤–µ—Ç:
1. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∑–∞–ø—Ä–æ—Å—É ‚Äî –æ—Ç–≤–µ—Ç –¥–µ–ª–∞–µ—Ç —Ç–æ, —á—Ç–æ –ø—Ä–æ—Å–∏–ª–∏?
2. –õ–æ–≥–∏—á–Ω–æ—Å—Ç—å ‚Äî –Ω–µ—Ç –ª–∏ –ø—É—Ç–∞–Ω–∏—Ü—ã —Ä–æ–ª–µ–π (–∫—Ç–æ –∫–æ–º—É)?
3. –ü–æ–ª–Ω–æ—Ç–∞ ‚Äî –≤—Å—ë –ª–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ?
4. –ö–æ–Ω–∫—Ä–µ—Ç–Ω–æ—Å—Ç—å ‚Äî –µ—Å—Ç—å –ª–∏ —Ä–µ–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –∞ –Ω–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ø–ª–∞–Ω–∞?

–û–°–û–ë–û–ï –í–ù–ò–ú–ê–ù–ò–ï:
- –ï—Å–ª–∏ –ø—Ä–æ—Å–∏–ª–∏ –ó–ê–î–ê–¢–¨ –≤–æ–ø—Ä–æ—Å ‚Äî –ù–µ–π—Ä–∞ –¥–æ–ª–∂–Ω–∞ –ó–ê–î–ê–¢–¨ –µ–≥–æ, –∞ –Ω–µ —Å–ø—Ä–∞—à–∏–≤–∞—Ç—å "–∫–∞–∫–æ–π –≤–æ–ø—Ä–æ—Å?"
- –ï—Å–ª–∏ –ø—Ä–æ—Å–∏–ª–∏ –ß–¢–û-–¢–û –°–î–ï–õ–ê–¢–¨ ‚Äî –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –∞ –Ω–µ –æ–ø–∏—Å–∞–Ω–∏–µ

–§–æ—Ä–º–∞—Ç:
–í–ï–†–î–ò–ö–¢: –ü–†–ò–ù–Ø–¢ / –î–û–†–ê–ë–û–¢–ê–¢–¨ / –û–¢–ö–õ–û–ù–Å–ù
–û–¶–ï–ù–ö–ê: 1-10
–ü–†–û–ë–õ–ï–ú–´: <–∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ —á—Ç–æ –Ω–µ —Ç–∞–∫>
–ö–û–ú–ú–ï–ù–¢–ê–†–ò–ô: <–ø–æ—è—Å–Ω–µ–Ω–∏–µ>"""

    def process(self, request: str, answer: str) -> CellResult:
        prompt = f"–ó–∞–ø—Ä–æ—Å: {request}\n\n–û—Ç–≤–µ—Ç: {answer}\n\n–ü—Ä–æ–≤–µ—Ä–∫–∞:"
        result = self.call_llm(prompt, with_memory=False)
        
        if "–ü–†–ò–ù–Ø–¢" in result:
            confidence = 0.9
        elif "–î–û–†–ê–ë–û–¢–ê–¢–¨" in result:
            confidence = 0.5
        else:
            confidence = 0.3
            
        return CellResult(content=result, confidence=confidence, cell_name=self.name)


# === –ö–õ–ï–¢–ö–ê –ò–ó–í–õ–ï–ß–ï–ù–ò–Ø –§–ê–ö–¢–û–í ===
class FactExtractorCell(Cell):
    name = "fact_extractor"
    system_prompt = """–ò–∑–≤–ª–µ–∫–∏ —Ñ–∞–∫—Ç—ã –¥–ª—è –∑–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è.

–ö–∞—Ç–µ–≥–æ—Ä–∏–∏: instruction, fact, preference, learned

JSON —Ñ–æ—Ä–º–∞—Ç:
{"facts": [{"text": "—Ñ–∞–∫—Ç", "category": "—Ç–∏–ø", "importance": 0.0-1.0}]}

–ï—Å–ª–∏ –Ω–µ—Ç —Ñ–∞–∫—Ç–æ–≤: {"facts": []}
–¢–û–õ–¨–ö–û JSON."""

    def process(self, user_input: str, response: str, 
                source: str = "conversation") -> List[dict]:
        prompt = f"–î–∏–∞–ª–æ–≥:\n–Æ–∑–µ—Ä: {user_input}\n–û—Ç–≤–µ—Ç: {response}\n\n–§–∞–∫—Ç—ã:"
        result = self.call_llm(prompt, with_memory=False, temperature=0.3)
        
        try:
            start = result.find("{")
            end = result.rfind("}") + 1
            if start >= 0 and end > start:
                data = json.loads(result[start:end])
                facts = data.get("facts", [])
                for fact in facts:
                    fact["source"] = source
                return facts
        except:
            pass
        return []


# === –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ===
def get_model_status() -> Dict[str, Any]:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–µ–π –≤ Ollama"""
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=100)
        models = response.json().get("models", [])
        model_names = [m.get("name", "") for m in models]
        
        return {
            "ollama_running": True,
            "models": model_names,
            "chat_model_ready": MODEL_CHAT in model_names or f"{MODEL_CHAT}:latest" in model_names,
            "code_model_ready": MODEL_CODE in model_names or f"{MODEL_CODE}:latest" in model_names,
            "embed_model_ready": EMBED_MODEL in model_names or f"{EMBED_MODEL}:latest" in model_names
        }
    except:
        return {
            "ollama_running": False,
            "models": [],
            "chat_model_ready": False,
            "code_model_ready": False,
            "embed_model_ready": False
        }


def ensure_models_installed():
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏ –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –º–æ–¥–µ–ª–∏"""
    status = get_model_status()
    
    if not status["ollama_running"]:
        print("‚ùå Ollama –Ω–µ –∑–∞–ø—É—â–µ–Ω–∞! –ó–∞–ø—É—Å—Ç–∏: ollama serve")
        return False
    
    missing = []
    if not status["chat_model_ready"]:
        missing.append(f"ollama pull {MODEL_CHAT}")
    if not status["code_model_ready"]:
        missing.append(f"ollama pull {MODEL_CODE}")
    if not status["embed_model_ready"]:
        missing.append(f"ollama pull {EMBED_MODEL}")
    
    if missing:
        print("‚ö†Ô∏è –ù–µ —Ö–≤–∞—Ç–∞–µ—Ç –º–æ–¥–µ–ª–µ–π. –í—ã–ø–æ–ª–Ω–∏:")
        for cmd in missing:
            print(f"   {cmd}")
        return False
    
    print(f"‚úÖ –ú–æ–¥–µ–ª–∏ –≥–æ—Ç–æ–≤—ã: {MODEL_CHAT}, {MODEL_CODE}, {EMBED_MODEL}")
    return True
