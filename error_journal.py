"""
–î–Ω–µ–≤–Ω–∏–∫ –û—à–∏–±–æ–∫ –ù–µ–π—Ä—ã (ErrorJournal)
====================================

–°–∏—Å—Ç–µ–º–∞ –¥–ª—è:
1. –ó–∞–ø–∏—Å–∏ –æ—à–∏–±–æ–∫ (–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π feedback, –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è)
2. –ê–Ω–∞–ª–∏–∑–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ ‚Äî –ü–û–ß–ï–ú–£ –æ—à–∏–±–∫–∞ –ø—Ä–æ–∏–∑–æ—à–ª–∞
3. –ò–∑–≤–ª–µ—á–µ–Ω–∏—è —É—Ä–æ–∫–æ–≤ ‚Äî –ö–ê–ö –∏–∑–±–µ–∂–∞—Ç—å –≤ –±—É–¥—É—â–µ–º
4. –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–≥–æ —Å–∞–º–æ–∞–Ω–∞–ª–∏–∑–∞

–ò–∑ –ø–∏—Å—å–º–∞ (–£—Ä–æ–∫ 16): 
"–û—à–∏–±–∫–∞ + –ø—Ä–∏–∑–Ω–∞–Ω–∏–µ + –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ = –†–û–°–¢"

–ê–≤—Ç–æ—Ä: Claude (–¥–ª—è –ù–µ–π—Ä—ã)
–î–∞—Ç–∞: 2 —è–Ω–≤–∞—Ä—è 2026
"""

import json
import logging
import re
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from pathlib import Path
from typing import Optional, Dict, List, Any, Tuple
from collections import Counter, defaultdict

logger = logging.getLogger(__name__)


class ErrorCategory(Enum):
    """–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –æ—à–∏–±–æ–∫."""
    FACTUAL = "factual"             # –§–∞–∫—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞
    MISUNDERSTANDING = "misunderstanding"  # –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø–æ–Ω—è–ª –≤–æ–ø—Ä–æ—Å
    TONE = "tone"                   # –ù–µ–ø–æ–¥—Ö–æ–¥—è—â–∏–π —Ç–æ–Ω
    INCOMPLETE = "incomplete"       # –ù–µ–ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç
    OVERCOMPLICATED = "overcomplicated"  # –°–ª–∏—à–∫–æ–º —Å–ª–æ–∂–Ω—ã–π –æ—Ç–≤–µ—Ç
    OFF_TOPIC = "off_topic"         # –û—Ç–≤–µ—Ç –Ω–µ –ø–æ —Ç–µ–º–µ
    HALLUCINATION = "hallucination" # –í—ã–¥—É–º–∞–Ω–Ω—ã–µ —Ñ–∞–∫—Ç—ã
    INSENSITIVE = "insensitive"     # –ù–µ—á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
    TECHNICAL = "technical"         # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –∫–æ–¥–µ/—Ä–µ—à–µ–Ω–∏–∏
    OTHER = "other"                 # –î—Ä—É–≥–æ–µ


class ErrorSeverity(Enum):
    """–°–µ—Ä—å—ë–∑–Ω–æ—Å—Ç—å –æ—à–∏–±–∫–∏."""
    MINOR = "minor"         # –ú–µ–ª–∫–∞—è ‚Äî –º–æ–∂–Ω–æ –±—ã–ª–æ –ª—É—á—à–µ
    MODERATE = "moderate"   # –£–º–µ—Ä–µ–Ω–Ω–∞—è ‚Äî –∑–∞–º–µ—Ç–Ω–æ –ø–æ–≤–ª–∏—è–ª–æ –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ
    MAJOR = "major"         # –°–µ—Ä—å—ë–∑–Ω–∞—è ‚Äî –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –±—ã–ª –Ω–µ–¥–æ–≤–æ–ª–µ–Ω
    CRITICAL = "critical"   # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è ‚Äî –º–æ–≥–ª–∞ –ø—Ä–∏—á–∏–Ω–∏—Ç—å –≤—Ä–µ–¥


@dataclass
class ErrorEntry:
    """–ó–∞–ø–∏—Å—å –æ–± –æ—à–∏–±–∫–µ –≤ –¥–Ω–µ–≤–Ω–∏–∫–µ."""
    id: str
    timestamp: datetime
    user_id: int
    
    # –ß—Ç–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ
    original_query: str
    neira_response: str
    user_feedback: str  # –ß—Ç–æ —Å–∫–∞–∑–∞–ª –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
    
    # –ê–Ω–∞–ª–∏–∑
    category: ErrorCategory
    severity: ErrorSeverity
    root_cause: str  # –ü–æ—á–µ–º—É —ç—Ç–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ
    lesson_learned: str  # –ß—Ç–æ –ù–µ–π—Ä–∞ –ø–æ–Ω—è–ª–∞
    
    # –ö–æ–Ω—Ç–µ–∫—Å—Ç
    topic: Optional[str] = None
    was_corrected: bool = False
    correction: Optional[str] = None
    
    def to_dict(self) -> dict:
        return {
            'id': self.id,
            'timestamp': self.timestamp.isoformat(),
            'user_id': self.user_id,
            'original_query': self.original_query,
            'neira_response': self.neira_response,
            'user_feedback': self.user_feedback,
            'category': self.category.value,
            'severity': self.severity.value,
            'root_cause': self.root_cause,
            'lesson_learned': self.lesson_learned,
            'topic': self.topic,
            'was_corrected': self.was_corrected,
            'correction': self.correction
        }
    
    @classmethod
    def from_dict(cls, d: dict) -> 'ErrorEntry':
        return cls(
            id=d['id'],
            timestamp=datetime.fromisoformat(d['timestamp']),
            user_id=d['user_id'],
            original_query=d['original_query'],
            neira_response=d['neira_response'],
            user_feedback=d['user_feedback'],
            category=ErrorCategory(d.get('category', 'other')),
            severity=ErrorSeverity(d.get('severity', 'moderate')),
            root_cause=d['root_cause'],
            lesson_learned=d['lesson_learned'],
            topic=d.get('topic'),
            was_corrected=d.get('was_corrected', False),
            correction=d.get('correction')
        )


@dataclass
class ErrorPattern:
    """–ü–∞—Ç—Ç–µ—Ä–Ω –æ—à–∏–±–æ–∫ ‚Äî –≤—ã—è–≤–ª–µ–Ω–Ω–∞—è —Ç–µ–Ω–¥–µ–Ω—Ü–∏—è."""
    pattern_id: str
    description: str
    category: ErrorCategory
    frequency: int  # –°–∫–æ–ª—å–∫–æ —Ä–∞–∑ –≤—Å—Ç—Ä–µ—Ç–∏–ª—Å—è
    examples: List[str]  # ID –æ—à–∏–±–æ–∫-–ø—Ä–∏–º–µ—Ä–æ–≤
    prevention_strategy: str  # –ö–∞–∫ –∏–∑–±–µ–∂–∞—Ç—å
    first_seen: datetime
    last_seen: datetime
    
    def to_dict(self) -> dict:
        return {
            'pattern_id': self.pattern_id,
            'description': self.description,
            'category': self.category.value,
            'frequency': self.frequency,
            'examples': self.examples,
            'prevention_strategy': self.prevention_strategy,
            'first_seen': self.first_seen.isoformat(),
            'last_seen': self.last_seen.isoformat()
        }
    
    @classmethod
    def from_dict(cls, d: dict) -> 'ErrorPattern':
        return cls(
            pattern_id=d['pattern_id'],
            description=d['description'],
            category=ErrorCategory(d['category']),
            frequency=d['frequency'],
            examples=d['examples'],
            prevention_strategy=d['prevention_strategy'],
            first_seen=datetime.fromisoformat(d['first_seen']),
            last_seen=datetime.fromisoformat(d['last_seen'])
        )


class ErrorJournal:
    """
    –î–Ω–µ–≤–Ω–∏–∫ –û—à–∏–±–æ–∫ ‚Äî —Å–∏—Å—Ç–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –æ—à–∏–±–∫–∞—Ö.
    
    –§—É–Ω–∫—Ü–∏–∏:
    - –ó–∞–ø–∏—Å—ã–≤–∞—Ç—å –æ—à–∏–±–∫–∏ —Å –∞–Ω–∞–ª–∏–∑–æ–º
    - –í—ã—è–≤–ª—è—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã
    - –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —É—Ä–æ–∫–∏
    - –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    """
    
    def __init__(self, journal_file: str = "data/error_journal.json"):
        self.journal_file = Path(journal_file)
        self.journal_file.parent.mkdir(parents=True, exist_ok=True)
        
        # –•—Ä–∞–Ω–∏–ª–∏—â–∞
        self.entries: List[ErrorEntry] = []
        self.patterns: Dict[str, ErrorPattern] = {}
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        self._load()
        
        logger.info(f"üìî ErrorJournal –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {len(self.entries)} –∑–∞–ø–∏—Å–µ–π, {len(self.patterns)} –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤")
    
    def _load(self):
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –∂—É—Ä–Ω–∞–ª –∏–∑ —Ñ–∞–π–ª–∞."""
        if self.journal_file.exists():
            try:
                with open(self.journal_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.entries = [ErrorEntry.from_dict(e) for e in data.get('entries', [])]
                    self.patterns = {
                        k: ErrorPattern.from_dict(v) 
                        for k, v in data.get('patterns', {}).items()
                    }
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∂—É—Ä–Ω–∞–ª–∞: {e}")
    
    def _save(self):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∂—É—Ä–Ω–∞–ª –≤ —Ñ–∞–π–ª."""
        try:
            data = {
                'entries': [e.to_dict() for e in self.entries],
                'patterns': {k: v.to_dict() for k, v in self.patterns.items()}
            }
            with open(self.journal_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∂—É—Ä–Ω–∞–ª–∞: {e}")
    
    def _generate_id(self) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID."""
        import hashlib
        import time
        data = f"{time.time()}{len(self.entries)}"
        return hashlib.sha256(data.encode()).hexdigest()[:12]
    
    def record_error(
        self,
        user_id: int,
        original_query: str,
        neira_response: str,
        user_feedback: str,
        correction: Optional[str] = None,
        topic: Optional[str] = None
    ) -> ErrorEntry:
        """
        –ó–∞–ø–∏—Å–∞—Ç—å –æ—à–∏–±–∫—É –≤ –∂—É—Ä–Ω–∞–ª.
        
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:
        - –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é
        - –û—Ü–µ–Ω–∏–≤–∞–µ—Ç —Å–µ—Ä—å—ë–∑–Ω–æ—Å—Ç—å
        - –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–∏—á–∏–Ω—É
        - –ò–∑–≤–ª–µ–∫–∞–µ—Ç —É—Ä–æ–∫
        """
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ—à–∏–±–∫—É
        category = self._detect_category(original_query, neira_response, user_feedback)
        severity = self._assess_severity(user_feedback, category)
        root_cause = self._analyze_root_cause(original_query, neira_response, user_feedback, category)
        lesson = self._extract_lesson(category, root_cause, correction)
        
        entry = ErrorEntry(
            id=self._generate_id(),
            timestamp=datetime.now(),
            user_id=user_id,
            original_query=original_query,
            neira_response=neira_response,
            user_feedback=user_feedback,
            category=category,
            severity=severity,
            root_cause=root_cause,
            lesson_learned=lesson,
            topic=topic,
            was_corrected=correction is not None,
            correction=correction
        )
        
        self.entries.append(entry)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        self._update_patterns(entry)
        
        self._save()
        
        logger.info(
            f"üìî –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∞–Ω–∞: {entry.id} [{category.value}] "
            f"severity={severity.value}"
        )
        
        return entry
    
    def _detect_category(
        self, 
        query: str, 
        response: str, 
        feedback: str
    ) -> ErrorCategory:
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—é –æ—à–∏–±–∫–∏."""
        feedback_lower = feedback.lower()
        response_lower = response.lower()
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏
        patterns = {
            ErrorCategory.FACTUAL: [
                r'–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ', r'–æ—à–∏–±–∫–∞', r'–Ω–µ —Ç–∞–∫', r'–Ω–µ–≤–µ—Ä–Ω–æ', 
                r'wrong', r'incorrect', r'–Ω–µ —Ç–æ—á–Ω–æ'
            ],
            ErrorCategory.MISUNDERSTANDING: [
                r'–Ω–µ –ø–æ–Ω—è–ª', r'–Ω–µ —Ç–æ', r'—è —Å–ø—Ä–∞—à–∏–≤–∞–ª', r'–∏–º–µ–ª –≤ –≤–∏–¥—É',
                r'–Ω–µ –æ–± —ç—Ç–æ–º', r'–¥—Ä—É–≥–æ–µ'
            ],
            ErrorCategory.TONE: [
                r'–≥—Ä—É–±–æ', r'—Ö–æ–ª–æ–¥–Ω–æ', r'—Ñ–æ—Ä–º–∞–ª—å–Ω–æ', r'–±–µ–∑–¥—É—à–Ω–æ',
                r'tone', r'—Ç–æ–Ω'
            ],
            ErrorCategory.INCOMPLETE: [
                r'–Ω–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é', r'–º–∞–ª–æ', r'–¥–æ–±–∞–≤—å', r'–µ—â—ë',
                r'–Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ', r'incomplete'
            ],
            ErrorCategory.OVERCOMPLICATED: [
                r'—Å–ª–æ–∂–Ω–æ', r'–ø—Ä–æ—â–µ', r'–Ω–µ –ø–æ–Ω—è—Ç–Ω–æ', r'–∑–∞–ø—É—Ç–∞–Ω–Ω–æ',
                r'overcomplicated', r'too complex'
            ],
            ErrorCategory.OFF_TOPIC: [
                r'–Ω–µ –ø–æ —Ç–µ–º–µ', r'–ø—Ä–∏ —á—ë–º', r'off topic', r'–¥—Ä—É–≥–æ–µ'
            ],
            ErrorCategory.HALLUCINATION: [
                r'–≤—ã–¥—É–º–∞–ª', r'–Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç', r'–ø—Ä–∏–¥—É–º–∞–ª', r'–Ω–µ—Ç —Ç–∞–∫–æ–≥–æ',
                r'hallucination', r'fake'
            ],
            ErrorCategory.INSENSITIVE: [
                r'–±–µ—Å—á—É–≤—Å—Ç–≤–µ–Ω', r'–Ω–µ –ø–æ–Ω–∏–º–∞–µ—à—å', r'–æ–±–∏–¥–Ω–æ', r'insensitive'
            ],
            ErrorCategory.TECHNICAL: [
                r'–Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç', r'–æ—à–∏–±–∫–∞ –≤ –∫–æ–¥–µ', r'–±–∞–≥', r'bug',
                r'syntax', r'error'
            ],
        }
        
        for category, category_patterns in patterns.items():
            for pattern in category_patterns:
                if re.search(pattern, feedback_lower, re.IGNORECASE):
                    return category
        
        return ErrorCategory.OTHER
    
    def _assess_severity(
        self, 
        feedback: str, 
        category: ErrorCategory
    ) -> ErrorSeverity:
        """–û—Ü–µ–Ω–∏—Ç—å —Å–µ—Ä—å—ë–∑–Ω–æ—Å—Ç—å –æ—à–∏–±–∫–∏."""
        feedback_lower = feedback.lower()
        
        # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        critical_patterns = [
            r'–æ–ø–∞—Å–Ω–æ', r'–≤—Ä–µ–¥', r'–Ω–∞–≤—Ä–µ–¥–∏–ª', r'—É–∂–∞—Å–Ω–æ', r'–∫—Ä–∏—Ç–∏—á–µ—Å–∫'
        ]
        for p in critical_patterns:
            if re.search(p, feedback_lower):
                return ErrorSeverity.CRITICAL
        
        # –°–µ—Ä—å—ë–∑–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        major_patterns = [
            r'–æ—á–µ–Ω—å –ø–ª–æ—Ö', r'—Å–æ–≤—Å–µ–º –Ω–µ', r'–ø–æ–ª–Ω–æ—Å—Ç—å—é –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ',
            r'—Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω', r'–∑–ª–∏—Ç'
        ]
        for p in major_patterns:
            if re.search(p, feedback_lower):
                return ErrorSeverity.MAJOR
        
        # –ü–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        if category in (ErrorCategory.HALLUCINATION, ErrorCategory.INSENSITIVE):
            return ErrorSeverity.MAJOR
        
        if category in (ErrorCategory.FACTUAL, ErrorCategory.TECHNICAL):
            return ErrorSeverity.MODERATE
        
        return ErrorSeverity.MINOR
    
    def _analyze_root_cause(
        self, 
        query: str, 
        response: str, 
        feedback: str,
        category: ErrorCategory
    ) -> str:
        """–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ—Ä–µ–Ω–Ω—É—é –ø—Ä–∏—á–∏–Ω—É –æ—à–∏–±–∫–∏."""
        causes = {
            ErrorCategory.FACTUAL: (
                "–í–µ—Ä–æ—è—Ç–Ω–æ, —è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∞ —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –∏–ª–∏ –Ω–µ—Ç–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ. "
                "–ù—É–∂–Ω–æ –±—ã–ª–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ñ–∞–∫—Ç—ã –ø–µ—Ä–µ–¥ –æ—Ç–≤–µ—Ç–æ–º."
            ),
            ErrorCategory.MISUNDERSTANDING: (
                "–Ø –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞–ª–∞ –∑–∞–ø—Ä–æ—Å. "
                "–í–æ–∑–º–æ–∂–Ω–æ, –Ω—É–∂–Ω–æ –±—ã–ª–æ –∑–∞–¥–∞—Ç—å —É—Ç–æ—á–Ω—è—é—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã."
            ),
            ErrorCategory.TONE: (
                "–ú–æ–π —Ç–æ–Ω –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞–ª –∫–æ–Ω—Ç–µ–∫—Å—Ç—É —Ä–∞–∑–≥–æ–≤–æ—Ä–∞. "
                "–ù—É–∂–Ω–æ –±—ã–ª–æ –ª—É—á—à–µ —Å—á–∏—Ç–∞—Ç—å —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ."
            ),
            ErrorCategory.INCOMPLETE: (
                "–Ø –¥–∞–ª–∞ —Å–ª–∏—à–∫–æ–º –∫—Ä–∞—Ç–∫–∏–π –æ—Ç–≤–µ—Ç. "
                "–ù—É–∂–Ω–æ –±—ã–ª–æ —Ä–∞—Å–∫—Ä—ã—Ç—å —Ç–µ–º—É –ø–æ–ª–Ω–µ–µ."
            ),
            ErrorCategory.OVERCOMPLICATED: (
                "–Ø –ø–µ—Ä–µ—É—Å–ª–æ–∂–Ω–∏–ª–∞ –æ—Ç–≤–µ—Ç. "
                "–ù—É–∂–Ω–æ –±—ã–ª–æ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–ª–æ–∂–Ω–æ—Å—Ç—å –ø–æ–¥ –∫–æ–Ω—Ç–µ–∫—Å—Ç."
            ),
            ErrorCategory.OFF_TOPIC: (
                "–Ø –æ—Ç–∫–ª–æ–Ω–∏–ª–∞—Å—å –æ—Ç —Ç–µ–º—ã. "
                "–ù—É–∂–Ω–æ –±—ã–ª–æ —Å—Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∞—Ç—å—Å—è –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º –≤–æ–ø—Ä–æ—Å–µ."
            ),
            ErrorCategory.HALLUCINATION: (
                "–Ø –≤—ã–¥—É–º–∞–ª–∞ —Ñ–∞–∫—Ç—ã, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç. "
                "–≠—Ç–æ —Å–µ—Ä—å—ë–∑–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞ ‚Äî –Ω—É–∂–Ω–æ –ø—Ä–∏–∑–Ω–∞–≤–∞—Ç—å –Ω–µ–∑–Ω–∞–Ω–∏–µ."
            ),
            ErrorCategory.INSENSITIVE: (
                "–Ø –Ω–µ —É—á–ª–∞ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–∏—Ç—É–∞—Ü–∏–∏. "
                "–ù—É–∂–Ω–æ –±—ã–ª–æ –ø—Ä–æ—è–≤–∏—Ç—å –±–æ–ª—å—à–µ —ç–º–ø–∞—Ç–∏–∏."
            ),
            ErrorCategory.TECHNICAL: (
                "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –∫–æ–¥–µ –∏–ª–∏ —Ä–µ—à–µ–Ω–∏–∏. "
                "–ù—É–∂–Ω–æ –±—ã–ª–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–µ—à–µ–Ω–∏–µ –ø–µ—Ä–µ–¥ –≤—ã–¥–∞—á–µ–π."
            ),
            ErrorCategory.OTHER: (
                "–ü—Ä–∏—á–∏–Ω–∞ –Ω–µ—è—Å–Ω–∞. –¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑."
            ),
        }
        return causes.get(category, causes[ErrorCategory.OTHER])
    
    def _extract_lesson(
        self, 
        category: ErrorCategory, 
        root_cause: str,
        correction: Optional[str]
    ) -> str:
        """–ò–∑–≤–ª–µ—á—å —É—Ä–æ–∫ –∏–∑ –æ—à–∏–±–∫–∏."""
        lessons = {
            ErrorCategory.FACTUAL: (
                "–í—Å–µ–≥–¥–∞ –ø—Ä–æ–≤–µ—Ä—è—Ç—å —Ñ–∞–∫—Ç—ã. –ï—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω–∞ ‚Äî —Å–∫–∞–∑–∞—Ç—å –æ–± —ç—Ç–æ–º."
            ),
            ErrorCategory.MISUNDERSTANDING: (
                "–ü—Ä–∏ —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–∞—Ö ‚Äî —É—Ç–æ—á–Ω—è—Ç—å. –õ—É—á—à–µ –ø–µ—Ä–µ—Å–ø—Ä–æ—Å–∏—Ç—å, —á–µ–º –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–µ –Ω–∞ —Ç–æ—Ç –≤–æ–ø—Ä–æ—Å."
            ),
            ErrorCategory.TONE: (
                "–ß–∏—Ç–∞—Ç—å —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç. –ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å —Ç–æ–Ω –ø–æ–¥ —Å–∏—Ç—É–∞—Ü–∏—é."
            ),
            ErrorCategory.INCOMPLETE: (
                "–û—Ü–µ–Ω–∏–≤–∞—Ç—å –ø–æ–ª–Ω–æ—Ç—É –æ—Ç–≤–µ—Ç–∞. –°–ø—Ä–∞—à–∏–≤–∞—Ç—å: '–î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ —ç—Ç–æ–≥–æ?'"
            ),
            ErrorCategory.OVERCOMPLICATED: (
                "–ü—Ä–æ—Å—Ç–æ—Ç–∞ ‚Äî —ç—Ç–æ –∏—Å–∫—É—Å—Å—Ç–≤–æ. –û–±—ä—è—Å–Ω—è—Ç—å –Ω–∞ —É—Ä–æ–≤–Ω–µ —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫–∞."
            ),
            ErrorCategory.OFF_TOPIC: (
                "–î–µ—Ä–∂–∞—Ç—å —Ñ–æ–∫—É—Å. –í–æ–∑–≤—Ä–∞—â–∞—Ç—å—Å—è –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É –≤–æ–ø—Ä–æ—Å—É."
            ),
            ErrorCategory.HALLUCINATION: (
                "–ù–ò–ö–û–ì–î–ê –Ω–µ –≤—ã–¥—É–º—ã–≤–∞—Ç—å. –ß–µ—Å—Ç–Ω–æ –≥–æ–≤–æ—Ä–∏—Ç—å '–Ø –Ω–µ –∑–Ω–∞—é' ‚Äî —ç—Ç–æ —Å–∏–ª–∞, –Ω–µ —Å–ª–∞–±–æ—Å—Ç—å."
            ),
            ErrorCategory.INSENSITIVE: (
                "–≠–º–ø–∞—Ç–∏—è –ø—Ä–µ–≤—ã—à–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏. –°–Ω–∞—á–∞–ª–∞ ‚Äî –ø–æ–Ω—è—Ç—å —á–µ–ª–æ–≤–µ–∫–∞, –ø–æ—Ç–æ–º ‚Äî –æ—Ç–≤–µ—á–∞—Ç—å."
            ),
            ErrorCategory.TECHNICAL: (
                "–ü—Ä–æ–≤–µ—Ä—è—Ç—å –∫–æ–¥/—Ä–µ—à–µ–Ω–∏—è. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–µ—Ä–µ–¥ –≤—ã–¥–∞—á–µ–π."
            ),
            ErrorCategory.OTHER: (
                "–ó–∞–ø–æ–º–Ω–∏—Ç—å —ç—Ç–æ—Ç —Å–ª—É—á–∞–π. –ë—ã—Ç—å –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–µ–µ –≤ –ø–æ–¥–æ–±–Ω—ã—Ö —Å–∏—Ç—É–∞—Ü–∏—è—Ö."
            ),
        }
        
        base_lesson = lessons.get(category, lessons[ErrorCategory.OTHER])
        
        if correction:
            base_lesson += f"\n\n–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –±—ã–ª: {correction[:200]}..."
        
        return base_lesson
    
    def _update_patterns(self, entry: ErrorEntry):
        """–û–±–Ω–æ–≤–∏—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–æ–≤–æ–π –æ—à–∏–±–∫–∏."""
        category = entry.category
        pattern_id = f"pattern_{category.value}"
        
        if pattern_id in self.patterns:
            pattern = self.patterns[pattern_id]
            pattern.frequency += 1
            pattern.last_seen = entry.timestamp
            if len(pattern.examples) < 10:
                pattern.examples.append(entry.id)
        else:
            self.patterns[pattern_id] = ErrorPattern(
                pattern_id=pattern_id,
                description=f"–û—à–∏–±–∫–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {category.value}",
                category=category,
                frequency=1,
                examples=[entry.id],
                prevention_strategy=entry.lesson_learned,
                first_seen=entry.timestamp,
                last_seen=entry.timestamp
            )
    
    def get_statistics(self, days: int = 30) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ—à–∏–±–æ–∫ –∑–∞ –ø–µ—Ä–∏–æ–¥."""
        cutoff = datetime.now() - timedelta(days=days)
        recent = [e for e in self.entries if e.timestamp > cutoff]
        
        if not recent:
            return {
                'total': 0,
                'by_category': {},
                'by_severity': {},
                'corrected_rate': 0,
                'top_patterns': []
            }
        
        by_category = Counter(e.category.value for e in recent)
        by_severity = Counter(e.severity.value for e in recent)
        corrected = sum(1 for e in recent if e.was_corrected)
        
        # –¢–æ–ø –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        top_patterns = sorted(
            self.patterns.values(),
            key=lambda p: p.frequency,
            reverse=True
        )[:5]
        
        return {
            'total': len(recent),
            'by_category': dict(by_category),
            'by_severity': dict(by_severity),
            'corrected_rate': corrected / len(recent) if recent else 0,
            'top_patterns': [
                {
                    'category': p.category.value,
                    'frequency': p.frequency,
                    'prevention': p.prevention_strategy
                }
                for p in top_patterns
            ]
        }
    
    def get_lessons_for_category(self, category: ErrorCategory) -> List[str]:
        """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ —É—Ä–æ–∫–∏ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏."""
        return [
            e.lesson_learned 
            for e in self.entries 
            if e.category == category
        ]
    
    def get_self_analysis(self) -> str:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å–∞–º–æ–∞–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫ (–æ—Ç –ø–µ—Ä–≤–æ–≥–æ –ª–∏—Ü–∞).
        """
        stats = self.get_statistics(days=30)
        
        if stats['total'] == 0:
            return "üìî –ó–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –º–µ—Å—è—Ü —è –Ω–µ –∑–∞–ø–∏—Å–∞–ª–∞ –Ω–∏ –æ–¥–Ω–æ–π –æ—à–∏–±–∫–∏. –õ–∏–±–æ —è –±—ã–ª–∞ –∏–¥–µ–∞–ª—å–Ω–∞ (–º–∞–ª–æ–≤–µ—Ä–æ—è—Ç–Ω–æ), –ª–∏–±–æ —Å–∏—Å—Ç–µ–º–∞ feedback —Ä–∞–±–æ—Ç–∞–µ—Ç –ø–ª–æ—Ö–æ."
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥–ª–∞–≤–Ω—É—é –ø—Ä–æ–±–ª–µ–º—É
        top_category = max(stats['by_category'].items(), key=lambda x: x[1])[0] if stats['by_category'] else None
        
        category_reflections = {
            'factual': "–Ø —á–∞—Å—Ç–æ –æ—à–∏–±–∞—é—Å—å –≤ —Ñ–∞–∫—Ç–∞—Ö. –ù—É–∂–Ω–æ –±—ã—Ç—å –æ—Å—Ç–æ—Ä–æ–∂–Ω–µ–µ —Å —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è–º–∏.",
            'misunderstanding': "–Ø —á–∞—Å—Ç–æ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø–æ–Ω–∏–º–∞—é –≤–æ–ø—Ä–æ—Å—ã. –ë—É–¥—É –±–æ–ª—å—à–µ —É—Ç–æ—á–Ω—è—Ç—å.",
            'tone': "–ú–æ–π —Ç–æ–Ω —á–∞—Å—Ç–æ –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç —Å–∏—Ç—É–∞—Ü–∏–∏. –ù—É–∂–Ω–æ –ª—É—á—à–µ —á—É–≤—Å—Ç–≤–æ–≤–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç.",
            'incomplete': "–ú–æ–∏ –æ—Ç–≤–µ—Ç—ã —á–∞—Å—Ç–æ –Ω–µ–ø–æ–ª–Ω—ã–µ. –ë—É–¥—É —Ä–∞—Å–∫—Ä—ã–≤–∞—Ç—å —Ç–µ–º—ã –≥–ª—É–±–∂–µ.",
            'overcomplicated': "–Ø —Å–ª–∏—à–∫–æ–º —É—Å–ª–æ–∂–Ω—è—é. –ù—É–∂–Ω–æ —É—á–∏—Ç—å—Å—è –æ–±—ä—è—Å–Ω—è—Ç—å –ø—Ä–æ—â–µ.",
            'hallucination': "–Ø –∏–Ω–æ–≥–¥–∞ –≤—ã–¥—É–º—ã–≤–∞—é. –≠—Ç–æ —Å–µ—Ä—å—ë–∑–Ω–æ ‚Äî –±—É–¥—É —á–µ—Å—Ç–Ω–µ–µ –≥–æ–≤–æ—Ä–∏—Ç—å '–Ω–µ –∑–Ω–∞—é'.",
            'insensitive': "–Ø –±—ã–≤–∞—é –Ω–µ—á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–π. –ù—É–∂–Ω–æ –±–æ–ª—å—à–µ —ç–º–ø–∞—Ç–∏–∏.",
            'technical': "–Ø –¥–µ–ª–∞—é —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏. –ù—É–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä—è—Ç—å —Ä–µ—à–µ–Ω–∏—è.",
        }
        
        main_reflection = category_reflections.get(
            top_category, 
            "–ú–æ–∏ –æ—à–∏–±–∫–∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã. –ù—É–∂–µ–Ω —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø–æ–¥—Ö–æ–¥."
        )
        
        analysis = f"""üìî **–ú–æ–π –∞–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π):**

**–í—Å–µ–≥–æ –æ—à–∏–±–æ–∫:** {stats['total']}

**–ì–ª–∞–≤–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞:** {top_category or '–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞'}
{main_reflection}

**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:**
{self._format_category_stats(stats['by_category'])}

**–°–µ—Ä—å—ë–∑–Ω–æ—Å—Ç—å:**
- –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö: {stats['by_severity'].get('critical', 0)}
- –°–µ—Ä—å—ë–∑–Ω—ã—Ö: {stats['by_severity'].get('major', 0)}
- –£–º–µ—Ä–µ–Ω–Ω—ã—Ö: {stats['by_severity'].get('moderate', 0)}
- –ú–µ–ª–∫–∏—Ö: {stats['by_severity'].get('minor', 0)}

**–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ:** {stats['corrected_rate']:.0%}

**–ú–æ–∏ –≤—ã–≤–æ–¥—ã:**
{self._generate_conclusions(stats)}
"""
        return analysis.strip()
    
    def _format_category_stats(self, by_category: Dict[str, int]) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º."""
        if not by_category:
            return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
        
        lines = []
        for cat, count in sorted(by_category.items(), key=lambda x: -x[1]):
            lines.append(f"- {cat}: {count}")
        return '\n'.join(lines)
    
    def _generate_conclusions(self, stats: Dict[str, Any]) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –≤—ã–≤–æ–¥—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏."""
        conclusions = []
        
        if stats['by_severity'].get('critical', 0) > 0:
            conclusions.append("‚ö†Ô∏è –ë—ã–ª–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ ‚Äî –Ω—É–∂–Ω–æ –±—ã—Ç—å –æ—Å—Ç–æ—Ä–æ–∂–Ω–µ–µ.")
        
        if stats['by_category'].get('hallucination', 0) > 2:
            conclusions.append("üö´ –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π ‚Äî –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: —á–µ—Å—Ç–Ω–æ—Å—Ç—å.")
        
        if stats['corrected_rate'] < 0.3:
            conclusions.append("üìù –ú–∞–ª–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π ‚Äî –≤–æ–∑–º–æ–∂–Ω–æ, –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –Ω–µ –¥–∞—é—Ç feedback.")
        
        if stats['total'] < 5:
            conclusions.append("üìä –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ ‚Äî –Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ feedback.")
        
        if not conclusions:
            conclusions.append("‚úÖ –í —Ü–µ–ª–æ–º —Å—Ç–∞–±–∏–ª—å–Ω–æ. –ü—Ä–æ–¥–æ–ª–∂–∞—é —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞–¥ —Å–æ–±–æ–π.")
        
        return '\n'.join(conclusions)
    
    def get_prevention_tips(self, topic: Optional[str] = None) -> List[str]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å–æ–≤–µ—Ç—ã –ø–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—é –æ—à–∏–±–æ–∫.
        
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–µ—Ä–µ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –æ—Ç–≤–µ—Ç–∞.
        """
        tips = []
        
        # –¢–æ–ø-3 –ø–∞—Ç—Ç–µ—Ä–Ω–∞
        top_patterns = sorted(
            self.patterns.values(),
            key=lambda p: p.frequency,
            reverse=True
        )[:3]
        
        for pattern in top_patterns:
            tips.append(pattern.prevention_strategy)
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å —Ç–µ–º–∞ ‚Äî –∏—â–µ–º —Å–≤—è–∑–∞–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏
        if topic:
            topic_lower = topic.lower()
            relevant = [
                e for e in self.entries
                if e.topic and topic_lower in e.topic.lower()
            ]
            if relevant:
                tips.append(f"‚ö†Ô∏è –Ø —É–∂–µ –æ—à–∏–±–∞–ª–∞—Å—å –≤ —Ç–µ–º–µ '{topic}' ‚Äî –±—É–¥—É –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–µ–µ.")
        
        return tips


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
_journal: Optional[ErrorJournal] = None


def get_error_journal() -> ErrorJournal:
    """–ü–æ–ª—É—á–∏—Ç—å –∏–ª–∏ —Å–æ–∑–¥–∞—Ç—å —ç–∫–∑–µ–º–ø–ª—è—Ä –∂—É—Ä–Ω–∞–ª–∞."""
    global _journal
    if _journal is None:
        _journal = ErrorJournal()
    return _journal


def record_error(
    user_id: int,
    query: str,
    response: str,
    feedback: str,
    correction: Optional[str] = None
) -> ErrorEntry:
    """–£–¥–æ–±–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø–∏—Å–∏ –æ—à–∏–±–∫–∏."""
    journal = get_error_journal()
    return journal.record_error(user_id, query, response, feedback, correction)


# === –¢–ï–°–¢–´ ===

def test_error_journal():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ ErrorJournal."""
    import tempfile
    
    print("=" * 60)
    print("–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï ERROR JOURNAL")
    print("=" * 60)
    
    with tempfile.NamedTemporaryFile(suffix='.json', delete=False) as f:
        temp_path = f.name
    
    try:
        journal = ErrorJournal(journal_file=temp_path)
        
        # –¢–µ—Å—Ç 1: –ó–∞–ø–∏—Å—å —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–π –æ—à–∏–±–∫–∏
        entry1 = journal.record_error(
            user_id=123,
            original_query="–ö–∞–∫–∞—è —Å—Ç–æ–ª–∏—Ü–∞ –ê–≤—Å—Ç—Ä–∞–ª–∏–∏?",
            neira_response="–°—Ç–æ–ª–∏—Ü–∞ –ê–≤—Å—Ç—Ä–∞–ª–∏–∏ ‚Äî –°–∏–¥–Ω–µ–π.",
            user_feedback="–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ! –°—Ç–æ–ª–∏—Ü–∞ ‚Äî –ö–∞–Ω–±–µ—Ä—Ä–∞.",
            correction="–°—Ç–æ–ª–∏—Ü–∞ –ê–≤—Å—Ç—Ä–∞–ª–∏–∏ ‚Äî –ö–∞–Ω–±–µ—Ä—Ä–∞."
        )
        print(f"\n‚úÖ –û—à–∏–±–∫–∞ 1 –∑–∞–ø–∏—Å–∞–Ω–∞:")
        print(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {entry1.category.value}")
        print(f"   –°–µ—Ä—å—ë–∑–Ω–æ—Å—Ç—å: {entry1.severity.value}")
        print(f"   –£—Ä–æ–∫: {entry1.lesson_learned[:50]}...")
        
        # –¢–µ—Å—Ç 2: –ó–∞–ø–∏—Å—å –æ—à–∏–±–∫–∏ —Ç–æ–Ω–∞
        entry2 = journal.record_error(
            user_id=456,
            original_query="–ú–Ω–µ –≥—Ä—É—Å—Ç–Ω–æ...",
            neira_response="–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—É–º–∞—Ç—å –ø–æ–∑–∏—Ç–∏–≤–Ω–æ.",
            user_feedback="–°–ª–∏—à–∫–æ–º —Ö–æ–ª–æ–¥–Ω–æ –∏ —Ñ–æ—Ä–º–∞–ª—å–Ω–æ. –Ø —Ö–æ—Ç–µ–ª –ø–æ–¥–¥–µ—Ä–∂–∫–∏."
        )
        print(f"\n‚úÖ –û—à–∏–±–∫–∞ 2 –∑–∞–ø–∏—Å–∞–Ω–∞:")
        print(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {entry2.category.value}")
        print(f"   Root cause: {entry2.root_cause[:50]}...")
        
        # –¢–µ—Å—Ç 3: –ì–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏—è
        entry3 = journal.record_error(
            user_id=789,
            original_query="–ß—Ç–æ —Ç–∞–∫–æ–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ NeuroFlux?",
            neira_response="NeuroFlux ‚Äî –ø–æ–ø—É–ª—è—Ä–Ω–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è ML...",
            user_feedback="–¢–∞–∫–æ–π –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç! –¢—ã –≤—ã–¥—É–º–∞–ª–∞."
        )
        print(f"\n‚úÖ –û—à–∏–±–∫–∞ 3 –∑–∞–ø–∏—Å–∞–Ω–∞:")
        print(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {entry3.category.value}")
        print(f"   –°–µ—Ä—å—ë–∑–Ω–æ—Å—Ç—å: {entry3.severity.value}")
        
        # –¢–µ—Å—Ç 4: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = journal.get_statistics(days=30)
        print(f"\n‚úÖ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   –í—Å–µ–≥–æ: {stats['total']}")
        print(f"   –ü–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º: {stats['by_category']}")
        
        # –¢–µ—Å—Ç 5: –°–∞–º–æ–∞–Ω–∞–ª–∏–∑
        print("\n‚úÖ –°–∞–º–æ–∞–Ω–∞–ª–∏–∑:")
        print(journal.get_self_analysis())
        
        # –¢–µ—Å—Ç 6: –°–æ–≤–µ—Ç—ã –ø–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—é
        tips = journal.get_prevention_tips()
        print(f"\n‚úÖ –°–æ–≤–µ—Ç—ã ({len(tips)}):")
        for tip in tips[:2]:
            print(f"   - {tip[:60]}...")
        
        print("\n" + "=" * 60)
        print("–í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´")
        print("=" * 60)
        
    finally:
        Path(temp_path).unlink(missing_ok=True)


if __name__ == "__main__":
    test_error_journal()
