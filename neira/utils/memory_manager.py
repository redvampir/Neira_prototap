"""
üß† –ï–¥–∏–Ω—ã–π –º–æ–¥—É–ª—å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–∞–º—è—Ç—å—é Neira

–û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª:
- memory_cleanup.py
- aggressive_memory_cleanup.py  
- clean_memory_duplicates.py
- memory_consolidator.py

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    from neira.utils.memory_manager import MemoryManager
    
    manager = MemoryManager()
    manager.full_cleanup()
    manager.find_duplicates()
    manager.consolidate()
"""

import json
import logging
import shutil
from collections import defaultdict
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any

from neira.config import (
    MEMORY_MAX_LONG_TERM,
    MEMORY_MAX_SHORT_TERM,
    MEMORY_CLEANUP_AGE_DAYS,
    MEMORY_MIN_CONFIDENCE,
)

logger = logging.getLogger(__name__)


class MemoryManager:
    """
    –ú–µ–Ω–µ–¥–∂–µ—Ä –ø–∞–º—è—Ç–∏ Neira.
    
    –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç:
    - –û—á–∏—Å—Ç–∫—É —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∑–∞–ø–∏—Å–µ–π
    - –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    - –ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—é –ø–∞–º—è—Ç–∏
    - –ë—ç–∫–∞–ø—ã
    """
    
    def __init__(
        self,
        memory_file: str = "neira_memory.json",
        backup_dir: str = "memory_backups"
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –ø–∞–º—è—Ç–∏.
        
        Args:
            memory_file: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –ø–∞–º—è—Ç–∏
            backup_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –±—ç–∫–∞–ø–æ–≤
        """
        self.memory_file = Path(memory_file)
        self.backup_dir = Path(backup_dir)
        self.backup_dir.mkdir(exist_ok=True)
    
    def load(self) -> list[dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–∞–º—è—Ç—å –∏–∑ —Ñ–∞–π–ª–∞."""
        if not self.memory_file.exists():
            logger.warning(f"–§–∞–π–ª –ø–∞–º—è—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {self.memory_file}")
            return []
        
        try:
            with open(self.memory_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except json.JSONDecodeError as e:
            logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –ø–∞–º—è—Ç–∏: {e}")
            return []
    
    def save(self, memories: list[dict[str, Any]]) -> None:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–∞–º—è—Ç—å –≤ —Ñ–∞–π–ª."""
        with open(self.memory_file, 'w', encoding='utf-8') as f:
            json.dump(memories, f, ensure_ascii=False, indent=2)
        logger.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(memories)} –∑–∞–ø–∏—Å–µ–π")
    
    def create_backup(self) -> Path:
        """
        –°–æ–∑–¥–∞—ë—Ç –±—ç–∫–∞–ø –ø–∞–º—è—Ç–∏.
        
        Returns:
            –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –±—ç–∫–∞–ø–∞
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_path = self.backup_dir / f"memory_backup_{timestamp}.json"
        
        if self.memory_file.exists():
            shutil.copy(self.memory_file, backup_path)
            logger.info(f"–ë—ç–∫–∞–ø —Å–æ–∑–¥–∞–Ω: {backup_path}")
        
        return backup_path
    
    def find_duplicates(self) -> list[tuple[int, str]]:
        """
        –ù–∞—Ö–æ–¥–∏—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –≤ –ø–∞–º—è—Ç–∏.
        
        Returns:
            –°–ø–∏—Å–æ–∫ (–∏–Ω–¥–µ–∫—Å, —Ç–µ–∫—Å—Ç) –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        """
        memories = self.load()
        seen_texts: dict[str, int] = {}
        duplicates: list[tuple[int, str]] = []
        
        for i, entry in enumerate(memories):
            text = entry.get('text', '').strip().lower()
            
            if text in seen_texts:
                duplicates.append((i, text[:70]))
            else:
                seen_texts[text] = i
        
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {len(duplicates)}")
        return duplicates
    
    def find_loops(self, threshold: int = 5) -> list[tuple[str, int]]:
        """
        –ù–∞—Ö–æ–¥–∏—Ç –∑–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏—è (–º–Ω–æ–≥–æ –∑–∞–ø–∏—Å–µ–π –∑–∞ –∫–æ—Ä–æ—Ç–∫–∏–π –ø–µ—Ä–∏–æ–¥).
        
        Args:
            threshold: –ü–æ—Ä–æ–≥ –∑–∞–ø–∏—Å–µ–π –≤ –º–∏–Ω—É—Ç—É –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏
            
        Returns:
            –°–ø–∏—Å–æ–∫ (timestamp, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ) –∑–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏–π
        """
        memories = self.load()
        time_buckets: dict[str, list[int]] = defaultdict(list)
        
        for i, entry in enumerate(memories):
            ts = entry.get('timestamp', '')
            if ts:
                minute_key = ts[:16]  # YYYY-MM-DDTHH:MM
                time_buckets[minute_key].append(i)
        
        loops = [
            (minute, len(indices))
            for minute, indices in time_buckets.items()
            if len(indices) > threshold
        ]
        
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ –∑–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏–π: {len(loops)}")
        return loops
    
    def cleanup_old(self, keep_days: int = MEMORY_CLEANUP_AGE_DAYS) -> int:
        """
        –£–¥–∞–ª—è–µ—Ç –∑–∞–ø–∏—Å–∏ —Å—Ç–∞—Ä—à–µ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞.
        
        Args:
            keep_days: –°–∫–æ–ª—å–∫–æ –¥–Ω–µ–π —Ö—Ä–∞–Ω–∏—Ç—å
            
        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª—ë–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
        """
        memories = self.load()
        cutoff = datetime.now() - timedelta(days=keep_days)
        
        original_count = len(memories)
        filtered = []
        
        for entry in memories:
            ts_str = entry.get('timestamp', '')
            try:
                ts = datetime.fromisoformat(ts_str.replace('Z', '+00:00'))
                if ts.replace(tzinfo=None) > cutoff:
                    filtered.append(entry)
            except (ValueError, AttributeError):
                # –ï—Å–ª–∏ –Ω–µ—Ç timestamp ‚Äî –æ—Å—Ç–∞–≤–ª—è–µ–º
                filtered.append(entry)
        
        removed = original_count - len(filtered)
        
        if removed > 0:
            self.save(filtered)
            logger.info(f"–£–¥–∞–ª–µ–Ω–æ —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π: {removed}")
        
        return removed
    
    def cleanup_low_confidence(
        self, 
        min_confidence: float = MEMORY_MIN_CONFIDENCE
    ) -> int:
        """
        –£–¥–∞–ª—è–µ—Ç –∑–∞–ø–∏—Å–∏ —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é.
        
        Args:
            min_confidence: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            
        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª—ë–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
        """
        memories = self.load()
        original_count = len(memories)
        
        filtered = [
            m for m in memories
            if m.get('confidence', 1.0) >= min_confidence
        ]
        
        removed = original_count - len(filtered)
        
        if removed > 0:
            self.save(filtered)
            logger.info(f"–£–¥–∞–ª–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é: {removed}")
        
        return removed
    
    def remove_duplicates(self) -> int:
        """
        –£–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –∏–∑ –ø–∞–º—è—Ç–∏.
        
        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª—ë–Ω–Ω—ã—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        """
        memories = self.load()
        seen_texts: set[str] = set()
        unique: list[dict[str, Any]] = []
        
        for entry in memories:
            text = entry.get('text', '').strip().lower()
            
            if text not in seen_texts:
                seen_texts.add(text)
                unique.append(entry)
        
        removed = len(memories) - len(unique)
        
        if removed > 0:
            self.save(unique)
            logger.info(f"–£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {removed}")
        
        return removed
    
    def consolidate(
        self,
        max_long_term: int = MEMORY_MAX_LONG_TERM,
        max_short_term: int = MEMORY_MAX_SHORT_TERM
    ) -> dict[str, int]:
        """
        –ö–æ–Ω—Å–æ–ª–∏–¥–∏—Ä—É–µ—Ç –ø–∞–º—è—Ç—å –¥–æ –∑–∞–¥–∞–Ω–Ω—ã—Ö –ª–∏–º–∏—Ç–æ–≤.
        
        Args:
            max_long_term: –ú–∞–∫—Å–∏–º—É–º –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
            max_short_term: –ú–∞–∫—Å–∏–º—É–º –∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
            
        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏–∏
        """
        memories = self.load()
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ —Ç–∏–ø—É
        long_term = [m for m in memories if m.get('memory_type') == 'long_term']
        short_term = [m for m in memories if m.get('memory_type') == 'short_term']
        other = [m for m in memories if m.get('memory_type') not in ('long_term', 'short_term')]
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏/–≤—Ä–µ–º–µ–Ω–∏ –∏ –æ–±—Ä–µ–∑–∞–µ–º
        long_term.sort(key=lambda x: x.get('confidence', 0), reverse=True)
        short_term.sort(key=lambda x: x.get('timestamp', ''), reverse=True)
        
        stats = {
            'long_term_removed': max(0, len(long_term) - max_long_term),
            'short_term_removed': max(0, len(short_term) - max_short_term),
        }
        
        consolidated = (
            long_term[:max_long_term] + 
            short_term[:max_short_term] + 
            other
        )
        
        self.save(consolidated)
        logger.info(f"–ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è: {stats}")
        
        return stats
    
    def full_cleanup(self, create_backup: bool = True) -> dict[str, int]:
        """
        –ü–æ–ª–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏.
        
        –í—ã–ø–æ–ª–Ω—è–µ—Ç:
        1. –ë—ç–∫–∞–ø
        2. –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π
        3. –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        4. –£–¥–∞–ª–µ–Ω–∏–µ –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        5. –ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—é
        
        Args:
            create_backup: –°–æ–∑–¥–∞–≤–∞—Ç—å –ª–∏ –±—ç–∫–∞–ø –ø–µ—Ä–µ–¥ –æ—á–∏—Å—Ç–∫–æ–π
            
        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—á–∏—Å—Ç–∫–∏
        """
        logger.info("=" * 50)
        logger.info("üßπ –ü–û–õ–ù–ê–Ø –û–ß–ò–°–¢–ö–ê –ü–ê–ú–Ø–¢–ò")
        logger.info("=" * 50)
        
        if create_backup:
            self.create_backup()
        
        stats = {
            'old_removed': self.cleanup_old(),
            'duplicates_removed': self.remove_duplicates(),
            'low_confidence_removed': self.cleanup_low_confidence(),
        }
        
        consolidate_stats = self.consolidate()
        stats.update(consolidate_stats)
        
        logger.info(f"–û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {stats}")
        return stats
    
    def get_stats(self) -> dict[str, Any]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–∞–º—è—Ç–∏.
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        """
        memories = self.load()
        
        by_type: dict[str, int] = defaultdict(int)
        for m in memories:
            by_type[m.get('memory_type', 'unknown')] += 1
        
        return {
            'total_records': len(memories),
            'by_type': dict(by_type),
            'duplicates': len(self.find_duplicates()),
            'loops': len(self.find_loops()),
            'file_size_kb': (
                self.memory_file.stat().st_size / 1024 
                if self.memory_file.exists() 
                else 0
            ),
        }


# CLI –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∏–∑ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
def main():
    """CLI –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–∞–º—è—Ç—å—é."""
    import argparse
    
    parser = argparse.ArgumentParser(description='–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç—å—é Neira')
    parser.add_argument(
        '--action', 
        choices=['cleanup', 'stats', 'duplicates', 'backup'],
        default='stats',
        help='–î–µ–π—Å—Ç–≤–∏–µ'
    )
    parser.add_argument(
        '--memory-file',
        default='neira_memory.json',
        help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –ø–∞–º—è—Ç–∏'
    )
    
    args = parser.parse_args()
    
    logging.basicConfig(level=logging.INFO)
    manager = MemoryManager(args.memory_file)
    
    if args.action == 'cleanup':
        stats = manager.full_cleanup()
        print(f"–û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {stats}")
    elif args.action == 'stats':
        stats = manager.get_stats()
        print(json.dumps(stats, indent=2, ensure_ascii=False))
    elif args.action == 'duplicates':
        dups = manager.find_duplicates()
        print(f"–ù–∞–π–¥–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {len(dups)}")
    elif args.action == 'backup':
        path = manager.create_backup()
        print(f"–ë—ç–∫–∞–ø —Å–æ–∑–¥–∞–Ω: {path}")


if __name__ == '__main__':
    main()
