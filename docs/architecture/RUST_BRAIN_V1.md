# Rust Brain V1 — каркас спецификации

> Цель документа: зафиксировать первую версию архитектурных ожиданий для Rust‑ядра мозга Neira.

## Область ответственности

- Детерминированные форматы данных и стабильные инварианты.
- Понятные границы между памятью, путями и «мудростью».
- Стандартизированная сериализация для обмена и миграций.

## Принципы

- Глоссарий терминов архитектуры: [RUST_BRAIN_GLOSSARY.md](RUST_BRAIN_GLOSSARY.md).

## Критерии автономии и приемки

- **Метрика автономии:** ≥ 70% запросов должны обрабатываться без LLM (по счетчику `offline_success / total_requests`).
- **Допустимая латентность по слоям (p95):**
  - Входная нормализация: ≤ 20 мс.
  - Маршрутизация клетки/органа: ≤ 30 мс.
  - Память (чтение): ≤ 50 мс, запись: ≤ 80 мс.
  - Планирование/реакции: ≤ 60 мс.
  - Суммарный локальный бюджет без LLM: ≤ 180 мс.
- **Правила fallback:**
  - LLM вызывается только после двух неудачных локальных стратегий.
  - При деградации (ошибка памяти/маршрута) переход в упрощенный режим без LLM и запись причины в лог.
  - Если суммарная латентность превышает 180 мс, блок LLM запрещен и возвращается локальный ответ с меткой `degraded`.
- **Минимальные тестовые сценарии:**
  - *Ручные:* 3 типовых диалога (FAQ, команда, ошибка ввода) без LLM; 1 сценарий деградации (отключение памяти).
  - *Автоматизированные:* smoke для загрузки конфигурации; p95-латентность по слоям; проверка доли автономии ≥ 70% на 100 запросах.

## Офлайн-режим и зависимости

- **Офлайн-режим обязателен:** мозг должен отвечать при отсутствии сети, даже в деградированном качестве.
- **Критический путь без сети:** intent → router → pathways → memory → synth должны работать без внешних сервисов.
- **LLM и внешние провайдеры** допускаются только как необязательный fallback и не должны ломать p95-бюджет локальной обработки.
- **Поведение при деградации:**
  - фиксируем причину (нет сети/недоступен сервис/таймаут);
  - возвращаем локальный ответ с меткой `degraded`;
  - не блокируем диалог ожиданием внешнего сервиса.

## Архитектурный стиль

- **Выбранный стиль:** гибрид (монолитное ядро + подключаемые адаптеры/плагины).
- **Ядро:** intent → router → pathways → memory → synth — всегда локально, без сети.
- **Адаптеры:** внешние провайдеры и сервисы подключаются как необязательные fallback‑модули.
- **Цель гибрида:** сохранить офлайн‑устойчивость и автономность, не блокируя развитие интеграций.

## Интерфейсы (первый контур)

- **CLI (обязателен):** отладка мозга, локальные тесты, режим офлайн по умолчанию.
- **HTTP API (рекомендуется):** стабильный контракт для интеграций и инструментов.
- **Telegram (вторая очередь):** только после стабилизации ядра и метрик автономности.
- **UI (веб/desktop):** опционально, после фиксации основных сценариев.

## Конкретные тестовые сценарии (датасет валидации)

### Сценарий 1: Приветствие (без LLM)
```
Вход: "Привет"
Ожидаемый Intent: { name: "greeting", confidence: ≥0.9 }
Ожидаемый ответ: "Привет! Чем могу помочь?" (или вариации)
LLM: НЕ вызывается
Latency: ≤50ms
```

### Сценарий 2: Вопрос из памяти (без LLM)
```
Вход: "Как тебя зовут?"
Ожидаемый Intent: { name: "identity_question", confidence: ≥0.8 }
Ожидаемый ответ: "Меня зовут Нейра." (из wisdom)
LLM: НЕ вызывается
Latency: ≤80ms
```

### Сценарий 3: Простая команда (без LLM)
```
Вход: "/help"
Ожидаемый Intent: { name: "command", confidence: 1.0 }
Ожидаемый ответ: список команд из шаблона
LLM: НЕ вызывается
Latency: ≤30ms
```

### Сценарий 4: Ошибка ввода (без LLM)
```
Вход: "аывоаывоаыв"
Ожидаемый Intent: { name: "unknown", confidence: ≤0.3 }
Ожидаемый ответ: "Не совсем понимаю. Можешь уточнить?"
LLM: НЕ вызывается (degraded локальный ответ)
Latency: ≤50ms
```

### Сценарий 5: Сложный вопрос (с LLM fallback)
```
Вход: "Объясни квантовую запутанность простыми словами"
Ожидаемый Intent: { name: "explanation_request", confidence: ≥0.7 }
Ожидаемый путь: 2 локальных попытки → LLM fallback
LLM: Вызывается (mistral.rs)
Latency: ≤500ms (с LLM)
```

### Сценарий 6: Деградация (отключена память)
```
Условие: MemoryStore недоступен
Вход: "Что я спрашивал вчера?"
Ожидаемый ответ: "Извини, память временно недоступна." + метка `degraded`
LLM: НЕ вызывается
Latency: ≤30ms
```

### Сценарий 7: Офлайн + сложный запрос
```
Условие: Нет сети, LLM недоступен
Вход: "Напиши функцию сортировки на Python"
Ожидаемый путь: 2 локальных попытки → degraded
Ожидаемый ответ: шаблонный код или "Сейчас не могу сгенерировать код, попробуй позже."
Latency: ≤180ms
```

## Тестовый датасет (100 запросов)

| Категория | Количество | Целевая автономия |
|-----------|------------|-------------------|
| Приветствия | 10 | 100% |
| Команды | 15 | 100% |
| FAQ (из wisdom) | 20 | 95% |
| Простые вопросы | 25 | 80% |
| Сложные вопросы | 20 | 30% |
| Ошибочный ввод | 10 | 100% |

**Итого целевая автономия: ≥70%** (70 из 100 без LLM)

## Следующие артефакты

- [RUST_BRAIN_DATA_FORMATS.md](RUST_BRAIN_DATA_FORMATS.md) — схемы данных, сериализация и правила версионирования.
- [RUST_BRAIN_CRATES.md](RUST_BRAIN_CRATES.md) — состав модулей, границы ответственности и минимальные интерфейсы.
- [RUST_BRAIN_MIGRATION_ROADMAP.md](RUST_BRAIN_MIGRATION_ROADMAP.md) — дорожная карта миграции данных, инварианты и план деградации.
- [RUST_BRAIN_ROADMAP.md](RUST_BRAIN_ROADMAP.md) — этапы развития, критерии готовности и риски.
- [RUST_BRAIN_MAPPING.md](RUST_BRAIN_MAPPING.md) — маппинг Python → Rust компонентов.
- [RUST_BRAIN_LLM_RUNTIME.md](RUST_BRAIN_LLM_RUNTIME.md) — выбор LLM runtime и моделей.
