# üåê –ù–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –æ—Ç Ollama

## –°—Ç–∞—Ç—É—Å (14.12.2024)

‚úÖ **–ì–û–¢–û–í–û**: –ù–µ–π—Ä–∞ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã  
‚ö†Ô∏è **–ß–ê–°–¢–ò–ß–ù–û**: Embeddings –∏ Vision –º–æ–¥–µ–ª–∏ —Ç—Ä–µ–±—É—é—Ç Ollama  
üìù **TODO**: –†–∞—Å—à–∏—Ä–∏—Ç—å LLMManager –¥–ª—è embeddings

---

## –¢–µ–∫—É—â–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

### –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (LLM Manager)

| –ú–æ–¥—É–ª—å | –°—Ç–∞—Ç—É—Å | –ü—Ä–æ–≤–∞–π–¥–µ—Ä—ã |
|--------|--------|-----------|
| `cells.py` | ‚úÖ –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π | Ollama, OpenAI, Claude, Groq |
| `llm_providers.py` | ‚úÖ –ì–æ—Ç–æ–≤ | –í—Å–µ –æ—Å–Ω–æ–≤–Ω—ã–µ API |
| `neira_config.py` | ‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è | Priority: ollama‚Üígroq‚Üíopenai‚Üíclaude |

### –ó–∞–≤–∏—Å–∏–º—ã–µ –æ—Ç Ollama

| –ú–æ–¥—É–ª—å | –§—É–Ω–∫—Ü–∏—è | –¢—Ä–µ–±—É–µ—Ç Ollama |
|--------|---------|---------------|
| `memory_system.py` | Embeddings (`nomic-embed-text`) | ‚úÖ –î–∞ |
| `telegram_bot.py` | Vision (`llava:7b`) | ‚úÖ –î–∞ |
| `model_manager.py` | –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ VRAM –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π | ‚úÖ –î–∞ |

---

## –†–µ–∂–∏–º—ã —Ä–∞–±–æ—Ç—ã

### 1Ô∏è‚É£ **FREE** ‚Äî –¢–æ–ª—å–∫–æ –±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã
```python
PROVIDER_PRIORITY = "ollama,groq"  # Groq fallback –µ—Å–ª–∏ Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
```

**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:**
- Ollama (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –¥–ª—è embeddings/vision)
- Groq API key (`GROQ_API_KEY` –≤ `.env`)

**–ú–æ–¥–µ–ª–∏:**
- `ollama`: `qwen2.5:0.5b` (–ª–æ–∫–∞–ª—å–Ω–æ)
- `groq`: `llama-3.3-70b-versatile` (–æ–±–ª–∞–∫–æ)

---

### 2Ô∏è‚É£ **BALANCED** ‚Äî –ú–∏–∫—Å –±–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö + –¥–µ—à—ë–≤—ã–µ –ø–ª–∞—Ç–Ω—ã–µ
```python
PROVIDER_PRIORITY = "ollama,groq,openai"
```

**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:**
- `GROQ_API_KEY`
- `OPENAI_API_KEY`

**–ú–æ–¥–µ–ª–∏:**
- `ollama`: `qwen2.5:3b`
- `groq`: `llama-3.3-70b-versatile`
- `openai`: `gpt-3.5-turbo`

---

### 3Ô∏è‚É£ **QUALITY** ‚Äî –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
```python
PROVIDER_PRIORITY = "claude,openai,groq,ollama"
```

**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:**
- `ANTHROPIC_API_KEY` (Claude)
- `OPENAI_API_KEY`

**–ú–æ–¥–µ–ª–∏:**
- `claude`: `claude-3-5-sonnet-20241022`
- `openai`: `gpt-4o`
- `groq`: fallback
- `ollama`: fallback

---

## –ó–∞–ø—É—Å–∫ **–ë–ï–ó** Ollama

### –í–∞—Ä–∏–∞–Ω—Ç –ê: –¢–æ–ª—å–∫–æ –æ–±–ª–∞—á–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã

```bash
# 1. –û—Ç–∫–ª—é—á–∏ Ollama
taskkill /f /im ollama.exe

# 2. –ù–∞—Å—Ç—Ä–æ–π API –∫–ª—é—á–∏
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
GROQ_API_KEY=gsk_...

# 3. –†–µ–∂–∏–º "quality" (–±–µ–∑ ollama –≤ priority)
PROVIDER_PRIORITY=claude,openai,groq
```

‚ö†Ô∏è **–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –±–µ–∑ Ollama:**
- ‚ùå Vision –º–æ–¥–µ–ª–∏ (llava) –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã
- ‚ùå Embeddings —Ç—Ä–µ–±—É—é—Ç OpenAI API –∏–ª–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—É
- ‚ùå ModelManager –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç (—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ VRAM –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π)

### –í–∞—Ä–∏–∞–Ω—Ç –ë: OpenAI Embeddings –≤–º–µ—Å—Ç–æ Ollama

**TODO** (—Ç—Ä–µ–±—É–µ—Ç –¥–æ—Ä–∞–±–æ—Ç–∫–∏ `memory_system.py`):

```python
# –í–º–µ—Å—Ç–æ
OLLAMA_EMBED_URL = "http://localhost:11434/api/embeddings"
EMBED_MODEL = "nomic-embed-text"

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å
OPENAI_EMBED_MODEL = "text-embedding-3-small"  # $0.00002 / 1K tokens
```

–°—Ç–æ–∏–º–æ—Å—Ç—å: ~$0.02 –∑–∞ 1000 –∑–∞–ø—Ä–æ—Å–æ–≤ (–æ—á–µ–Ω—å –¥–µ—à—ë–≤–æ).

---

## Roadmap: –ü–æ–ª–Ω–∞—è –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å

### –≠—Ç–∞–ø 1: Embeddings abstraction ‚è≥
- [ ] –î–æ–±–∞–≤–∏—Ç—å `LLMProvider.get_embedding(text: str) -> List[float]`
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –≤ `OpenAIProvider` (text-embedding-3-small)
- [ ] –û–±–Ω–æ–≤–∏—Ç—å `MemorySystem` –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–∏
- [ ] Fallback: –µ—Å–ª–∏ embeddings –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã ‚Üí –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π TF-IDF

### –≠—Ç–∞–ø 2: Vision abstraction ‚è≥
- [ ] –î–æ–±–∞–≤–∏—Ç—å `LLMProvider.analyze_image(image_base64, prompt) -> str`
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –≤ `OpenAIProvider` (gpt-4o-vision)
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –≤ `ClaudeProvider` (claude-3-5-sonnet vision)
- [ ] –û–±–Ω–æ–≤–∏—Ç—å `telegram_bot.py` –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–∏

### –≠—Ç–∞–ø 3: –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è ‚è≥
- [ ] –û–±–Ω–æ–≤–∏—Ç—å QUICKSTART.md (–ø—Ä–∏–º–µ—Ä—ã –±–µ–∑ Ollama)
- [ ] –û–±–Ω–æ–≤–∏—Ç—å SETUP.md (API keys configuration)
- [ ] –°–æ–∑–¥–∞—Ç—å FAQ "–ö–∞–∫ –∑–∞–ø—É—Å—Ç–∏—Ç—å –±–µ–∑ Ollama?"

---

## –ü—Ä–∏–º–µ—Ä—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

### Cloud-only (–±–µ–∑ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π)
```env
# .env
PROVIDER_PRIORITY=groq,openai
GROQ_API_KEY=gsk_...
OPENAI_API_KEY=sk-...

# Embeddings —á–µ—Ä–µ–∑ OpenAI
EMBED_PROVIDER=openai
OPENAI_EMBED_MODEL=text-embedding-3-small
```

### Hybrid (–ª–æ–∫–∞–ª—å–Ω—ã–π Ollama + –æ–±–ª–∞—á–Ω—ã–π fallback)
```env
PROVIDER_PRIORITY=ollama,groq,openai
GROQ_API_KEY=gsk_...

# Ollama –¥–ª—è embeddings/vision
OLLAMA_URL=http://localhost:11434
```

### Groq-only (—Å–∞–º—ã–π –¥–µ—à—ë–≤—ã–π)
```env
PROVIDER_PRIORITY=groq
GROQ_API_KEY=gsk_...

# Embeddings –æ—Ç–∫–ª—é—á–µ–Ω—ã (–∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫)
EMBED_PROVIDER=none
```

---

## –¢–µ–∫—É—â–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è

| –§—É–Ω–∫—Ü–∏—è | Ollama-only | –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ |
|---------|-------------|--------------|
| **Text generation** | ‚ùå –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ | OpenAI, Claude, Groq |
| **Embeddings** | ‚úÖ `nomic-embed-text` | TODO: OpenAI embeddings |
| **Vision** | ‚úÖ `llava:7b` | TODO: OpenAI/Claude vision |
| **VRAM management** | ‚úÖ ModelManager | –ù–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è –æ–±–ª–∞—á–Ω—ã—Ö |

---

## –ö–æ–º–∞–Ω–¥—ã –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏

### –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã
```python
from llm_providers import create_default_manager

manager = create_default_manager()
print(manager.available_providers)
# –û–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥: ['ollama', 'groq', 'openai']
```

### –¢–µ—Å—Ç –±–µ–∑ Ollama
```python
# 1. –£–±–µ–¥–∏—Å—å —á—Ç–æ Ollama –≤—ã–∫–ª—é—á–µ–Ω
# 2. –ó–∞–ø—É—Å—Ç–∏
from llm_providers import LLMManager, GroqProvider, OpenAIProvider

manager = LLMManager(providers=[
    GroqProvider(),
    OpenAIProvider()
])

response = manager.generate("–ü—Ä–∏–≤–µ—Ç!")
print(response.content)  # –î–æ–ª–∂–µ–Ω —Ä–∞–±–æ—Ç–∞—Ç—å —á–µ—Ä–µ–∑ Groq –∏–ª–∏ OpenAI
```

---

## –í–æ–ø—Ä–æ—Å—ã –∏ –æ—Ç–≤–µ—Ç—ã

**Q: –ú–æ–∂–Ω–æ –ª–∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—Ç–∫–∞–∑–∞—Ç—å—Å—è –æ—Ç Ollama?**  
A: –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏ –¥–∞ (–¥–ª—è text generation), –Ω–æ embeddings –∏ vision –ø–æ–∫–∞ —Ç—Ä–µ–±—É—é—Ç –µ–≥–æ. –†–∞–±–æ—Ç–∞–µ–º –Ω–∞–¥ –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–µ–π.

**Q: –ö–∞–∫–æ–π —Å–∞–º—ã–π –¥–µ—à—ë–≤—ã–π —Å–ø–æ—Å–æ–± –∑–∞–ø—É—Å–∫–∞?**  
A: Groq (–±–µ—Å–ø–ª–∞—Ç–Ω—ã–π –ª–∏–º–∏—Ç 14400 req/day) + –æ—Ç–∫–ª—é—á–∏—Ç—å embeddings.

**Q: –ù—É–∂–µ–Ω –ª–∏ GPU –±–µ–∑ Ollama?**  
A: –ù–µ—Ç. –û–±–ª–∞—á–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã (OpenAI/Claude/Groq) —Ä–∞–±–æ—Ç–∞—é—Ç –Ω–∞ –∏—Ö —Å–µ—Ä–≤–µ—Ä–∞—Ö.

**Q: –ö–∞–∫–æ–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä –ª—É—á—à–∏–π –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞?**  
A: `claude-3-5-sonnet` > `gpt-4o` > `qwen2.5` (Ollama) > `groq llama-3.3`

---

## –ö–æ–Ω—Ç—Ä–∏–±—å—é—Ü–∏—è

–•–æ—á–µ—à—å –ø–æ–º–æ—á—å —Å –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å—é –æ—Ç Ollama?

1. **Embeddings provider** ‚Äî —Ä–µ–∞–ª–∏–∑—É–π OpenAI embeddings –≤ `llm_providers.py`
2. **Vision provider** ‚Äî –¥–æ–±–∞–≤—å gpt-4o-vision support
3. **–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ** ‚Äî –ø—Ä–æ–≤–µ—Ä—å —Ä–∞–±–æ—Ç—É –±–µ–∑ Ollama –≤ —Ä–∞–∑–Ω—ã—Ö —Ä–µ–∂–∏–º–∞—Ö

–ü–∏—à–∏ –≤ Issues: `[OLLAMA-INDEPENDENCE]`
