# üß† –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ —É–ª—É—á—à–µ–Ω–∏—é —Å–∏—Å—Ç–µ–º—ã –ø–∞–º—è—Ç–∏ Neira

## üìä –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ

**–ß—Ç–æ —É–∂–µ –µ—Å—Ç—å (memory_system.py v2.0):**
- ‚úÖ –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ —Ç–∏–ø—ã: Working/Short-Term/Long-Term/Episodic/Semantic
- ‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–µ—Ä–µ–¥ –∑–∞–ø–∏—Å—å—é
- ‚úÖ Confidence score (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å 0-1)
- ‚úÖ –ó–∞—â–∏—Ç–∞ –æ—Ç –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏—è (–ª–∏–º–∏—Ç—ã: 1000/500/300)
- ‚úÖ –ê–≤—Ç–æ–æ—á–∏—Å—Ç–∫–∞ –Ω–∏–∑–∫–æ—É–≤–µ—Ä–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
- ‚úÖ –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞

**–ü—Ä–æ–±–ª–µ–º—ã –ø–æ—Å–ª–µ –∞–Ω–∞–ª–∏–∑–∞:**
1. **–ü–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–π –ø–∞–º—è—Ç–∏** ‚Äî 3.6 MB, 173 –∑–∞–ø–∏—Å–∏ (–ø–æ—Å–ª–µ —á–∏—Å—Ç–∫–∏ 107)
2. **–ó–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏—è** ‚Äî –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏ –∑–∞ –º–∏–Ω—É—Ç—É (–¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–æ 12 —Å–ª—É—á–∞–µ–≤)
3. **–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏** ‚Äî –∑–∞–ø–æ–º–∏–Ω–∞–µ—Ç –æ–±—Å—É–∂–¥–µ–Ω–∏—è –ø—Ä–æ –∫–æ–¥, –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
4. **–ù–µ—Ç —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏—è** ‚Äî –ø–∞–º—è—Ç—å –≤ plaintext JSON
5. **–ù–µ—Ç –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è** ‚Äî –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –æ—Ç–∫–∞—Ç–∏—Ç—å—Å—è –Ω–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
6. **–ù–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ–∑–∞—Ü–∏–∏** ‚Äî –≤—Å–µ –∑–∞–ø–∏—Å–∏ —Ä–∞–≤–Ω–æ–∑–Ω–∞—á–Ω—ã
7. **–ú–µ–¥–ª–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫** ‚Äî –ª–∏–Ω–µ–π–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –≤—Å–µ—Ö –∑–∞–ø–∏—Å–µ–π

---

## üéØ –†–µ—à–µ–Ω–∏–µ 1: –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –ø–∞–º—è—Ç–∏

### –ü—Ä–æ–±–ª–µ–º–∞
–ó–∞–ø–∏—Å–∏ –¥—É–±–ª–∏—Ä—É—é—Ç—Å—è, –∑–∞—Ü–∏–∫–ª–∏–≤–∞—é—Ç—Å—è, –Ω–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –ø–æ—Ö–æ–∂–∏—Ö.

### –†–µ—à–µ–Ω–∏–µ
**Memory Consolidation Engine** ‚Äî –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–ª–∏—è–Ω–∏–µ –∏ –∞—Ä—Ö–∏–≤–∞—Ü–∏—è

```python
class MemoryConsolidator:
    """–£–º–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∑–∞–ø–∏—Å–µ–π –ø–∞–º—è—Ç–∏"""
    
    def consolidate_similar(self, memories: List[MemoryEntry], threshold=0.85):
        """
        –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –ø–æ—Ö–æ–∂–∏–µ –∑–∞–ø–∏—Å–∏ (>85% —Å—Ö–æ–∂–µ—Å—Ç–∏) –≤ –æ–¥–Ω—É —Å –ø–æ–≤—ã—à–µ–Ω–Ω–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
        """
        clusters = []
        used = set()
        
        for i, mem1 in enumerate(memories):
            if i in used:
                continue
                
            cluster = [mem1]
            for j, mem2 in enumerate(memories[i+1:], i+1):
                if j in used:
                    continue
                    
                similarity = self._semantic_similarity(mem1.text, mem2.text)
                if similarity >= threshold:
                    cluster.append(mem2)
                    used.add(j)
            
            if len(cluster) > 1:
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤ –æ–¥–Ω—É –∑–∞–ø–∏—Å—å —Å –ø–æ–≤—ã—à–µ–Ω–Ω–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
                merged = self._merge_cluster(cluster)
                clusters.append(merged)
            else:
                clusters.append(mem1)
        
        return clusters
    
    def _merge_cluster(self, cluster: List[MemoryEntry]) -> MemoryEntry:
        """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –∫–ª–∞—Å—Ç–µ—Ä –ø–æ—Ö–æ–∂–∏—Ö –∑–∞–ø–∏—Å–µ–π"""
        # –ë–µ—Ä—ë–º —Å–∞–º—É—é —Å–≤–µ–∂—É—é –¥–∞—Ç—É
        latest = max(cluster, key=lambda x: x.timestamp)
        
        # –ü–æ–≤—ã—à–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ)
        confidence_boost = min(1.0, latest.confidence + 0.1 * len(cluster))
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å–≤—è–∑–∏
        all_related = set()
        for mem in cluster:
            all_related.update(mem.related_ids)
        
        return MemoryEntry(
            id=latest.id,
            text=latest.text,
            memory_type=latest.memory_type,
            category=latest.category,
            timestamp=latest.timestamp,
            confidence=confidence_boost,
            validation_status="validated",  # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–æ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ–º
            related_ids=list(all_related),
            access_count=sum(m.access_count for m in cluster)
        )
```

**–≠—Ñ—Ñ–µ–∫—Ç:**
- –°–∂–∞—Ç–∏–µ –ø–∞–º—è—Ç–∏ –Ω–∞ 30-50%
- –ü–æ–≤—ã—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ (–ø–æ–¥—Ç–≤–µ—Ä–∂–¥—ë–Ω–Ω—ã–µ —Ñ–∞–∫—Ç—ã –ø–æ–ª—É—á–∞—é—Ç boost)
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è —á–µ—Ä–µ–∑ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ

---

## üéØ –†–µ—à–µ–Ω–∏–µ 2: –í–µ–∫—Ç–æ—Ä–Ω–∞—è –ë–î –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞

### –ü—Ä–æ–±–ª–µ–º–∞
–õ–∏–Ω–µ–π–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ 173 –∑–∞–ø–∏—Å—è–º –º–µ–¥–ª–µ–Ω–Ω—ã–π. –ü—Ä–∏ —Ä–æ—Å—Ç–µ –¥–æ 1000 –±—É–¥–µ—Ç –∫—Ä–∏—Ç–∏—á–Ω–æ.

### –†–µ—à–µ–Ω–∏–µ
**ChromaDB** –∏–ª–∏ **FAISS** –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞

```python
import chromadb
from chromadb.config import Settings

class VectorMemoryIndex:
    """–í–µ–∫—Ç–æ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞"""
    
    def __init__(self, persist_directory="./memory_vectors"):
        self.client = chromadb.Client(Settings(
            chroma_db_impl="duckdb+parquet",
            persist_directory=persist_directory
        ))
        
        self.collection = self.client.get_or_create_collection(
            name="neira_memory",
            metadata={"description": "Long-term memory with embeddings"}
        )
    
    def add_memory(self, memory: MemoryEntry, embedding: List[float]):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –∑–∞–ø–∏—Å—å —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–º"""
        self.collection.add(
            ids=[memory.id],
            embeddings=[embedding],
            documents=[memory.text],
            metadatas=[{
                "category": memory.category,
                "confidence": memory.confidence,
                "timestamp": memory.timestamp
            }]
        )
    
    def search(self, query_embedding: List[float], top_k=5, min_confidence=0.3):
        """–ë—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –∑–∞–ø–∏—Å–µ–π"""
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k,
            where={"confidence": {"$gte": min_confidence}}
        )
        
        return results['ids'][0], results['distances'][0]
```

**–≠—Ñ—Ñ–µ–∫—Ç:**
- –ü–æ–∏—Å–∫ –∑–∞ O(log n) –≤–º–µ—Å—Ç–æ O(n)
- –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å –¥–æ –º–∏–ª–ª–∏–æ–Ω–æ–≤ –∑–∞–ø–∏—Å–µ–π
- –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º (–∫–∞—Ç–µ–≥–æ—Ä–∏—è, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å, –¥–∞—Ç–∞)

---

## üéØ –†–µ—à–µ–Ω–∏–µ 3: –®–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏

### –ü—Ä–æ–±–ª–µ–º–∞
–ü–∞–º—è—Ç—å —Ö—Ä–∞–Ω–∏—Ç—Å—è –≤ plaintext ‚Äî —É—è–∑–≤–∏–º–æ—Å—Ç—å –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∏–∑–≤–Ω–µ.

### –†–µ—à–µ–Ω–∏–µ
**AES-256 —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ** —Å –∫–ª—é—á–æ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

```python
from cryptography.fernet import Fernet
import base64
import hashlib

class SecureMemoryStorage:
    """–®–∏—Ñ—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –ø–∞–º—è—Ç–∏"""
    
    def __init__(self, password: str):
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–ª—é—á –∏–∑ –ø–∞—Ä–æ–ª—è
        key = hashlib.sha256(password.encode()).digest()
        self.cipher = Fernet(base64.urlsafe_b64encode(key))
    
    def save_encrypted(self, data: dict, filepath: str):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–∞–º—è—Ç—å –≤ –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω–æ–º –≤–∏–¥–µ"""
        json_bytes = json.dumps(data, ensure_ascii=False).encode('utf-8')
        encrypted = self.cipher.encrypt(json_bytes)
        
        with open(filepath, 'wb') as f:
            f.write(encrypted)
    
    def load_encrypted(self, filepath: str) -> dict:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—É—é –ø–∞–º—è—Ç—å"""
        with open(filepath, 'rb') as f:
            encrypted = f.read()
        
        decrypted = self.cipher.decrypt(encrypted)
        return json.loads(decrypted.decode('utf-8'))
```

**–≠—Ñ—Ñ–µ–∫—Ç:**
- –ó–∞—â–∏—Ç–∞ –æ—Ç –Ω–µ—Å–∞–Ω–∫—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞
- –ö–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å –ø–µ—Ä–µ–ø–∏—Å–æ–∫
- –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ (–º–æ–∂–Ω–æ –æ—Ç–∫–ª—é—á–∏—Ç—å)

---

## üéØ –†–µ—à–µ–Ω–∏–µ 4: –ü—Ä–∏–æ—Ä–∏—Ç–µ–∑–∞—Ü–∏—è –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏

### –ü—Ä–æ–±–ª–µ–º–∞
–í—Å–µ –∑–∞–ø–∏—Å–∏ —Ä–∞–≤–Ω–æ–∑–Ω–∞—á–Ω—ã ‚Äî –≤–∞–∂–Ω—ã–µ —Ñ–∞–∫—Ç—ã —Ç–µ—Ä—è—é—Ç—Å—è —Å—Ä–µ–¥–∏ –º—É—Å–æ—Ä–∞.

### –†–µ—à–µ–Ω–∏–µ
**Scoring —Å–∏—Å—Ç–µ–º–∞** —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º —Ä–∞—Å—á—ë—Ç–æ–º –≤–∞–∂–Ω–æ—Å—Ç–∏

```python
class MemoryScorer:
    """–û—Ü–µ–Ω–∫–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏ –∑–∞–ø–∏—Å–µ–π"""
    
    def calculate_importance(self, memory: MemoryEntry, context: dict) -> float:
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å –∑–∞–ø–∏—Å–∏ (0-1)
        
        –§–∞–∫—Ç–æ—Ä—ã:
        - –ß–∞—Å—Ç–æ—Ç–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (access_count)
        - –°–≤–µ–∂–µ—Å—Ç—å (recency)
        - –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ (validation_status)
        - –°–≤—è–∑–∞–Ω–Ω–æ—Å—Ç—å (—Å–∫–æ–ª—å–∫–æ –¥—Ä—É–≥–∏—Ö –∑–∞–ø–∏—Å–µ–π —Å—Å—ã–ª–∞—é—Ç—Å—è)
        - –ö–∞—Ç–µ–≥–æ—Ä–∏—è (FACT > CONVERSATION)
        """
        score = 0.0
        
        # 1. –ß–∞—Å—Ç–æ—Ç–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (0-0.3)
        score += min(0.3, memory.access_count / 100)
        
        # 2. –°–≤–µ–∂–µ—Å—Ç—å (0-0.2)
        age_days = (datetime.now() - datetime.fromisoformat(memory.timestamp)).days
        recency_score = max(0, 0.2 - (age_days / 365) * 0.2)
        score += recency_score
        
        # 3. –í–∞–ª–∏–¥–∞—Ü–∏—è (0-0.3)
        validation_scores = {
            "user_confirmed": 0.3,
            "validated": 0.2,
            "pending": 0.1,
            "rejected": 0.0
        }
        score += validation_scores.get(memory.validation_status, 0.1)
        
        # 4. –°–≤—è–∑–∞–Ω–Ω–æ—Å—Ç—å (0-0.1)
        score += min(0.1, len(memory.related_ids) / 50)
        
        # 5. –ö–∞—Ç–µ–≥–æ—Ä–∏—è (0-0.1)
        category_scores = {
            "fact": 0.1,
            "instruction": 0.09,
            "preference": 0.08,
            "person": 0.07,
            "learned": 0.05,
            "conversation": 0.03,
            "event": 0.02
        }
        score += category_scores.get(memory.category, 0.05)
        
        return min(1.0, score)
    
    def prioritize_memories(self, memories: List[MemoryEntry]) -> List[MemoryEntry]:
        """–°–æ—Ä—Ç–∏—Ä—É–µ—Ç –∑–∞–ø–∏—Å–∏ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏"""
        scored = [
            (mem, self.calculate_importance(mem, {}))
            for mem in memories
        ]
        
        sorted_mems = sorted(scored, key=lambda x: x[1], reverse=True)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ–ª–µ importance
        for mem, score in sorted_mems:
            mem.importance = score
        
        return [m[0] for m in sorted_mems]
```

**–≠—Ñ—Ñ–µ–∫—Ç:**
- –í–∞–∂–Ω—ã–µ —Ñ–∞–∫—Ç—ã –≤—Å–µ–≥–¥–∞ –≤ —Ç–æ–ø–µ
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∞—Ä—Ö–∏–≤–∞—Ü–∏—è —Ä–µ–¥–∫–æ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö
- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è LLM (—Ç–æ–ª—å–∫–æ —Ç–æ–ø-20)

---

## üéØ –†–µ—à–µ–Ω–∏–µ 5: Git-like –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ

### –ü—Ä–æ–±–ª–µ–º–∞
–ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –æ—Ç–∫–∞—Ç–∏—Ç—å—Å—è –ø–æ—Å–ª–µ –æ—à–∏–±–æ—á–Ω–æ–π –æ—á–∏—Å—Ç–∫–∏ –∏–ª–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è.

### –†–µ—à–µ–Ω–∏–µ
**Snapshot —Å–∏—Å—Ç–µ–º–∞** —Å diff'–∞–º–∏

```python
class MemoryVersionControl:
    """Git-like –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏"""
    
    def __init__(self, snapshots_dir="./memory_snapshots"):
        self.snapshots_dir = Path(snapshots_dir)
        self.snapshots_dir.mkdir(exist_ok=True)
    
    def create_snapshot(self, memory_data: dict, message: str = ""):
        """–°–æ–∑–¥–∞—ë—Ç —Å–Ω–∏–º–æ–∫ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        snapshot_id = hashlib.md5(f"{timestamp}{message}".encode()).hexdigest()[:8]
        
        snapshot = {
            "id": snapshot_id,
            "timestamp": timestamp,
            "message": message,
            "data": memory_data,
            "stats": {
                "total_memories": len(memory_data),
                "avg_confidence": sum(m.get("confidence", 0) for m in memory_data) / len(memory_data)
            }
        }
        
        filepath = self.snapshots_dir / f"snapshot_{timestamp}_{snapshot_id}.json"
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(snapshot, f, ensure_ascii=False, indent=2)
        
        # –õ–æ–≥ –∏–∑–º–µ–Ω–µ–Ω–∏–π
        self._append_to_changelog(snapshot_id, message, timestamp)
        
        return snapshot_id
    
    def restore_snapshot(self, snapshot_id: str) -> dict:
        """–í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∏–∑ —Å–Ω–∏–º–∫–∞"""
        snapshots = list(self.snapshots_dir.glob(f"snapshot_*_{snapshot_id}.json"))
        
        if not snapshots:
            raise ValueError(f"Snapshot {snapshot_id} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        with open(snapshots[0], 'r', encoding='utf-8') as f:
            snapshot = json.load(f)
        
        return snapshot["data"]
    
    def list_snapshots(self) -> List[dict]:
        """–°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Å–Ω–∏–º–∫–æ–≤"""
        snapshots = []
        for filepath in sorted(self.snapshots_dir.glob("snapshot_*.json")):
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
                snapshots.append({
                    "id": data["id"],
                    "timestamp": data["timestamp"],
                    "message": data.get("message", ""),
                    "stats": data.get("stats", {})
                })
        return snapshots
```

**–≠—Ñ—Ñ–µ–∫—Ç:**
- –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (–º–æ–∂–Ω–æ –æ—Ç–∫–∞—Ç–∏—Ç—å)
- –ò—Å—Ç–æ—Ä–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π –ø–∞–º—è—Ç–∏
- –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ—Å–ª–µ —Å–±–æ–µ–≤

---

## üéØ –†–µ—à–µ–Ω–∏–µ 6: –î–µ—Ç–µ–∫—Ç–æ—Ä –∞–Ω–æ–º–∞–ª–∏–π –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏

### –ü—Ä–æ–±–ª–µ–º–∞
–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏ –∏ –∑–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏—è –¥–µ—Ç–µ–∫—Ç–∏—Ä—É—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø–æ—Å—Ç—Ñ–∞–∫—Ç—É–º.

### –†–µ—à–µ–Ω–∏–µ
**Anomaly Detector** –ø–µ—Ä–µ–¥ –∑–∞–ø–∏—Å—å—é

```python
class MemoryAnomalyDetector:
    """–î–µ—Ç–µ–∫—Ç–æ—Ä –∞–Ω–æ–º–∞–ª—å–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º"""
    
    def __init__(self):
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –º—É—Å–æ—Ä–∞
        self.technical_patterns = [
            r"import\s+\w+",
            r"class\s+\w+:",
            r"def\s+\w+\(",
            r"async\s+def",
            r"–Ω–µ–π—Ä–æ–Ω–Ω(–∞—è|—ã–µ|—ã—Ö|–æ–π)\s+—Å–µ—Ç",
            r"—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä",
            r"–≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω(—ã–π|–æ–≥–æ)\s+—Å–ø—É—Å–∫",
            r"–±–∏–æ—Ö–∏–º–∏—á–µ—Å–∫(–∏–π|–æ–≥–æ|–æ–º)",
        ]
        
        # –ò—Å—Ç–æ—Ä–∏—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö N –∑–∞–ø–∏—Å–µ–π –¥–ª—è –¥–µ—Ç–µ–∫—Ç–∞ –∑–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏—è
        self.recent_window = []
        self.window_size = 10
    
    def is_anomaly(self, text: str, timestamp: str) -> Tuple[bool, str]:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∑–∞–ø–∏—Å—å –∞–Ω–æ–º–∞–ª–∏–µ–π
        
        Returns:
            (is_anomaly, reason)
        """
        # 1. –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∫–æ–¥/–∂–∞—Ä–≥–æ–Ω
        for pattern in self.technical_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                return True, "technical_jargon"
        
        # 2. –ó–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏–µ (3+ –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö –∑–∞ –º–∏–Ω—É—Ç—É)
        minute_key = timestamp[:16]  # YYYY-MM-DDTHH:MM
        same_minute = [
            (t, txt) for t, txt in self.recent_window
            if t[:16] == minute_key
        ]
        
        if len(same_minute) >= 3:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å
            similarities = [
                self._text_similarity(text, txt)
                for _, txt in same_minute
            ]
            if max(similarities, default=0) > 0.7:
                return True, "looping"
        
        # 3. –°–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (>2000 —Å–∏–º–≤–æ–ª–æ–≤)
        if len(text) > 2000:
            return True, "too_long"
        
        # 4. –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ—Ä–∞–∑—ã
        suspicious = [
            "—è –Ω–µ –∑–Ω–∞—é", "–Ω–µ —É–≤–µ—Ä–µ–Ω", "–≤–æ–∑–º–æ–∂–Ω–æ", "–º–æ–∂–µ—Ç –±—ã—Ç—å",
            "—Å–æ–≥–ª–∞—Å–Ω–æ –º–æ–∏–º –¥–∞–Ω–Ω—ã–º", "–≤ –º–æ–µ–π –±–∞–∑–µ", "–∫–∞–∫ —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å"
        ]
        
        lower_text = text.lower()
        suspicion_count = sum(1 for phrase in suspicious if phrase in lower_text)
        
        if suspicion_count >= 3:
            return True, "uncertain_language"
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –æ–∫–Ω–æ
        self.recent_window.append((timestamp, text))
        if len(self.recent_window) > self.window_size:
            self.recent_window.pop(0)
        
        return False, ""
    
    def _text_similarity(self, text1: str, text2: str) -> float:
        """Jaccard similarity"""
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())
        return len(words1 & words2) / len(words1 | words2) if words1 | words2 else 0
```

**–≠—Ñ—Ñ–µ–∫—Ç:**
- –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –º—É—Å–æ—Ä–∞ –¥–æ –∑–∞–ø–∏—Å–∏
- –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ –∑–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏–π
- –ß–∏—Å—Ç–∞—è –ø–∞–º—è—Ç—å —Å –ø–µ—Ä–≤–æ–≥–æ –¥–Ω—è

---

## üì¶ –ò—Ç–æ–≥–æ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ v3.0

```
MemorySystem v3.0
‚îú‚îÄ‚îÄ Core
‚îÇ   ‚îú‚îÄ‚îÄ VectorMemoryIndex (ChromaDB) ‚Äî –±—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫
‚îÇ   ‚îú‚îÄ‚îÄ SecureMemoryStorage (AES-256) ‚Äî —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ
‚îÇ   ‚îî‚îÄ‚îÄ MemoryVersionControl (Snapshots) ‚Äî –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
‚îÇ
‚îú‚îÄ‚îÄ Intelligence
‚îÇ   ‚îú‚îÄ‚îÄ MemoryConsolidator ‚Äî –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø–æ—Ö–æ–∂–∏—Ö
‚îÇ   ‚îú‚îÄ‚îÄ MemoryScorer ‚Äî –ø—Ä–∏–æ—Ä–∏—Ç–µ–∑–∞—Ü–∏—è
‚îÇ   ‚îî‚îÄ‚îÄ MemoryAnomalyDetector ‚Äî –∑–∞—â–∏—Ç–∞ –æ—Ç –º—É—Å–æ—Ä–∞
‚îÇ
‚îî‚îÄ‚îÄ Policies
    ‚îú‚îÄ‚îÄ Auto-cleanup (–ø–æ importance score)
    ‚îú‚îÄ‚îÄ Auto-consolidation (—Ä–∞–∑ –≤ —Å—É—Ç–∫–∏)
    ‚îî‚îÄ‚îÄ Auto-snapshot (–ø–µ—Ä–µ–¥ –æ—á–∏—Å—Ç–∫–æ–π)
```

---

## üöÄ –ü–ª–∞–Ω –≤–Ω–µ–¥—Ä–µ–Ω–∏—è (–ø–æ—ç—Ç–∞–ø–Ω–æ)

### –§–∞–∑–∞ 1: –ó–∞—â–∏—Ç–∞ (1-2 –¥–Ω—è)
1. ‚úÖ Anomaly Detector ‚Äî –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –º—É—Å–æ—Ä–∞
2. ‚úÖ Auto-cleanup ‚Äî –ª–∏–º–∏—Ç—ã –∏ –æ—á–∏—Å—Ç–∫–∞
3. ‚úÖ Snapshots ‚Äî –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ

### –§–∞–∑–∞ 2: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è (2-3 –¥–Ω—è)
4. ‚è≥ VectorIndex ‚Äî ChromaDB –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è
5. ‚è≥ Consolidation ‚Äî –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø–æ—Ö–æ–∂–∏—Ö
6. ‚è≥ Scoring ‚Äî –ø—Ä–∏–æ—Ä–∏—Ç–µ–∑–∞—Ü–∏—è

### –§–∞–∑–∞ 3: –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å (1 –¥–µ–Ω—å)
7. ‚è≥ Encryption ‚Äî –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ
8. ‚è≥ Access control ‚Äî –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞

---

## üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

**–°–µ–π—á–∞—Å:**
1. –í–Ω–µ–¥—Ä–∏—Ç—å `MemoryAnomalyDetector` ‚Äî –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç —Ä–æ—Å—Ç –º—É—Å–æ—Ä–∞
2. –í–∫–ª—é—á–∏—Ç—å `auto_consolidation` ‚Äî —Å–æ–∂–º—ë—Ç —Ç–µ–∫—É—â–∏–µ 107 –∑–∞–ø–∏—Å–µ–π
3. –°–æ–∑–¥–∞—Ç—å snapshot –ø–µ—Ä–µ–¥ –ª—é–±—ã–º–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è–º–∏

**–ß–µ—Ä–µ–∑ –Ω–µ–¥–µ–ª—é:**
4. –ú–∏–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ ChromaDB ‚Äî —É—Å–∫–æ—Ä–∏—Ç –≤ 10-100x
5. –î–æ–±–∞–≤–∏—Ç—å scoring ‚Äî –≤–∞–∂–Ω—ã–µ —Ñ–∞–∫—Ç—ã –≤—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–Ω—ã

**–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ:**
6. –®–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ ‚Äî –µ—Å–ª–∏ –≤–∞–∂–Ω–∞ –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å
7. –í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å ‚Äî –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏

---

## üìä –ú–µ—Ç—Ä–∏–∫–∏ —É—Å–ø–µ—Ö–∞

**–î–æ —É–ª—É—á—à–µ–Ω–∏–π:**
- –ü–∞–º—è—Ç–∏: 3.6 MB ‚Üí 2.2 MB (–ø–æ—Å–ª–µ —Ä—É—á–Ω–æ–π —á–∏—Å—Ç–∫–∏)
- –ó–∞–ø–∏—Å–µ–π: 173 ‚Üí 107
- –ó–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏–π: 12 —Å–ª—É—á–∞–µ–≤
- –ü–æ–∏—Å–∫: O(n) –ª–∏–Ω–µ–π–Ω—ã–π

**–ü–æ—Å–ª–µ v3.0 (–ø—Ä–æ–≥–Ω–æ–∑):**
- –ü–∞–º—è—Ç–∏: ~1 MB (–∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è + scoring)
- –ó–∞–ø–∏—Å–µ–π: ~80 –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö
- –ó–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏–π: 0 (–¥–µ—Ç–µ–∫—Ç–æ—Ä)
- –ü–æ–∏—Å–∫: O(log n) –≤–µ–∫—Ç–æ—Ä–Ω—ã–π
- –ó–∞—â–∏—Ç–∞: AES-256 + snapshots
- –°–∫–æ—Ä–æ—Å—Ç—å: +90% –±—ã—Å—Ç—Ä–µ–µ

---

**–ö–∞–∫–æ–µ —Ä–µ—à–µ–Ω–∏–µ —Ö–æ—á–µ—à—å –≤–Ω–µ–¥—Ä–∏—Ç—å –ø–µ—Ä–≤—ã–º?**
