"""–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–æ–¥–µ–ª–µ–π –¥–ª—è Neira —á–µ—Ä–µ–∑ Ollama.

–°–∫—Ä–∏–ø—Ç –ø–æ–¥—Ç—è–≥–∏–≤–∞–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ neira-personality.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç `ollama pull` –∏ –≤—ã–≤–æ–¥–∏—Ç –ø–æ–Ω—è—Ç–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –æ–± –æ—à–∏–±–∫–∞—Ö.
"""

from __future__ import annotations

import argparse
import shutil
import subprocess
import sys
import urllib.error
import urllib.request
from dataclasses import dataclass
from typing import Iterable, List, Sequence

DEFAULT_OLLAMA_API_URL = "http://localhost:11434/api/version"


@dataclass(frozen=True)
class ModelSpec:
    """–û–ø–∏—Å–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏."""

    name: str
    reason: str


REQUIRED_MODELS: List[ModelSpec] = [
    ModelSpec(name="qwen2.5-coder:7b", reason="–º–æ–¥–µ–ª—å –¥–ª—è –∫–æ–¥–∞"),
    ModelSpec(name="mistral:7b-instruct", reason="–º–æ–¥–µ–ª—å –¥–ª—è —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π"),
    ModelSpec(name="nomic-embed-text", reason="embedding-–º–æ–¥–µ–ª—å –¥–ª—è –ø–æ–∏—Å–∫–∞"),
]

PERSONALITY_MODEL = ModelSpec(
    name="neira-personality", reason="–¥–∏–∞–ª–æ–≥–æ–≤–∞—è –º–æ–¥–µ–ª—å —Å –ª–∏—á–Ω–æ—Å—Ç—å—é"
)


def build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(
        description="–°–∫–∞—á–∞—Ç—å –º–æ–¥–µ–ª–∏ Ollama, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ Neira"
    )
    parser.add_argument(
        "--with-personality",
        action="store_true",
        help="–¥–æ–±–∞–≤–∏—Ç—å –∑–∞–≥—Ä—É–∑–∫—É neira-personality, –µ—Å–ª–∏ –æ–Ω–∞ —É–∂–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–∞",
    )
    parser.add_argument(
        "--only",
        nargs="+",
        metavar="MODEL",
        choices=[
            "qwen2.5-coder:7b",
            "mistral:7b-instruct",
            "nomic-embed-text",
            "neira-personality",
        ],
        help="—Å–∫–∞—á–∞—Ç—å —Ç–æ–ª—å–∫–æ —É–∫–∞–∑–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ (—Å–ø–∏—Å–æ–∫ —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª)",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="–Ω–µ –≤—ã–ø–æ–ª–Ω—è—Ç—å –∫–æ–º–∞–Ω–¥—ã, —Ç–æ–ª—å–∫–æ –ø–æ–∫–∞–∑–∞—Ç—å –ø–ª–∞–Ω",
    )
    parser.add_argument(
        "--server-url",
        default=DEFAULT_OLLAMA_API_URL,
        help="–∞–¥—Ä–µ—Å Ollama –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ API (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é http://localhost:11434)",
    )
    return parser


def ensure_ollama_cli() -> bool:
    if shutil.which("ollama"):
        return True
    print("‚ùå –ö–æ–º–∞–Ω–¥–∞ 'ollama' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ PATH. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Ollama –∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ.")
    return False


def warn_if_server_unavailable(api_url: str) -> None:
    try:
        with urllib.request.urlopen(api_url, timeout=3) as resp:
            if resp.status != 200:
                print("‚ö†Ô∏è Ollama –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ, –≤–æ–∑–º–æ–∂–Ω–æ —Å–µ—Ä–≤–µ—Ä –Ω–µ –∑–∞–ø—É—â–µ–Ω.")
            return
    except urllib.error.URLError as exc:
        print(
            f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Ollama ({api_url}). "
            "–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –∑–∞–ø—É—â–µ–Ω–æ 'ollama serve'. –î–µ—Ç–∞–ª–∏:",
            exc,
        )


def pull_model(model: ModelSpec, dry_run: bool) -> bool:
    command = ["ollama", "pull", model.name]
    if dry_run:
        print(f"DRY-RUN: {' '.join(command)}  # {model.reason}")
        return True

    print(f"‚¨áÔ∏è  –°–∫–∞—á–∏–≤–∞—é {model.name} ({model.reason})...")
    try:
        result = subprocess.run(command, check=False, capture_output=True, text=True)
    except FileNotFoundError:
        print("‚ùå –ö–æ–º–∞–Ω–¥–∞ 'ollama' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Ollama –∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ.")
        return False

    if result.returncode == 0:
        print(f"‚úÖ {model.name} –≥–æ—Ç–æ–≤–∞")
        return True

    print(
        f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å {model.name}. –ö–æ–¥ {result.returncode}. "
        f"Stdout: {result.stdout.strip()} | Stderr: {result.stderr.strip()}"
    )
    return False


def select_models(args: argparse.Namespace) -> List[ModelSpec]:
    requested: Sequence[str] = args.only or []

    if requested:
        known = {spec.name: spec for spec in REQUIRED_MODELS + [PERSONALITY_MODEL]}
        return [known[name] for name in requested]

    models: List[ModelSpec] = list(REQUIRED_MODELS)
    if args.with_personality:
        models.append(PERSONALITY_MODEL)
    return models


def install_models(models: Iterable[ModelSpec], dry_run: bool) -> int:
    success = True
    for spec in models:
        success &= pull_model(spec, dry_run=dry_run)
    if success:
        print("üéâ –í—Å–µ –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã.")
    else:
        print("‚ö†Ô∏è –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –º–æ–¥–µ–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤—ã—à–µ.")
    return 0 if success else 1


def main(argv: Sequence[str]) -> int:
    parser = build_parser()
    args = parser.parse_args(argv)
    models = select_models(args)

    if not models:
        print("–ù–µ—á–µ–≥–æ —Å–∫–∞—á–∏–≤–∞—Ç—å: —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –ø—É—Å—Ç.")
        return 0

    if not args.dry_run:
        if not ensure_ollama_cli():
            return 1
        warn_if_server_unavailable(api_url=args.server_url)

    return install_models(models, dry_run=args.dry_run)


if __name__ == "__main__":
    sys.exit(main(sys.argv[1:]))
