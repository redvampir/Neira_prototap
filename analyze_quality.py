#!/usr/bin/env python3
"""–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–∞–º—è—Ç–∏ –ù–µ–π—Ä—ã"""
import json

with open('neira_memory.json', 'r', encoding='utf-8') as f:
    data = json.load(f)

print('=' * 70)
print('–ö–ê–ß–ï–°–¢–í–ï–ù–ù–´–ô –ê–ù–ê–õ–ò–ó –ü–ê–ú–Ø–¢–ò –ù–ï–ô–†–´ (–±–µ–∑ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π)')
print('=' * 70)

# –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è –ø–æ –∫–∞—á–µ—Å—Ç–≤—É
excellent = []  # –¢–æ—á–Ω—ã–µ —Ñ–∞–∫—Ç—ã, –ø–æ–ª–µ–∑–Ω—ã–µ
good = []       # –ù–æ—Ä–º–∞–ª—å–Ω—ã–µ, –Ω–æ –æ–±—â–∏–µ
mediocre = []   # –°–ª–∏—à–∫–æ–º –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–µ/—Ä–∞–∑–º—ã—Ç—ã–µ

for m in data:
    text = m.get('text', '')
    
    # –≠–≤—Ä–∏—Å—Ç–∏–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
    if any(x in text.lower() for x in ['–ø–∞–≤–µ–ª', '–Ω–µ–π—Ä–∞', '—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫', '–ø–∞—Ä—Ç–Ω—ë—Ä', '—Å–æ–∑–¥–∞—Ç–µ–ª']):
        excellent.append(m)
    elif any(x in text.lower() for x in ['–¥–æ–ª–∂–Ω', '–Ω—É–∂–Ω', '—Ç—Ä–µ–±—É–µ—Ç', '–≤–∞–∂–Ω–æ', '–ø–æ–º–æ—á—å', '–∞–Ω–∞–ª–∏–∑']):
        good.append(m)
    elif len(text) < 50:
        mediocre.append(m)
    else:
        good.append(m)

print(f'\nüìä –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–û –ö–ê–ß–ï–°–¢–í–£:')
print(f'   üåü –û—Ç–ª–∏—á–Ω—ã–µ (–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ñ–∞–∫—Ç—ã): {len(excellent)}')
print(f'   ‚úÖ –•–æ—Ä–æ—à–∏–µ (–ø–æ–ª–µ–∑–Ω—ã–µ): {len(good)}')
print(f'   ‚ö†Ô∏è –ü–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ (—Ä–∞–∑–º—ã—Ç—ã–µ): {len(mediocre)}')

print(f'\nüåü –ü–†–ò–ú–ï–†–´ –û–¢–õ–ò–ß–ù–´–• –ó–ê–ü–ò–°–ï–ô:')
for m in excellent[:10]:
    text = m.get('text', '')[:90]
    print(f'   ‚Ä¢ {text}...')

print(f'\n‚úÖ –ü–†–ò–ú–ï–†–´ –•–û–†–û–®–ò–• –ó–ê–ü–ò–°–ï–ô:')
for m in good[:10]:
    text = m.get('text', '')[:90]
    print(f'   ‚Ä¢ {text}...')

print(f'\n‚ö†Ô∏è –ü–†–ò–ú–ï–†–´ –ü–û–°–†–ï–î–°–¢–í–ï–ù–ù–´–•:')
for m in mediocre[:5]:
    text = m.get('text', '')[:90]
    print(f'   ‚Ä¢ {text}...')

# –£–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å
texts = [m.get('text', '') for m in data]
unique = len(set(texts))
print(f'\nüìà –ú–ï–¢–†–ò–ö–ò:')
print(f'   –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(data)}')
print(f'   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {unique}')
print(f'   –î—É–±–ª–∏–∫–∞—Ç–æ–≤: {len(data) - unique}')
print(f'   –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞: {sum(len(t) for t in texts) // len(texts)} —Å–∏–º–≤–æ–ª–æ–≤')

# –ö–∞—Ç–µ–≥–æ—Ä–∏–∏
categories = {}
for m in data:
    cat = m.get('category', 'unknown')
    categories[cat] = categories.get(cat, 0) + 1

print(f'\nüìÇ –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú:')
for cat, count in sorted(categories.items(), key=lambda x: -x[1]):
    pct = count * 100 // len(data)
    print(f'   {cat}: {count} ({pct}%)')

# –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è –º–æ–¥–µ–ª–∏ 7B
print(f'\n' + '=' * 70)
print('üí° –û–¶–ï–ù–ö–ê –î–õ–Ø –ú–û–î–ï–õ–ò 7B:')
print('=' * 70)
quality_score = (len(excellent) * 3 + len(good) * 2 + len(mediocre) * 0.5) / len(data)
print(f'   –ò–Ω–¥–µ–∫—Å –∫–∞—á–µ—Å—Ç–≤–∞: {quality_score:.2f}/3.0')

if quality_score > 2.0:
    verdict = "–û–¢–õ–ò–ß–ù–û - –º–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç –≤—ã—à–µ –æ–∂–∏–¥–∞–Ω–∏–π"
elif quality_score > 1.5:
    verdict = "–•–û–†–û–®–û - –ø—Ä–∏–µ–º–ª–µ–º–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–ª—è 7B"
elif quality_score > 1.0:
    verdict = "–°–†–ï–î–ù–ï - –µ—Å—Ç—å –ø—Ä–æ–±–ª–µ–º—ã —Å –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–µ–π"
else:
    verdict = "–ü–õ–û–•–û - –Ω—É–∂–Ω–∞ –¥–æ—Ä–∞–±–æ—Ç–∫–∞ –∏–ª–∏ —Å–º–µ–Ω–∞ –º–æ–¥–µ–ª–∏"

print(f'   –í–µ—Ä–¥–∏–∫—Ç: {verdict}')
