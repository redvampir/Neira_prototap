"""
ResponseEngine v1.0 ‚Äî –î–≤–∏–∂–æ–∫ –∞–≤—Ç–æ–Ω–æ–º–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤

–í–∫–ª—é—á–∞–µ—Ç:
- ResponseCache: –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤ LLM
- PathwayAutoGenerator: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ pathways –∏–∑ —á–∞—Å—Ç—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
- ResponseVariator: –í–∞—Ä–∏–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ –±–µ–∑ LLM

–¶–µ–ª—å: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç—å ‚Äî –º–∏–Ω–∏–º—É–º –æ–±—Ä–∞—â–µ–Ω–∏–π –∫ LLM
"""

import hashlib
import json
import logging
import random
import re
from collections import defaultdict
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from typing import Any, Callable, Dict, List, Optional, Set, Tuple

from neira_brain import get_brain, NeiraBrain
from local_embeddings import get_local_embedding, cosine_similarity, find_similar

logger = logging.getLogger("ResponseEngine")


# ============== Response Cache ==============

class ResponseCache:
    """
    –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤ LLM
    
    - –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ –ø–æ—Ö–æ–∂–∏–º –∑–∞–ø—Ä–æ—Å–∞–º
    - TTL –¥–ª—è —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∑–∞–ø–∏—Å–µ–π
    - –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π TTL –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–∞
    """
    
    DEFAULT_TTL_HOURS = 24 * 7  # 1 –Ω–µ–¥–µ–ª—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    MIN_SIMILARITY = 0.85  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫—ç—à–∞
    
    def __init__(self, brain: Optional[NeiraBrain] = None):
        self.brain = brain or get_brain()
        self._embedding_cache: Dict[str, Tuple[str, List[float]]] = {}  # query_hash -> (query, embedding)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º embeddings –¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–ø–∏—Å–µ–π –∫—ç—à–∞
        self._load_embeddings()
        
        logger.info(f"üì¶ ResponseCache –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {len(self._embedding_cache)} –∑–∞–ø–∏—Å–µ–π")
    
    def _load_embeddings(self):
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å embeddings –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"""
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∑–∞–ø–∏—Å–∏ –∫—ç—à–∞ –∏–∑ –ë–î
        cache_entries = self.brain.cache_search("")  # –ü—É—Å—Ç–æ–π –ø–æ–∏—Å–∫ = –≤—Å–µ –∑–∞–ø–∏—Å–∏
        
        for entry in cache_entries:
            query = entry.get('query', '')
            if query:
                emb = get_local_embedding(query)
                if emb:
                    query_hash = self._hash_query(query)
                    self._embedding_cache[query_hash] = (query, emb)
    
    def _hash_query(self, query: str) -> str:
        """–•—ç—à –∑–∞–ø—Ä–æ—Å–∞"""
        normalized = ' '.join(query.lower().split())
        return hashlib.sha256(normalized.encode()).hexdigest()[:16]
    
    def get(self, query: str) -> Optional[str]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –∏–∑ –∫—ç—à–∞
        
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –¥–ª—è –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è –ø–æ—Ö–æ–∂–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        """
        query_emb = get_local_embedding(query)
        if not query_emb:
            return None
        
        # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ –∑–∞–ø—Ä–æ—Å—ã
        candidates = list(self._embedding_cache.values())
        if not candidates:
            return None
        
        similar = find_similar(query, candidates, top_k=1, threshold=self.MIN_SIMILARITY)
        
        if similar:
            matched_query, score = similar[0]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º TTL
            entry = self.brain.cache_get(matched_query)
            if entry:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ –∏—Å—Ç—ë–∫ –ª–∏ TTL
                created_at = datetime.fromisoformat(entry['created_at'])
                ttl_hours = entry.get('ttl_hours', self.DEFAULT_TTL_HOURS)
                
                if datetime.now() - created_at < timedelta(hours=ttl_hours):
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                    self.brain.record_metric('cache_hit', 'system', {
                        'query': query[:100],
                        'matched': matched_query[:100],
                        'similarity': score
                    })
                    
                    return entry['response']
        
        return None
    
    def store(
        self,
        query: str,
        response: str,
        category: str = "general",
        quality_score: float = 0.7,
        ttl_hours: Optional[int] = None
    ):
        """
        –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç–≤–µ—Ç –≤ –∫—ç—à
        
        Args:
            query: –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            response: –û—Ç–≤–µ—Ç LLM
            category: –ö–∞—Ç–µ–≥–æ—Ä–∏—è –∑–∞–ø—Ä–æ—Å–∞
            quality_score: –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ (0-1), –≤–ª–∏—è–µ—Ç –Ω–∞ TTL
            ttl_hours: –Ø–≤–Ω—ã–π TTL –∏–ª–∏ –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –Ω–∞ –æ—Å–Ω–æ–≤–µ quality
        """
        # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π TTL: –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –∂–∏–≤—É—Ç –¥–æ–ª—å—à–µ
        if ttl_hours is None:
            ttl_hours = int(self.DEFAULT_TTL_HOURS * (0.5 + quality_score))
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
        self.brain.cache_store(
            query=query,
            response=response,
            category=category,
            ttl_hours=ttl_hours,
            metadata={'quality_score': quality_score}
        )
        
        # –û–±–Ω–æ–≤–ª—è–µ–º embedding cache
        emb = get_local_embedding(query)
        if emb:
            query_hash = self._hash_query(query)
            self._embedding_cache[query_hash] = (query, emb)
        
        logger.debug(f"üíæ Cached: '{query[:50]}...' (TTL: {ttl_hours}h)")
    
    def invalidate(self, query: str):
        """–ò–Ω–≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø–∏—Å—å –∫—ç—à–∞"""
        query_hash = self._hash_query(query)
        if query_hash in self._embedding_cache:
            del self._embedding_cache[query_hash]
        
        # TODO: –£–¥–∞–ª–∏—Ç—å –∏–∑ –ë–î –∫–æ–≥–¥–∞ –±—É–¥–µ—Ç –º–µ—Ç–æ–¥
        logger.debug(f"üóëÔ∏è Invalidated: '{query[:50]}...'")
    
    def get_stats(self) -> Dict[str, Any]:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫—ç—à–∞"""
        return {
            'entries': len(self._embedding_cache),
            'memory_mb': len(str(self._embedding_cache)) / 1024 / 1024
        }


# ============== Pathway Auto Generator ==============

class PathwayAutoGenerator:
    """
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ pathways –∏–∑ —á–∞—Å—Ç—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    
    –õ–æ–≥–∏–∫–∞:
    1. –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º –≤—Å–µ –∑–∞–ø—Ä–æ—Å—ã
    2. –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ—Ö–æ–∂–∏–µ
    3. –ï—Å–ª–∏ –≥—Ä—É–ø–ø–∞ –¥–æ—Å—Ç–∏–≥–∞–µ—Ç –ø–æ—Ä–æ–≥–∞ ‚Äî —Å–æ–∑–¥–∞—ë–º pathway
    4. Pathway —Å —à–∞–±–ª–æ–Ω–æ–º –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —É—Å–ø–µ—à–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ –≥—Ä—É–ø–ø—ã
    """
    
    MIN_GROUP_SIZE = 3  # –ú–∏–Ω–∏–º—É–º –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è pathway
    SIMILARITY_THRESHOLD = 0.8  # –ü–æ—Ä–æ–≥ —Å—Ö–æ–¥—Å—Ç–≤–∞ –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
    
    def __init__(self, brain: Optional[NeiraBrain] = None):
        self.brain = brain or get_brain()
        self._pending_queries: List[Dict[str, Any]] = []  # –û–∂–∏–¥–∞—é—â–∏–µ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
        
        logger.info("üîß PathwayAutoGenerator –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def track_query(self, query: str, response: str, success: bool = True):
        """
        –û—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è pathway
        """
        if not success or len(query) < 10 or len(response) < 20:
            return
        
        emb = get_local_embedding(query)
        if not emb:
            return
        
        self._pending_queries.append({
            'query': query,
            'response': response,
            'embedding': emb,
            'timestamp': datetime.now().isoformat()
        })
        
        # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–µ pathways
        if len(self._pending_queries) >= self.MIN_GROUP_SIZE * 2:
            self._try_generate_pathways()
    
    def _try_generate_pathways(self):
        """–ü–æ–ø—ã—Ç–∞—Ç—å—Å—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å pathways –∏–∑ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"""
        if len(self._pending_queries) < self.MIN_GROUP_SIZE:
            return
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ—Ö–æ–∂–∏–µ –∑–∞–ø—Ä–æ—Å—ã
        groups: List[List[Dict]] = []
        used = set()
        
        for i, q1 in enumerate(self._pending_queries):
            if i in used:
                continue
            
            group = [q1]
            used.add(i)
            
            for j, q2 in enumerate(self._pending_queries[i+1:], start=i+1):
                if j in used:
                    continue
                
                similarity = cosine_similarity(q1['embedding'], q2['embedding'])
                if similarity >= self.SIMILARITY_THRESHOLD:
                    group.append(q2)
                    used.add(j)
            
            if len(group) >= self.MIN_GROUP_SIZE:
                groups.append(group)
        
        # –°–æ–∑–¥–∞—ë–º pathways –∏–∑ –≥—Ä—É–ø–ø
        for group in groups:
            self._create_pathway_from_group(group)
        
        # –û—á–∏—â–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ
        self._pending_queries = [q for i, q in enumerate(self._pending_queries) if i not in used]
        
        logger.info(f"üîß –°–æ–∑–¥–∞–Ω–æ {len(groups)} pathways, –æ—Å—Ç–∞–ª–æ—Å—å pending: {len(self._pending_queries)}")
    
    def _create_pathway_from_group(self, group: List[Dict]):
        """–°–æ–∑–¥–∞—Ç—å pathway –∏–∑ –≥—Ä—É–ø–ø—ã –ø–æ—Ö–æ–∂–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"""
        if not group:
            return
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –≥—Ä—É–ø–ø—ã
        all_words: Dict[str, int] = defaultdict(int)
        for item in group:
            words = re.findall(r'[–∞-—èa-z]{3,}', item['query'].lower())
            for word in words:
                all_words[word] += 1
        
        # –ë–µ—Ä—ë–º —Å–∞–º—ã–µ —á–∞—Å—Ç—ã–µ –∫–∞–∫ —Ç—Ä–∏–≥–≥–µ—Ä—ã
        common_words = sorted(all_words.items(), key=lambda x: x[1], reverse=True)[:5]
        triggers = [w for w, _ in common_words if _ >= 2]
        
        if len(triggers) < 2:
            return
        
        # –ë–µ—Ä—ë–º —Å–∞–º—ã–π –ø–æ–¥—Ö–æ–¥—è—â–∏–π –æ—Ç–≤–µ—Ç –∫–∞–∫ —à–∞–±–ª–æ–Ω
        # (–ø–æ–∫–∞ –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–≤—ã–π, –≤ –±—É–¥—É—â–µ–º ‚Äî –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ü–µ–Ω–æ–∫)
        template_response = group[0]['response']
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º ID
        pathway_id = f"auto_{hashlib.sha256('_'.join(triggers).encode()).hexdigest()[:8]}"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ç–∞–∫–æ–π pathway –µ—â—ë –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        existing = self.brain.get_pathway(pathway_id)
        if existing:
            return
        
        # –°–æ–∑–¥–∞—ë–º
        pathway = {
            'id': pathway_id,
            'triggers': triggers,
            'response_template': template_response,
            'category': 'auto_generated',
            'tier': 'warm',
            'success_count': len(group),
            'fail_count': 0,
            'metadata': {
                'source_queries': [g['query'][:100] for g in group[:3]],
                'auto_generated': True,
                'created_at': datetime.now().isoformat()
            }
        }
        
        self.brain.save_pathway(pathway)
        
        logger.info(f"‚ú® Auto-pathway —Å–æ–∑–¥–∞–Ω: {pathway_id} (triggers: {triggers})")
    
    def force_generate(self):
        """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è pathways"""
        self._try_generate_pathways()
    
    def find_matching_pathway(self, query: str) -> Optional[Dict[str, Any]]:
        """
        –ù–∞–π—Ç–∏ pathway, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –∑–∞–ø—Ä–æ—Å—É
        
        Args:
            query: –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å pathway –∏–ª–∏ None
        """
        query_lower = query.lower()
        query_words = set(re.findall(r'[–∞-—èa-z]{3,}', query_lower))
        
        if not query_words:
            return None
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ pathways –∏–∑ –ë–î
        pathways = self.brain.query(
            "SELECT * FROM pathways WHERE confidence > 0.1"
        )
        
        best_match = None
        best_score = 0.0
        
        for row in pathways:
            try:
                triggers = json.loads(row['triggers']) if row['triggers'] else []
                if not triggers:
                    continue
                
                # –°—á–∏—Ç–∞–µ–º —Å–∫–æ–ª—å–∫–æ —Ç—Ä–∏–≥–≥–µ—Ä–æ–≤ —Å–æ–≤–ø–∞–¥–∞–µ—Ç
                triggers_set = set(t.lower() for t in triggers)
                matches = len(query_words & triggers_set)
                
                if matches == 0:
                    continue
                
                # Score –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ—Ü–µ–Ω—Ç–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
                score = matches / len(triggers_set)
                
                # –ë–æ–Ω—É—Å –∑–∞ tier
                tier = row.get('tier', 'cold')
                tier_bonus = {'hot': 0.3, 'warm': 0.15, 'cold': 0.0}.get(tier, 0.0)
                score += tier_bonus
                
                # –ë–æ–Ω—É—Å –∑–∞ success_count
                success = row.get('success_count', 0) or 0
                if success > 0:
                    score += min(0.2, success * 0.02)
                
                if score > best_score:
                    best_score = score
                    best_match = dict(row)
                    
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ pathway: {e}")
                continue
        
        if best_match and best_score >= 0.5:
            logger.debug(f"üéØ –ù–∞–π–¥–µ–Ω pathway '{best_match.get('id')}' (score: {best_score:.2f})")
            return best_match
        
        return None
    
    def maybe_create_pathway(
        self, 
        query: str, 
        response: str, 
        success: bool = True
    ) -> Optional[str]:
        """
        –°–æ–∑–¥–∞—Ç—å pathway –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–π
        
        Args:
            query: –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞
            response: –¢–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞
            success: –ë—ã–ª –ª–∏ –æ—Ç–≤–µ—Ç —É—Å–ø–µ—à–Ω—ã–º
            
        Returns:
            ID —Å–æ–∑–¥–∞–Ω–Ω–æ–≥–æ pathway –∏–ª–∏ None
        """
        if not success or len(query) < 15 or len(response) < 30:
            return None
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        words = re.findall(r'[–∞-—èa-z]{4,}', query.lower())
        if len(words) < 2:
            return None
        
        # –°—á–∏—Ç–∞–µ–º —á–∞—Å—Ç–æ—Ç—É —Å–ª–æ–≤
        word_freq: Dict[str, int] = defaultdict(int)
        for w in words:
            word_freq[w] += 1
        
        # –ë–µ—Ä—ë–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ –∫–∞–∫ —Ç—Ä–∏–≥–≥–µ—Ä—ã
        triggers = [w for w in words if word_freq[w] <= 2][:5]
        
        if len(triggers) < 2:
            return None
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø–æ—Ö–æ–∂–µ–≥–æ pathway –Ω–µ—Ç
        existing = self.find_matching_pathway(query)
        if existing:
            return None
        
        # –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π pathway
        pathway_id = f"user_{hashlib.sha256(query[:50].encode()).hexdigest()[:8]}"
        
        pathway = {
            'id': pathway_id,
            'triggers': triggers,
            'response_template': response,
            'category': 'user_generated',
            'tier': 'cold',  # –ù–æ–≤—ã–µ pathways –Ω–∞—á–∏–Ω–∞—é—Ç —Å cold
            'success_count': 1,
            'fail_count': 0,
            'confidence': 0.6,
            'metadata': {
                'source_query': query[:200],
                'created_at': datetime.now().isoformat(),
                'source': 'positive_feedback'
            }
        }
        
        self.brain.save_pathway(pathway)
        logger.info(f"‚ú® User-pathway —Å–æ–∑–¥–∞–Ω: {pathway_id} (triggers: {triggers[:3]}...)")
        
        return pathway_id


# ============== Pathway Tier Manager ==============

class PathwayTierManager:
    """
    –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç–∏—Ä–∞–º–∏ pathways (hot/warm/cold)
    
    –õ–æ–≥–∏–∫–∞ –ø—Ä–æ–¥–≤–∏–∂–µ–Ω–∏—è:
    - cold ‚Üí warm: success_count >= 3 –ò confidence >= 0.6
    - warm ‚Üí hot: success_count >= 10 –ò confidence >= 0.8 –ò fail_count < success_count/5
    - hot ‚Üí warm: fail_count > success_count/3 –ò–õ–ò confidence < 0.7
    - warm ‚Üí cold: fail_count > success_count/2 –ò–õ–ò confidence < 0.5
    
    Hot pathways –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –ø–µ—Ä–≤—ã–º–∏ (–±—ã—Å—Ç—Ä–µ–π—à–∏–π –æ—Ç–≤–µ—Ç)
    """
    
    # –ü–æ—Ä–æ–≥–∏ –¥–ª—è –ø—Ä–æ–¥–≤–∏–∂–µ–Ω–∏—è
    COLD_TO_WARM_SUCCESS = 3
    COLD_TO_WARM_CONFIDENCE = 0.6
    
    WARM_TO_HOT_SUCCESS = 10
    WARM_TO_HOT_CONFIDENCE = 0.8
    WARM_TO_HOT_FAIL_RATIO = 0.2  # fail_count < success * ratio
    
    # –ü–æ—Ä–æ–≥–∏ –¥–ª—è –ø–æ–Ω–∏–∂–µ–Ω–∏—è
    HOT_TO_WARM_FAIL_RATIO = 0.33
    HOT_TO_WARM_MIN_CONFIDENCE = 0.7
    
    WARM_TO_COLD_FAIL_RATIO = 0.5
    WARM_TO_COLD_MIN_CONFIDENCE = 0.5
    
    def __init__(self, brain: Optional[NeiraBrain] = None):
        self.brain = brain or get_brain()
        logger.info("üìä PathwayTierManager –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def evaluate_pathway(self, pathway_id: str) -> Optional[str]:
        """
        –û—Ü–µ–Ω–∏—Ç—å pathway –∏ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –Ω—É–∂–Ω–æ –ª–∏ –∏–∑–º–µ–Ω–∏—Ç—å tier
        
        Returns:
            –ù–æ–≤—ã–π tier ('hot', 'warm', 'cold') –∏–ª–∏ None –µ—Å–ª–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π –Ω–µ –Ω—É–∂–Ω–æ
        """
        pathway = self.brain.get_pathway(pathway_id)
        if not pathway:
            return None
        
        current_tier = pathway.get('tier', 'cold')
        success = pathway.get('success_count', 0) or 0
        fail = pathway.get('fail_count', 0) or 0
        confidence = pathway.get('confidence', 0.5) or 0.5
        
        new_tier = self._calculate_new_tier(current_tier, success, fail, confidence)
        
        if new_tier != current_tier:
            self._update_tier(pathway_id, new_tier)
            return new_tier
        
        return None
    
    def _calculate_new_tier(
        self, 
        current: str, 
        success: int, 
        fail: int, 
        confidence: float
    ) -> str:
        """–í—ã—á–∏—Å–ª–∏—Ç—å –Ω–æ–≤—ã–π tier –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç—Ä–∏–∫"""
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–Ω–∏–∂–µ–Ω–∏–µ —Å–Ω–∞—á–∞–ª–∞ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏)
        if current == 'hot':
            # Hot ‚Üí Warm: —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –æ—à–∏–±–æ–∫ –∏–ª–∏ –Ω–∏–∑–∫–∞—è confidence
            if success > 0 and fail > success * self.HOT_TO_WARM_FAIL_RATIO:
                return 'warm'
            if confidence < self.HOT_TO_WARM_MIN_CONFIDENCE:
                return 'warm'
        
        if current == 'warm':
            # Warm ‚Üí Cold: –æ—á–µ–Ω—å –º–Ω–æ–≥–æ –æ—à–∏–±–æ–∫ –∏–ª–∏ –æ—á–µ–Ω—å –Ω–∏–∑–∫–∞—è confidence
            if success > 0 and fail > success * self.WARM_TO_COLD_FAIL_RATIO:
                return 'cold'
            if confidence < self.WARM_TO_COLD_MIN_CONFIDENCE:
                return 'cold'
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–≤—ã—à–µ–Ω–∏–µ
        if current == 'cold':
            # Cold ‚Üí Warm
            if success >= self.COLD_TO_WARM_SUCCESS and confidence >= self.COLD_TO_WARM_CONFIDENCE:
                return 'warm'
        
        if current == 'warm':
            # Warm ‚Üí Hot
            can_promote = (
                success >= self.WARM_TO_HOT_SUCCESS and
                confidence >= self.WARM_TO_HOT_CONFIDENCE and
                (fail == 0 or fail < success * self.WARM_TO_HOT_FAIL_RATIO)
            )
            if can_promote:
                return 'hot'
        
        return current
    
    def _update_tier(self, pathway_id: str, new_tier: str):
        """–û–±–Ω–æ–≤–∏—Ç—å tier –≤ –ë–î"""
        self.brain.execute("""
            UPDATE pathways 
            SET tier = ?, last_used = CURRENT_TIMESTAMP
            WHERE id = ?
        """, (new_tier, pathway_id))
        
        logger.info(f"üéöÔ∏è Pathway '{pathway_id}' ‚Üí tier: {new_tier}")
    
    def evaluate_all(self) -> Dict[str, int]:
        """
        –û—Ü–µ–Ω–∏—Ç—å –≤—Å–µ pathways –∏ –æ–±–Ω–æ–≤–∏—Ç—å —Ç–∏—Ä—ã
        
        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–π {promoted: N, demoted: M}
        """
        stats = {'promoted': 0, 'demoted': 0, 'unchanged': 0}
        
        pathways = self.brain.query("SELECT id, tier FROM pathways")
        
        for row in pathways:
            old_tier = row['tier']
            new_tier = self.evaluate_pathway(row['id'])
            
            if new_tier is None:
                stats['unchanged'] += 1
            elif self._tier_rank(new_tier) > self._tier_rank(old_tier):
                stats['promoted'] += 1
            else:
                stats['demoted'] += 1
        
        logger.info(
            f"üìä Tier evaluation: promoted={stats['promoted']}, "
            f"demoted={stats['demoted']}, unchanged={stats['unchanged']}"
        )
        
        return stats
    
    def _tier_rank(self, tier: str) -> int:
        """–ß–∏—Å–ª–æ–≤–æ–π —Ä–∞–Ω–≥ —Ç–∏—Ä–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
        return {'cold': 0, 'warm': 1, 'hot': 2}.get(tier, 0)
    
    def get_tier_stats(self) -> Dict[str, int]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ç–∏—Ä–∞–º"""
        result = self.brain.query("""
            SELECT tier, COUNT(*) as count 
            FROM pathways 
            GROUP BY tier
        """)
        
        stats = {'hot': 0, 'warm': 0, 'cold': 0}
        for row in result:
            tier = row['tier'] or 'cold'
            stats[tier] = row['count']
        
        return stats


# ============== Response Variator ==============

class ResponseVariator:
    """
    –í–∞—Ä–∏–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ –±–µ–∑ –æ–±—Ä–∞—â–µ–Ω–∏—è –∫ LLM
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç:
    - –°–∏–Ω–æ–Ω–∏–º—ã –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–π/–ø—Ä–æ—â–∞–Ω–∏–π
    - –í–∞—Ä–∏–∞—Ü–∏–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
    - –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã
    - –ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—é
    """
    
    # –°–∏–Ω–æ–Ω–∏–º—ã –¥–ª—è –≤–∞—Ä–∏–∞—Ü–∏–π
    GREETING_VARIANTS = [
        "–ü—Ä–∏–≤–µ—Ç!", "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π!", "–ü—Ä–∏–≤–µ—Ç—Å—Ç–≤—É—é!", "–î–æ–±—Ä—ã–π –¥–µ–Ω—å!",
        "–•—ç–π!", "–†–∞–¥–∞ —Ç–µ–±—è –≤–∏–¥–µ—Ç—å!", "üëã –ü—Ä–∏–≤–µ—Ç!"
    ]
    
    POSITIVE_MARKERS = [
        "‚ú®", "üéâ", "üëç", "üí´", "üåü", "üòä", "üôÇ"
    ]
    
    THINKING_PHRASES = [
        "–•–º, –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ...", "–î–∞–π –ø–æ–¥—É–º–∞—Ç—å...", "–¢–∞–∫, –¥–∞–≤–∞–π —Ä–∞–∑–±–µ—Ä—ë–º—Å—è...",
        "–°–º–æ—Ç—Ä–∏...", "–í–æ—Ç —á—Ç–æ —è –¥—É–º–∞—é..."
    ]
    
    CONFIRMATION_PHRASES = [
        "–ì–æ—Ç–æ–≤–æ!", "–°–¥–µ–ª–∞–Ω–æ!", "–í–æ—Ç, –¥–µ—Ä–∂–∏!", "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞!",
        "–í–æ—Ç —á—Ç–æ –ø–æ–ª—É—á–∏–ª–æ—Å—å:", "–ì–æ—Ç–æ–≤–æ! üéâ"
    ]
    
    TRANSITIONS = [
        "–ö—Å—Ç–∞—Ç–∏,", "–ö —Å–ª–æ–≤—É,", "–ú–µ–∂–¥—É –ø—Ä–æ—á–∏–º,", "–ê –µ—â—ë"
    ]
    
    # –®–∞–±–ª–æ–Ω—ã —Å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏
    VARIABLE_PATTERNS = {
        '{user_name}': lambda ctx: ctx.get('user_name', '–¥—Ä—É–≥'),
        '{time_greeting}': lambda ctx: ResponseVariator._time_greeting(),
        '{random_emoji}': lambda ctx: random.choice(['üòä', 'üôÇ', 'üëã', '‚ú®', 'üí´']),
        '{random_positive}': lambda ctx: random.choice(ResponseVariator.POSITIVE_MARKERS),
    }
    
    @staticmethod
    def _time_greeting() -> str:
        """–ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤—Ä–µ–º–µ–Ω–∏ —Å—É—Ç–æ–∫"""
        hour = datetime.now().hour
        if 5 <= hour < 12:
            return "–î–æ–±—Ä–æ–µ —É—Ç—Ä–æ"
        elif 12 <= hour < 17:
            return "–î–æ–±—Ä—ã–π –¥–µ–Ω—å"
        elif 17 <= hour < 22:
            return "–î–æ–±—Ä—ã–π –≤–µ—á–µ—Ä"
        else:
            return "–î–æ–±—Ä–æ–π –Ω–æ—á–∏"
    
    @classmethod
    def variate(cls, response: str, context: Optional[Dict[str, Any]] = None) -> str:
        """
        –î–æ–±–∞–≤–∏—Ç—å –≤–∞—Ä–∏–∞—Ü–∏–∏ –∫ –æ—Ç–≤–µ—Ç—É
        
        Args:
            response: –ò—Å—Ö–æ–¥–Ω—ã–π –æ—Ç–≤–µ—Ç
            context: –ö–æ–Ω—Ç–µ–∫—Å—Ç (user_name, etc)
        
        Returns:
            –í–∞—Ä–∏–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
        """
        if not response:
            return response
        
        context = context or {}
        result = response
        
        # –ó–∞–º–µ–Ω—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
        for pattern, replacer in cls.VARIABLE_PATTERNS.items():
            if pattern in result:
                result = result.replace(pattern, replacer(context))
        
        return result
    
    @classmethod
    def generate_greeting(cls, user_name: Optional[str] = None) -> str:
        """–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ"""
        greeting = random.choice(cls.GREETING_VARIANTS)
        time_part = cls._time_greeting()
        
        if user_name:
            templates = [
                f"{greeting} {user_name}!",
                f"{time_part}, {user_name}!",
                f"üëã {user_name}! {greeting}"
            ]
        else:
            templates = [
                greeting,
                f"{time_part}!",
                f"üëã {greeting}"
            ]
        
        return random.choice(templates)
    
    @classmethod
    def add_personality(cls, response: str, mood: str = "neutral") -> str:
        """
        –î–æ–±–∞–≤–∏—Ç—å –ª–∏—á–Ω–æ—Å—Ç—å –∫ –æ—Ç–≤–µ—Ç—É
        
        Args:
            response: –û—Ç–≤–µ—Ç
            mood: neutral, happy, curious, helpful
        """
        if mood == "happy":
            if not any(e in response for e in cls.POSITIVE_MARKERS):
                response = f"{random.choice(cls.POSITIVE_MARKERS)} {response}"
        
        elif mood == "curious":
            if random.random() > 0.7:
                response = f"{random.choice(cls.THINKING_PHRASES)} {response}"
        
        elif mood == "helpful":
            if random.random() > 0.5 and not response.endswith(('!', '?')):
                response = f"{response} {random.choice(cls.CONFIRMATION_PHRASES)}"
        
        return response


# ============== Response Engine (Main Interface) ==============

class ResponseEngine:
    """
    –ì–ª–∞–≤–Ω—ã–π –¥–≤–∏–∂–æ–∫ –¥–ª—è –∞–≤—Ç–æ–Ω–æ–º–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
    
    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç: Cache + AutoGenerator + Variator + TierManager + Pathways
    """
    
    def __init__(self, brain: Optional[NeiraBrain] = None):
        self.brain = brain or get_brain()
        self.cache = ResponseCache(self.brain)
        self.auto_gen = PathwayAutoGenerator(self.brain)
        self.tier_manager = PathwayTierManager(self.brain)
        self.variator = ResponseVariator()
        
        # –ê–ª–∏–∞—Å –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∏–∑–≤–Ω–µ
        self.pathway_generator = self.auto_gen
        
        logger.info("üöÄ ResponseEngine –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def try_respond_autonomous(
        self,
        query: str,
        user_context: Optional[Dict[str, Any]] = None
    ) -> Tuple[Optional[str], str]:
        """
        –ü–æ–ø—ã—Ç–∞—Ç—å—Å—è –æ—Ç–≤–µ—Ç–∏—Ç—å –∞–≤—Ç–æ–Ω–æ–º–Ω–æ (–±–µ–∑ LLM)
        
        Returns:
            (–æ—Ç–≤–µ—Ç –∏–ª–∏ None, –∏—Å—Ç–æ—á–Ω–∏–∫ –æ—Ç–≤–µ—Ç–∞)
        """
        user_context = user_context or {}
        
        # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º pathways (hot tier ‚Äî –º–æ–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç)
        pathways = self.brain.search_pathways(query)
        for p in pathways:
            if p.get('tier') == 'hot' and p.get('success_count', 0) > 5:
                response = self.variator.variate(p['response_template'], user_context)
                
                # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
                self.brain.record_metric('pathway_hit', 'system', {
                    'pathway_id': p['id'],
                    'query': query[:100]
                })
                
                return response, f"pathway:{p['id']}"
        
        # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        cached = self.cache.get(query)
        if cached:
            response = self.variator.variate(cached, user_context)
            return response, "cache"
        
        # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º warm pathways
        for p in pathways:
            if p.get('tier') == 'warm' and p.get('success_count', 0) > 2:
                response = self.variator.variate(p['response_template'], user_context)
                return response, f"pathway:{p['id']}"
        
        # 4. –ù–µ —Å–º–æ–≥–ª–∏ –æ—Ç–≤–µ—Ç–∏—Ç—å –∞–≤—Ç–æ–Ω–æ–º–Ω–æ
        return None, "need_llm"
    
    def store_llm_response(
        self,
        query: str,
        response: str,
        success: bool = True,
        quality_score: float = 0.7
    ):
        """
        –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç–≤–µ—Ç LLM –¥–ª—è –±—É–¥—É—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        """
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
        self.cache.store(query, response, quality_score=quality_score)
        
        # –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è pathways
        self.auto_gen.track_query(query, response, success)
        
        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫—É
        self.brain.record_metric('llm_response_stored', 'system', {
            'query': query[:100],
            'success': success,
            'quality': quality_score
        })
    
    def process_feedback(self, pathway_id: str, positive: bool = True):
        """
        –û–±—Ä–∞–±–æ—Ç–∞—Ç—å feedback –∏ –æ–±–Ω–æ–≤–∏—Ç—å tier –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        
        Args:
            pathway_id: ID pathway
            positive: –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π –∏–ª–∏ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π feedback
        """
        # –û–±–Ω–æ–≤–ª—è–µ–º success/fail count —É–∂–µ –¥–µ–ª–∞–µ—Ç—Å—è –≤ handle_pathway_feedback
        # –ó–¥–µ—Å—å –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω—É–∂–Ω–æ –ª–∏ –∏–∑–º–µ–Ω–∏—Ç—å tier
        new_tier = self.tier_manager.evaluate_pathway(pathway_id)
        if new_tier:
            logger.info(f"üéöÔ∏è Pathway '{pathway_id}' promoted/demoted to: {new_tier}")
    
    def get_autonomy_stats(self) -> Dict[str, Any]:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç–∏"""
        metrics = self.brain.get_metrics_summary(hours=24 * 7)  # 7 –¥–Ω–µ–π
        tier_stats = self.tier_manager.get_tier_stats()

        autonomy_rate = metrics.get('autonomy_rate_strict', metrics.get('autonomy_rate', 0))
        autonomy_rate_weighted = metrics.get('autonomy_rate_weighted', 0)

        return {
            'cache': self.cache.get_stats(),
            'tiers': tier_stats,
            'autonomy_rate_percent': round(float(autonomy_rate), 1),
            'autonomy_rate_weighted_percent': round(float(autonomy_rate_weighted), 1),
            'definition': {
                'autonomy_strict': 'autonomous_responses / total_requests',
                'autonomy_weighted': '(autonomous_responses + hybrid_responses * 0.5) / total_requests',
                'autonomous_responses': '–û—Ç–≤–µ—Ç—ã –±–µ–∑ LLM/–≤–µ–±–∞ (cortex/–æ—Ä–≥–∞–Ω—ã/–∫—ç—à/pathways).',
                'hybrid_responses': '–û—Ç–≤–µ—Ç—ã —Å —á–∞—Å—Ç–∏—á–Ω—ã–º —É—á–∞—Å—Ç–∏–µ–º LLM.',
                'llm_calls': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞—â–µ–Ω–∏–π –∫ LLM.'
            },
            'metrics': metrics,
        }
    
    def evaluate_all_pathways(self) -> Dict[str, int]:
        """–û—Ü–µ–Ω–∏—Ç—å –≤—Å–µ pathways –∏ –æ–±–Ω–æ–≤–∏—Ç—å —Ç–∏—Ä—ã"""
        return self.tier_manager.evaluate_all()


# ============== Global Instance ==============

_response_engine: Optional[ResponseEngine] = None


def get_response_engine() -> ResponseEngine:
    """–ü–æ–ª—É—á–∏—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä ResponseEngine"""
    global _response_engine
    if _response_engine is None:
        _response_engine = ResponseEngine()
    return _response_engine


# ============== Test ==============

if __name__ == "__main__":
    import os
    os.environ["NEIRA_LOCAL_EMBEDDINGS"] = "true"
    
    print("üß™ –¢–µ—Å—Ç ResponseEngine")
    print("=" * 50)
    
    engine = get_response_engine()
    
    # –¢–µ—Å—Ç –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ (–ø–æ–∫–∞ –ø—É—Å—Ç–æ)
    response, source = engine.try_respond_autonomous("–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?", {'user_name': '–¢–µ—Å—Ç'})
    print(f"–ê–≤—Ç–æ–Ω–æ–º–Ω—ã–π –æ—Ç–≤–µ—Ç: {response} (–∏—Å—Ç–æ—á–Ω–∏–∫: {source})")
    
    # –°–∏–º—É–ª–∏—Ä—É–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ LLM –æ—Ç–≤–µ—Ç–∞
    engine.store_llm_response(
        query="–ö–∞–∫ –Ω–∞–ø–∏—Å–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é –Ω–∞ Python?",
        response="–î–ª—è –Ω–∞–ø–∏—Å–∞–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ def...",
        success=True
    )
    print("‚úÖ LLM –æ—Ç–≤–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ –∫—ç—à")
    
    # –¢–µ—Å—Ç –≤–∞—Ä–∏–∞—Ç–æ—Ä–∞
    print("\n" + "=" * 50)
    print("–¢–µ—Å—Ç ResponseVariator:")
    
    for _ in range(3):
        greeting = ResponseVariator.generate_greeting("–ê–ª–µ–∫—Å–µ–π")
        print(f"  {greeting}")
    
    test_response = "–í–æ—Ç —Ç–≤–æ–π –∫–æ–¥: print('hello')"
    varied = ResponseVariator.add_personality(test_response, mood="happy")
    print(f"\n–° –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ–º: {varied}")
    
    # –¢–µ—Å—Ç —Å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏
    template = "üëã {time_greeting}, {user_name}! {random_emoji}"
    result = ResponseVariator.variate(template, {'user_name': '–î—Ä—É–≥'})
    print(f"–®–∞–±–ª–æ–Ω —Å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏: {result}")
    
    print("\nüéâ –¢–µ—Å—Ç—ã –∑–∞–≤–µ—Ä—à–µ–Ω—ã!")
