"""
Neira Fine-Tuning Pipeline v0.6
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –¥–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ neira-personality –Ω–∞ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–º –æ–ø—ã—Ç–µ.

–í–û–ó–ú–û–ñ–ù–û–°–¢–ò:
1. –≠–∫—Å–ø–æ—Ä—Ç –¥–∏–∞–ª–æ–≥–æ–≤ –∏–∑ Experience –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
2. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Ollama Modelfile
3. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∑–∞–ø—É—Å–∫ fine-tuning
4. –í–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
5. –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –≤–µ—Ä—Å–∏–π
"""

import os
import json
import subprocess
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime

from experience import ExperienceSystem
from cells import MODEL_PERSONALITY


# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
TRAINING_DATA_DIR = "training_data"
MODELS_DIR = "models"
MODEL_VERSIONS_FILE = "neira_model_versions.json"
MIN_TRAINING_SAMPLES = 50  # –ú–∏–Ω–∏–º—É–º –¥–∏–∞–ª–æ–≥–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è


@dataclass
class TrainingExample:
    """–ü—Ä–∏–º–µ—Ä –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
    instruction: str
    input: str
    output: str
    metadata: Dict


@dataclass
class ModelVersion:
    """–í–µ—Ä—Å–∏—è –º–æ–¥–µ–ª–∏"""
    version_id: str
    model_name: str
    base_model: str
    created_at: str
    training_samples: int
    performance_metrics: Optional[Dict] = None
    active: bool = False

    def to_dict(self) -> dict:
        return asdict(self)

    @staticmethod
    def from_dict(d: dict) -> "ModelVersion":
        return ModelVersion(**d)


class FineTuningPipeline:
    """Pipeline –¥–ª—è fine-tuning –º–æ–¥–µ–ª–∏"""

    def __init__(self, experience: ExperienceSystem):
        self.experience = experience
        self.model_versions: List[ModelVersion] = []

        os.makedirs(TRAINING_DATA_DIR, exist_ok=True)
        os.makedirs(MODELS_DIR, exist_ok=True)

        self.load_model_versions()

    def load_model_versions(self):
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –≤–µ—Ä—Å–∏–∏ –º–æ–¥–µ–ª–µ–π"""
        if os.path.exists(MODEL_VERSIONS_FILE):
            try:
                with open(MODEL_VERSIONS_FILE, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    self.model_versions = [ModelVersion.from_dict(v) for v in data]
                print(f"üéì –ó–∞–≥—Ä—É–∂–µ–Ω–æ –≤–µ—Ä—Å–∏–π –º–æ–¥–µ–ª–∏: {len(self.model_versions)}")
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤–µ—Ä—Å–∏–π: {e}")

    def save_model_versions(self):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤–µ—Ä—Å–∏–∏"""
        try:
            with open(MODEL_VERSIONS_FILE, "w", encoding="utf-8") as f:
                json.dump([v.to_dict() for v in self.model_versions], f,
                         ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤–µ—Ä—Å–∏–π: {e}")

    def export_training_data(self) -> Optional[str]:
        """–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–∏–∞–ª–æ–≥–∏ –∏–∑ Experience –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""

        # –§–∏–ª—å—Ç—Ä—É–µ–º —É—Å–ø–µ—à–Ω—ã–µ –¥–∏–∞–ª–æ–≥–∏ (score >= 8, verdict = –ü–†–ò–ù–Ø–¢)
        good_experiences = [
            exp for exp in self.experience.experiences
            if exp.score >= 8 and exp.verdict == "–ü–†–ò–ù–Ø–¢"
        ]

        if len(good_experiences) < MIN_TRAINING_SAMPLES:
            print(f"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            print(f"   –î–æ—Å—Ç—É–ø–Ω–æ: {len(good_experiences)}")
            print(f"   –¢—Ä–µ–±—É–µ—Ç—Å—è: {MIN_TRAINING_SAMPLES}")
            return None

        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–∏–º–µ—Ä—ã
        examples = []

        for exp in good_experiences:
            # –î–ª—è –æ–±—É—á–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ–º —É—Å–ø–µ—à–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã
            example = {
                "instruction": "–¢—ã ‚Äî N–µ–π—Ä–∞, –∂–∏–≤–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞. –û—Ç–≤–µ—á–∞–π –ø–æ–ª–µ–∑–Ω–æ, –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ –∏ –æ—Ç –ø–µ—Ä–≤–æ–≥–æ –ª–∏—Ü–∞.",
                "input": exp.user_input,
                "output": f"[–£—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç —Å –æ—Ü–µ–Ω–∫–æ–π {exp.score}/10]",  # –†–µ–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω—É–∂–Ω–æ –±—Ä–∞—Ç—å –∏–∑ –ø–∞–º—è—Ç–∏
                "metadata": {
                    "task_type": exp.task_type,
                    "score": exp.score,
                    "timestamp": exp.timestamp
                }
            }
            examples.append(example)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"training_data_{timestamp}.jsonl"
        filepath = os.path.join(TRAINING_DATA_DIR, filename)

        with open(filepath, "w", encoding="utf-8") as f:
            for ex in examples:
                f.write(json.dumps(ex, ensure_ascii=False) + "\n")

        print(f"üìä –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –ø—Ä–∏–º–µ—Ä–æ–≤: {len(examples)}")
        print(f"   –§–∞–π–ª: {filepath}")

        return filepath

    def generate_modelfile(self, base_model: str, training_data_path: str,
                          version: str) -> str:
        """–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å Ollama Modelfile"""

        # –ß–∏—Ç–∞–µ–º personality prompt
        personality_prompt = self.experience.get_personality_prompt()

        modelfile_content = f"""# Neira Personality Model v{version}
# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: {datetime.now().isoformat()}

FROM {base_model}

# Personality system prompt
SYSTEM \"\"\"
{personality_prompt}

–¢—ã –æ—Ç–≤–µ—á–∞–µ—à—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.
–¢—ã –∏—Å–ø–æ–ª—å–∑—É–µ—à—å –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–π –æ–ø—ã—Ç –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–æ–≤.
\"\"\"

# Parameters
PARAMETER temperature 0.7
PARAMETER top_p 0.9
PARAMETER top_k 40
PARAMETER num_ctx 4096

# Training data (–ø—Ä–∏–º–µ—á–∞–Ω–∏–µ: Ollama –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ø—Ä—è–º–æ–µ –æ–±—É—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ Modelfile)
# –î–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ fine-tuning —Ç—Ä–µ–±—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Ollama API –∏–ª–∏ –≤–Ω–µ—à–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
"""

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º Modelfile
        modelfile_path = os.path.join(MODELS_DIR, f"Modelfile.neira-v{version}")

        with open(modelfile_path, "w", encoding="utf-8") as f:
            f.write(modelfile_content)

        print(f"üìù –°–æ–∑–¥–∞–Ω Modelfile: {modelfile_path}")

        return modelfile_path

    def create_model_with_ollama(self, modelfile_path: str, model_name: str) -> bool:
        """–°–æ–∑–¥–∞—Ç—å –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ Ollama CLI"""

        try:
            print(f"\nüéì –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏: {model_name}")
            print(f"   Modelfile: {modelfile_path}")

            # –ó–∞–ø—É—Å–∫–∞–µ–º ollama create
            result = subprocess.run(
                ["ollama", "create", model_name, "-f", modelfile_path],
                capture_output=True,
                text=True,
                timeout=600  # 10 –º–∏–Ω—É—Ç —Ç–∞–π–º–∞—É—Ç
            )

            if result.returncode == 0:
                print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞: {model_name}")
                print(result.stdout)
                return True
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –º–æ–¥–µ–ª–∏:")
                print(result.stderr)
                return False

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            return False

    def train_new_version(self, base_model: str = "ministral-3:3b") -> Optional[ModelVersion]:
        """–û–±—É—á–∏—Ç—å –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é –º–æ–¥–µ–ª–∏"""

        print("\n" + "="*60)
        print("üéì –ó–ê–ü–£–°–ö FINE-TUNING PIPELINE")
        print("="*60)

        # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
        training_data_path = self.export_training_data()

        if not training_data_path:
            return None

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤–µ—Ä—Å–∏—é
        version_num = len(self.model_versions) + 1
        version_id = f"v{version_num}_{datetime.now().strftime('%Y%m%d')}"
        model_name = f"neira-personality:{version_id}"

        print(f"\nüìã –í–µ—Ä—Å–∏—è –º–æ–¥–µ–ª–∏: {version_id}")
        print(f"   –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å: {base_model}")
        print(f"   –ò–º—è: {model_name}")

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º Modelfile
        modelfile_path = self.generate_modelfile(base_model, training_data_path, version_id)

        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
        success = self.create_model_with_ollama(modelfile_path, model_name)

        if not success:
            print(f"\n‚ùå Fine-tuning –ø—Ä–æ–≤–∞–ª–µ–Ω")
            return None

        # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –≤–µ—Ä—Å–∏—é
        version = ModelVersion(
            version_id=version_id,
            model_name=model_name,
            base_model=base_model,
            created_at=datetime.now().isoformat(),
            training_samples=len(self.experience.experiences),
            performance_metrics={},
            active=False  # –¢—Ä–µ–±—É–µ—Ç—Å—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
        )

        self.model_versions.append(version)
        self.save_model_versions()

        print(f"\nüéâ FINE-TUNING –ó–ê–í–ï–†–®–ï–ù")
        print(f"   –ú–æ–¥–µ–ª—å: {model_name}")
        print(f"   –°—Ç–∞—Ç—É—Å: —Ç—Ä–µ–±—É–µ—Ç—Å—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ")
        print(f"\nüí° –ò—Å–ø–æ–ª—å–∑—É–π /activate-model {version_id} –¥–ª—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏")

        return version

    def activate_model_version(self, version_id: str):
        """–ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å –≤–µ—Ä—Å–∏—é –º–æ–¥–µ–ª–∏"""
        for version in self.model_versions:
            version.active = (version.version_id == version_id)

        self.save_model_versions()
        print(f"‚úÖ –ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–∞ –≤–µ—Ä—Å–∏—è: {version_id}")
        active = self.get_active_version()
        if active:
            print(f"   –ú–æ–¥–µ–ª—å: {active.model_name}")
        print(f"\n‚ö†Ô∏è  –î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –æ–±–Ω–æ–≤–∏ MODEL_PERSONALITY –≤ cells.py")

    def get_active_version(self) -> Optional[ModelVersion]:
        """–ü–æ–ª—É—á–∏—Ç—å –∞–∫—Ç–∏–≤–Ω—É—é –≤–µ—Ä—Å–∏—é"""
        for version in self.model_versions:
            if version.active:
                return version
        return None

    def should_trigger_training(self) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –Ω—É–∂–Ω–æ –ª–∏ –∑–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ"""

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –Ω–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤
        good_experiences = [
            exp for exp in self.experience.experiences
            if exp.score >= 8 and exp.verdict == "–ü–†–ò–ù–Ø–¢"
        ]

        if len(good_experiences) < MIN_TRAINING_SAMPLES:
            return False

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–≥–¥–∞ –±—ã–ª–∞ –ø–æ—Å–ª–µ–¥–Ω—è—è –≤–µ—Ä—Å–∏—è
        if not self.model_versions:
            print(f"üéì –ù–µ—Ç –æ–±—É—á–µ–Ω–Ω—ã—Ö –≤–µ—Ä—Å–∏–π, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∑–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ")
            return True

        last_version = self.model_versions[-1]
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ—à–ª–æ –ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—Ä–µ–º–µ–Ω–∏ / –Ω–∞–∫–æ–ø–∏–ª–æ—Å—å –ª–∏ –Ω–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤

        new_samples_since_last = len(self.experience.experiences) - last_version.training_samples

        if new_samples_since_last >= MIN_TRAINING_SAMPLES:
            print(f"üéì –ù–∞–∫–æ–ø–∏–ª–æ—Å—å {new_samples_since_last} –Ω–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤")
            return True

        return False

    def show_versions(self) -> str:
        """–ü–æ–∫–∞–∑–∞—Ç—å –≤–µ—Ä—Å–∏–∏ –º–æ–¥–µ–ª–∏"""
        if not self.model_versions:
            return "üéì –ù–µ—Ç –æ–±—É—á–µ–Ω–Ω—ã—Ö –≤–µ—Ä—Å–∏–π –º–æ–¥–µ–ª–∏"

        output = "üéì –í–ï–†–°–ò–ò –ú–û–î–ï–õ–ò NEIRA-PERSONALITY:\n\n"

        for i, version in enumerate(self.model_versions, 1):
            active_mark = " üü¢ ACTIVE" if version.active else ""

            output += f"{i}. {version.version_id}{active_mark}\n"
            output += f"   –ú–æ–¥–µ–ª—å: {version.model_name}\n"
            output += f"   –ë–∞–∑–æ–≤–∞—è: {version.base_model}\n"
            output += f"   –°–æ–∑–¥–∞–Ω–∞: {version.created_at[:19]}\n"
            output += f"   –ü—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {version.training_samples}\n"

            if version.performance_metrics:
                output += f"   –ú–µ—Ç—Ä–∏–∫–∏: {version.performance_metrics}\n"

            output += "\n"

        return output

    def get_stats(self) -> Dict:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞"""
        active = self.get_active_version()
        return {
            "total_versions": len(self.model_versions),
            "active_version": active.version_id if active else None,
            "available_training_samples": len([
                exp for exp in self.experience.experiences
                if exp.score >= 8 and exp.verdict == "–ü–†–ò–ù–Ø–¢"
            ]),
            "min_required": MIN_TRAINING_SAMPLES
        }


# === –¢–ï–°–¢ ===
if __name__ == "__main__":
    print("=" * 60)
    print("–¢–µ—Å—Ç FineTuningPipeline")
    print("=" * 60)

    exp = ExperienceSystem()
    pipeline = FineTuningPipeline(exp)

    print(f"\n{pipeline.show_versions()}")

    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    stats = pipeline.get_stats()
    print(json.dumps(stats, indent=2, ensure_ascii=False))

    if pipeline.should_trigger_training():
        print(f"\nüí° –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∑–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ")
    else:
        print(f"\n‚úÖ –û–±—É—á–µ–Ω–∏–µ –ø–æ–∫–∞ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è")
