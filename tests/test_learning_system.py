#!/usr/bin/env python3
"""
–¢–µ—Å—Ç —Å–∏—Å—Ç–µ–º—ã –æ–±—É—á–µ–Ω–∏—è –ù–µ–π—Ä—ã.
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.
"""

import asyncio
import sys
import pytest
import logging
from pathlib import Path

logger = logging.getLogger(__name__)
sys.path.insert(0, str(Path(__file__).parent))


@pytest.mark.asyncio
async def test_file_extraction():
    """–¢–µ—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–∑ —Ñ–∞–π–ª–∞"""
    print("\n" + "=" * 60)
    print("üìÅ –¢–µ—Å—Ç 1: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑ —Ñ–∞–π–ª–∞")
    print("=" * 60)
    
    try:
        from content_extractor import ContentExtractor
        
        extractor = ContentExtractor()
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º README.md
        content = await extractor.extract("README.md")
        
        print(f"‚úì –§–∞–π–ª: {content.title}")
        print(f"  –¢–∏–ø: {content.source_type}")
        print(f"  –°–ª–æ–≤: {content.word_count}")
        print(f"  –ü—Ä–µ–≤—å—é: {content.content[:100]}...")
        
        return True, f"–§–∞–π–ª OK ({content.word_count} —Å–ª–æ–≤)"
    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –≤ test_file_extraction: %s", e)
        return False, f"–§–∞–π–ª: {e}"


@pytest.mark.asyncio
async def test_noise_filter():
    """–¢–µ—Å—Ç —Ñ–∏–ª—å—Ç—Ä–∞ —à—É–º–∞"""
    print("\n" + "=" * 60)
    print("üßπ –¢–µ—Å—Ç 2: –§–∏–ª—å—Ç—Ä —à—É–º–∞")
    print("=" * 60)
    
    try:
        from content_extractor import NoiseFilter
        
        # –¢–µ—Å—Ç–æ–≤—ã–π HTML —Å —à—É–º–æ–º
        noisy_text = """
        –†–µ–∫–ª–∞–º–∞: –ö—É–ø–∏—Ç–µ —Å–µ–π—á–∞—Å!
        Subscribe to our newsletter
        
        –≠—Ç–æ –ø–æ–ª–µ–∑–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å.
        –ó–¥–µ—Å—å –≤–∞–∂–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–∏.
        
        Cookie policy | Privacy | Terms
        Share on Facebook | Twitter | VK
        –ó–∞–≥—Ä—É–∑–∫–∞... Please wait
        """
        
        clean = NoiseFilter.clean_text(noisy_text)
        
        print(f"‚úì –î–æ –æ—á–∏—Å—Ç–∫–∏: {len(noisy_text)} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"‚úì –ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: {len(clean)} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"  –†–µ–∑—É–ª—å—Ç–∞—Ç: {clean[:100]}...")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —à—É–º —É–¥–∞–ª—ë–Ω
        assert "–†–µ–∫–ª–∞–º–∞" not in clean or len(clean) < len(noisy_text)
        assert "Subscribe" not in clean or len(clean) < len(noisy_text)
        
        return True, "–§–∏–ª—å—Ç—Ä —à—É–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç"
    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –≤ test_noise_filter: %s", e)
        return False, f"–§–∏–ª—å—Ç—Ä: {e}"


@pytest.mark.asyncio
async def test_chunking():
    """–¢–µ—Å—Ç —Ä–∞–∑–±–∏–µ–Ω–∏—è –Ω–∞ —á–∞–Ω–∫–∏"""
    print("\n" + "=" * 60)
    print("‚úÇÔ∏è –¢–µ—Å—Ç 3: –†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ —á–∞–Ω–∫–∏")
    print("=" * 60)
    
    try:
        from content_extractor import LearningManager
        
        manager = LearningManager()
        
        # –î–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        long_text = "–≠—Ç–æ —Ç–µ—Å—Ç–æ–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ. " * 100
        
        chunks = manager._chunk_content(long_text, chunk_size=500, overlap=50)
        
        print(f"‚úì –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç: {len(long_text)} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"‚úì –ß–∞–Ω–∫–æ–≤ —Å–æ–∑–¥–∞–Ω–æ: {len(chunks)}")
        print(f"‚úì –†–∞–∑–º–µ—Ä –ø–µ—Ä–≤–æ–≥–æ —á–∞–Ω–∫–∞: {len(chunks[0])} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —á–∞–Ω–∫–∏ –Ω–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–µ
        for i, chunk in enumerate(chunks):
            assert len(chunk) <= 600, f"–ß–∞–Ω–∫ {i} —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π: {len(chunk)}"
        
        return True, f"Chunking OK ({len(chunks)} —á–∞–Ω–∫–æ–≤)"
    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –≤ test_chunking: %s", e)
        return False, f"Chunking: {e}"


@pytest.mark.asyncio
async def test_summary():
    """–¢–µ—Å—Ç —Å–æ–∑–¥–∞–Ω–∏—è summary"""
    print("\n" + "=" * 60)
    print("üìù –¢–µ—Å—Ç 4: –°–æ–∑–¥–∞–Ω–∏–µ summary")
    print("=" * 60)
    
    try:
        from content_extractor import LearningManager
        
        manager = LearningManager()
        
        text = """
        –í–≤–µ–¥–µ–Ω–∏–µ –≤ Python. Python - —ç—Ç–æ –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π —è–∑—ã–∫ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è.
        –û–Ω –±—ã–ª —Å–æ–∑–¥–∞–Ω –ì–≤–∏–¥–æ –≤–∞–Ω –†–æ—Å—Å—É–º–æ–º –≤ 1991 –≥–æ–¥—É.
        Python –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –≤–µ–±-—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏, –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.
        –í–∞–∂–Ω–æ –ø–æ–Ω–∏–º–∞—Ç—å –æ—Å–Ω–æ–≤—ã —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞ Python.
        –ì–ª–∞–≤–Ω–æ–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ Python - —ç—Ç–æ —á–∏—Ç–∞–µ–º–æ—Å—Ç—å –∫–æ–¥–∞.
        Python –∏–º–µ–µ—Ç –±–æ–≥–∞—Ç—É—é —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –±–∏–±–ª–∏–æ—Ç–µ–∫—É.
        –í—ã–≤–æ–¥: Python –æ—Ç–ª–∏—á–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö –ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç–æ–≤.
        """
        
        summary = manager._create_summary(text, max_sentences=3)
        
        print(f"‚úì –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"‚úì Summary: {len(summary)} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"  –†–µ–∑—É–ª—å—Ç–∞—Ç: {summary}")
        
        assert len(summary) < len(text)
        
        return True, "Summary OK"
    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –≤ test_summary: %s", e)
        return False, f"Summary: {e}"


@pytest.mark.asyncio
async def test_learning_history():
    """–¢–µ—Å—Ç –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è"""
    print("\n" + "=" * 60)
    print("üìö –¢–µ—Å—Ç 5: –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è")
    print("=" * 60)
    
    try:
        from content_extractor import LearningManager
        
        manager = LearningManager()
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats = manager.get_learning_stats()
        
        print(f"‚úì –í—Å–µ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {stats['total_sources']}")
        print(f"‚úì –í—Å–µ–≥–æ —Å–ª–æ–≤: {stats['total_words']}")
        print(f"‚úì –ü–æ —Ç–∏–ø–∞–º: {stats['by_type']}")
        print(f"‚úì –ü–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º: {stats['by_category']}")
        
        return True, f"–ò—Å—Ç–æ—Ä–∏—è OK ({stats['total_sources']} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤)"
    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –≤ test_learning_history: %s", e)
        return False, f"–ò—Å—Ç–æ—Ä–∏—è: {e}"


@pytest.mark.asyncio
async def test_learn_from_file():
    """–¢–µ—Å—Ç –ø–æ–ª–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ –æ–±—É—á–µ–Ω–∏—è –∏–∑ —Ñ–∞–π–ª–∞"""
    print("\n" + "=" * 60)
    print("üéì –¢–µ—Å—Ç 6: –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è")
    print("=" * 60)
    
    try:
        from content_extractor import LearningManager
        
        manager = LearningManager()
        
        # –û–±—É—á–∞–µ–º—Å—è –∏–∑ README
        result = await manager.learn_from_source(
            "README.md",
            category="documentation",
            summarize=True
        )
        
        print(f"‚úì –£—Å–ø–µ—Ö: {result['success']}")
        print(f"‚úì –ù–∞–∑–≤–∞–Ω–∏–µ: {result.get('title', 'N/A')}")
        print(f"‚úì –°–ª–æ–≤: {result.get('word_count', 0)}")
        print(f"‚úì –ß–∞–Ω–∫–æ–≤: {result.get('chunks', 0)}")
        
        if result.get('summary'):
            print(f"‚úì Summary: {result['summary'][:100]}...")
        
        return True, f"–û–±—É—á–µ–Ω–∏–µ OK ({result.get('word_count', 0)} —Å–ª–æ–≤)"
    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –≤ test_learn_from_file: %s", e)
        return False, f"–û–±—É—á–µ–Ω–∏–µ: {e}"


@pytest.mark.asyncio
async def test_web_extraction():
    """–¢–µ—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü—ã (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)"""
    print("\n" + "=" * 60)
    print("üåê –¢–µ—Å—Ç 7: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü—ã")
    print("=" * 60)
    
    try:
        from content_extractor import ContentExtractor
        
        extractor = ContentExtractor()
        
        # –ü—Ä–æ—Å—Ç–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –¥–ª—è —Ç–µ—Å—Ç–∞
        url = "https://httpbin.org/html"
        
        content = await extractor.extract(url)
        
        print(f"‚úì URL: {url}")
        print(f"‚úì –ó–∞–≥–æ–ª–æ–≤–æ–∫: {content.title}")
        print(f"‚úì –°–ª–æ–≤: {content.word_count}")
        print(f"‚úì –î–æ–º–µ–Ω: {content.metadata.get('domain', 'N/A')}")
        
        return True, f"Web OK ({content.word_count} —Å–ª–æ–≤)"
    except ImportError as e:
        return None, f"Web: —Ç—Ä–µ–±—É–µ—Ç—Å—è beautifulsoup4"
    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –≤ test_web_extraction: %s", e)
        return False, f"Web: {e}"


async def main():
    """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤"""
    print("\n" + "üéì" * 30)
    print("   –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –°–ò–°–¢–ï–ú–´ –û–ë–£–ß–ï–ù–ò–Ø –ù–ï–ô–†–´")
    print("üéì" * 30)
    
    results = []
    
    # –ë–∞–∑–æ–≤—ã–µ —Ç–µ—Å—Ç—ã
    results.append(await test_file_extraction())
    results.append(await test_noise_filter())
    results.append(await test_chunking())
    results.append(await test_summary())
    results.append(await test_learning_history())
    results.append(await test_learn_from_file())
    
    # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç –≤–µ–±–∞
    web_result = await test_web_extraction()
    if web_result[0] is not None:
        results.append(web_result)
    else:
        print(f"‚ö†Ô∏è {web_result[1]}")
    
    # –ò—Ç–æ–≥–∏
    print("\n" + "=" * 60)
    print("üìä –ò–¢–û–ì–ò –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø")
    print("=" * 60)
    
    passed = sum(1 for ok, _ in results if ok)
    total = len(results)
    
    for i, (ok, msg) in enumerate(results, 1):
        status = "‚úÖ" if ok else "‚ùå"
        print(f"{status} –¢–µ—Å—Ç {i}: {msg}")
    
    print(f"\n{'=' * 60}")
    print(f"–ü—Ä–æ–π–¥–µ–Ω–æ: {passed}/{total}")
    
    if passed == total:
        print("üéâ –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã!")
    elif passed >= total - 1:
        print("‚ú® –ü–æ—á—Ç–∏ –≤—Å—ë —Ä–∞–±–æ—Ç–∞–µ—Ç!")
    else:
        print("‚ö†Ô∏è –ï—Å—Ç—å –ø—Ä–æ–±–ª–µ–º—ã")
    
    return passed >= total - 1


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)
