"""
–ê–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ Neira
- –£–¥–∞–ª—è–µ—Ç —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ (>30 –¥–Ω–µ–π)
- –£–¥–∞–ª—è–µ—Ç –∑–∞—Ü–∏–∫–ª–µ–Ω–Ω—ã–µ –ø–æ–≤—Ç–æ—Ä—ã
- –£–¥–∞–ª—è–µ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏
- –°–∂–∏–º–∞–µ—Ç –∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—É—é –ø–∞–º—è—Ç—å
"""
import json
from datetime import datetime, timedelta
from pathlib import Path
from collections import defaultdict


def load_memory(file_path):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –ø–∞–º—è—Ç–∏ –∏–∑ JSON"""
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def save_memory(file_path, data):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏ –≤ JSON"""
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def create_backup(file_path):
    """–°–æ–∑–¥–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞ –ø–µ—Ä–µ–¥ –æ—á–∏—Å—Ç–∫–æ–π"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_dir = Path("memory_backups")
    backup_dir.mkdir(exist_ok=True)
    
    backup_path = backup_dir / f"{file_path.stem}_backup_{timestamp}.json"
    data = load_memory(file_path)
    save_memory(backup_path, data)
    print(f"üíæ –ë—ç–∫–∞–ø —Å–æ–∑–¥–∞–Ω: {backup_path}")
    return backup_path


def clean_main_memory(keep_days=30, keep_recent=50):
    """
    –û—á–∏—Å—Ç–∫–∞ –æ—Å–Ω–æ–≤–Ω–æ–π –ø–∞–º—è—Ç–∏
    
    Args:
        keep_days: –°–∫–æ–ª—å–∫–æ –¥–Ω–µ–π —Ö—Ä–∞–Ω–∏—Ç—å (—Å—Ç–∞—Ä—à–µ —É–¥–∞–ª—è–µ–º)
        keep_recent: –°–∫–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –∑–∞–ø–∏—Å–µ–π –≤—Å–µ–≥–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å
    """
    file_path = Path("neira_memory.json")
    
    if not file_path.exists():
        print(f"‚ùå –§–∞–π–ª {file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    # –ë—ç–∫–∞–ø
    create_backup(file_path)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞
    memories = load_memory(file_path)
    original_count = len(memories)
    
    print(f"\n{'='*80}")
    print(f"üßπ –û–ß–ò–°–¢–ö–ê –û–°–ù–û–í–ù–û–ô –ü–ê–ú–Ø–¢–ò")
    print(f"{'='*80}")
    print(f"–ó–∞–ø–∏—Å–µ–π –¥–æ –æ—á–∏—Å—Ç–∫–∏: {original_count}")
    
    # –§–∏–ª—å—Ç—Ä –ø–æ –¥–∞—Ç–µ
    cutoff_date = datetime.now() - timedelta(days=keep_days)
    
    filtered = []
    removed_old = 0
    removed_technical = 0
    removed_loops = 0
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –º–∏–Ω—É—Ç–∞–º –¥–ª—è –¥–µ—Ç–µ–∫—Ç–∞ –∑–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏—è
    by_minute = defaultdict(list)
    
    for mem in memories:
        timestamp_str = mem.get("timestamp", "")
        text = mem.get("text", mem.get("fact", ""))  # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –æ–±–æ–∏—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤
        
        # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—É
        try:
            mem_date = datetime.fromisoformat(timestamp_str.replace("Z", "+00:00"))
        except:
            # –ï—Å–ª–∏ –¥–∞—Ç–∞ –∫—Ä–∏–≤–∞—è ‚Äî —É–¥–∞–ª—è–µ–º
            removed_old += 1
            continue
        
        # –°—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ —É–¥–∞–ª—è–µ–º (–∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö keep_recent)
        if mem_date < cutoff_date and len(filtered) >= keep_recent:
            removed_old += 1
            continue
        
        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏
        technical_garbage = [
            "–Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å", "—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä", "–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ",
            "import asyncio", "class ", "def ", "–±–∏–æ—Ö–∏–º–∏—á–µ—Å–∫–∏–π –ø—Ä–æ—Ü–µ—Å—Å",
            "–≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫", "–æ–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å", "—Å–∏–Ω–∞–ø—Å", "—Ö–ª–æ—Ä–æ–ø–ª–∞—Å—Ç"
        ]
        
        if any(garbage in text.lower() for garbage in technical_garbage):
            # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 20 –∑–∞–ø–∏—Å–µ–π ‚Äî —É–¥–∞–ª—è–µ–º
            if len(memories) - memories.index(mem) > 20:
                removed_technical += 1
                continue
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –º–∏–Ω—É—Ç–µ
        minute_key = timestamp_str[:16]  # YYYY-MM-DDTHH:MM
        by_minute[minute_key].append(text)
        
        filtered.append(mem)
    
    # –î–µ—Ç–µ–∫—Ç –∑–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏—è (>5 –∑–∞–ø–∏—Å–µ–π –≤ –º–∏–Ω—É—Ç—É)
    loop_minutes = {k: v for k, v in by_minute.items() if len(v) > 5}
    
    if loop_minutes:
        print(f"\n‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∑–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏–µ –≤ {len(loop_minutes)} –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ç–æ—á–∫–∞—Ö:")
        
        final = []
        for mem in filtered:
            minute_key = mem.get("timestamp", "")[:16]
            mem_text = mem.get("text", mem.get("fact", ""))
            
            if minute_key in loop_minutes:
                # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—É—é –∑–∞–ø–∏—Å—å –∏–∑ –∑–∞—Ü–∏–∫–ª–µ–Ω–Ω–æ–π –º–∏–Ω—É—Ç—ã
                if by_minute[minute_key].index(mem_text) == 0:
                    final.append(mem)
                else:
                    removed_loops += 1
            else:
                final.append(mem)
        
        filtered = final
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    save_memory(file_path, filtered)
    
    final_count = len(filtered)
    total_removed = original_count - final_count
    
    print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
    print(f"  ‚Ä¢ –£–¥–∞–ª–µ–Ω–æ —Å—Ç–∞—Ä—ã—Ö (>{keep_days} –¥–Ω–µ–π): {removed_old}")
    print(f"  ‚Ä¢ –£–¥–∞–ª–µ–Ω–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö: {removed_technical}")
    print(f"  ‚Ä¢ –£–¥–∞–ª–µ–Ω–æ –∑–∞—Ü–∏–∫–ª–µ–Ω–Ω—ã—Ö: {removed_loops}")
    print(f"  ‚Ä¢ –í—Å–µ–≥–æ —É–¥–∞–ª–µ–Ω–æ: {total_removed}")
    print(f"  ‚Ä¢ –û—Å—Ç–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–µ–π: {final_count}")
    print(f"  ‚Ä¢ –≠–∫–æ–Ω–æ–º–∏—è: {((original_count - final_count) / original_count * 100):.1f}%")


def clean_short_term(keep_recent=10):
    """–û—á–∏—Å—Ç–∫–∞ –∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω–æ–π –ø–∞–º—è—Ç–∏ ‚Äî –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N"""
    file_path = Path("neira_short_term.json")
    
    if not file_path.exists():
        print(f"‚ùå –§–∞–π–ª {file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    create_backup(file_path)
    
    memories = load_memory(file_path)
    original_count = len(memories)
    
    print(f"\n{'='*80}")
    print(f"üßπ –û–ß–ò–°–¢–ö–ê –ö–†–ê–¢–ö–û–°–†–û–ß–ù–û–ô –ü–ê–ú–Ø–¢–ò")
    print(f"{'='*80}")
    print(f"–ó–∞–ø–∏—Å–µ–π –¥–æ –æ—á–∏—Å—Ç–∫–∏: {original_count}")
    
    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N
    filtered = memories[-keep_recent:]
    
    save_memory(file_path, filtered)
    
    print(f"  ‚Ä¢ –£–¥–∞–ª–µ–Ω–æ: {original_count - len(filtered)}")
    print(f"  ‚Ä¢ –û—Å—Ç–∞–ª–æ—Å—å: {len(filtered)}")


def clean_experience(keep_recent=50):
    """–û—á–∏—Å—Ç–∫–∞ –æ–ø—ã—Ç–∞ ‚Äî —É–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –∏ –¥—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è —É—Ä–æ–∫–∏"""
    file_path = Path("neira_experience.json")
    
    if not file_path.exists():
        print(f"‚ùå –§–∞–π–ª {file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    create_backup(file_path)
    
    experiences = load_memory(file_path)
    original_count = len(experiences)
    
    print(f"\n{'='*80}")
    print(f"üßπ –û–ß–ò–°–¢–ö–ê –û–ü–´–¢–ê")
    print(f"{'='*80}")
    print(f"–ó–∞–ø–∏—Å–µ–π –¥–æ –æ—á–∏—Å—Ç–∫–∏: {original_count}")
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–∏–ø—É –∑–∞–¥–∞—á–∏
    by_task = defaultdict(list)
    
    for exp in experiences:
        task_type = exp.get("task_type", "unknown")
        by_task[task_type].append(exp)
    
    # –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏ –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5
    filtered = []
    for task_type, exps in by_task.items():
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ
        sorted_exps = sorted(
            exps,
            key=lambda x: x.get("timestamp", ""),
            reverse=True
        )
        # –ë–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5
        filtered.extend(sorted_exps[:5])
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ
    filtered = sorted(filtered, key=lambda x: x.get("timestamp", ""))
    
    save_memory(file_path, filtered)
    
    print(f"  ‚Ä¢ –£–¥–∞–ª–µ–Ω–æ: {original_count - len(filtered)}")
    print(f"  ‚Ä¢ –û—Å—Ç–∞–ª–æ—Å—å: {len(filtered)}")
    print(f"  ‚Ä¢ –¢–∏–ø–æ–≤ –∑–∞–¥–∞—á: {len(by_task)}")


def clean_chat_contexts(keep_recent_messages=20):
    """–û—á–∏—Å—Ç–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤ —á–∞—Ç–æ–≤ ‚Äî —Å–∂–∏–º–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ –∏—Å—Ç–æ—Ä–∏–∏"""
    file_path = Path("neira_chat_contexts.json")
    
    if not file_path.exists():
        print(f"‚ùå –§–∞–π–ª {file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    create_backup(file_path)
    
    contexts = load_memory(file_path)
    
    print(f"\n{'='*80}")
    print(f"üßπ –û–ß–ò–°–¢–ö–ê –ö–û–ù–¢–ï–ö–°–¢–û–í –ß–ê–¢–û–í")
    print(f"{'='*80}")
    
    total_messages_before = 0
    total_messages_after = 0
    
    for chat_id, chat_data in contexts.items():
        history = chat_data.get("context_history", [])
        total_messages_before += len(history)
        
        # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —Å–æ–æ–±—â–µ–Ω–∏–π
        if len(history) > keep_recent_messages:
            chat_data["context_history"] = history[-keep_recent_messages:]
            total_messages_after += keep_recent_messages
        else:
            total_messages_after += len(history)
    
    save_memory(file_path, contexts)
    
    print(f"  ‚Ä¢ –°–æ–æ–±—â–µ–Ω–∏–π –¥–æ: {total_messages_before}")
    print(f"  ‚Ä¢ –°–æ–æ–±—â–µ–Ω–∏–π –ø–æ—Å–ª–µ: {total_messages_after}")
    print(f"  ‚Ä¢ –£–¥–∞–ª–µ–Ω–æ: {total_messages_before - total_messages_after}")


def remove_old_backups(keep_last=3):
    """–£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –±—ç–∫–∞–ø—ã, –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N"""
    backup_dir = Path("memory_backups")
    
    if not backup_dir.exists():
        return
    
    backups = sorted(backup_dir.glob("*.json"), key=lambda p: p.stat().st_mtime, reverse=True)
    
    if len(backups) <= keep_last:
        return
    
    print(f"\n{'='*80}")
    print(f"üßπ –û–ß–ò–°–¢–ö–ê –°–¢–ê–†–´–• –ë–≠–ö–ê–ü–û–í")
    print(f"{'='*80}")
    print(f"–ù–∞–π–¥–µ–Ω–æ –±—ç–∫–∞–ø–æ–≤: {len(backups)}")
    
    removed = 0
    for backup in backups[keep_last:]:
        backup.unlink()
        removed += 1
    
    print(f"  ‚Ä¢ –£–¥–∞–ª–µ–Ω–æ: {removed}")
    print(f"  ‚Ä¢ –û—Å—Ç–∞–ª–æ—Å—å: {keep_last}")


if __name__ == "__main__":
    print("üß† –ê–ì–†–ï–°–°–ò–í–ù–ê–Ø –û–ß–ò–°–¢–ö–ê –ü–ê–ú–Ø–¢–ò NEIRA")
    print(f"–î–∞—Ç–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    # 1. –û—Å–Ω–æ–≤–Ω–∞—è –ø–∞–º—è—Ç—å (—Å—Ç–∞—Ä—à–µ 30 –¥–Ω–µ–π —É–¥–∞–ª—è–µ–º)
    clean_main_memory(keep_days=30, keep_recent=100)
    
    # 2. –ö—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω–∞—è –ø–∞–º—è—Ç—å (—Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10)
    clean_short_term(keep_recent=10)
    
    # 3. –û–ø—ã—Ç (–ø–æ 5 –∑–∞–ø–∏—Å–µ–π –Ω–∞ —Ç–∏–ø –∑–∞–¥–∞—á–∏)
    clean_experience(keep_recent=50)
    
    # 4. –ö–æ–Ω—Ç–µ–∫—Å—Ç—ã —á–∞—Ç–æ–≤ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 20 —Å–æ–æ–±—â–µ–Ω–∏–π)
    clean_chat_contexts(keep_recent_messages=20)
    
    # 5. –°—Ç–∞—Ä—ã–µ –±—ç–∫–∞–ø—ã (–æ—Å—Ç–∞–≤–ª—è–µ–º 3 –ø–æ—Å–ª–µ–¥–Ω–∏—Ö)
    remove_old_backups(keep_last=3)
    
    print(f"\n{'='*80}")
    print("‚úÖ –û–ß–ò–°–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê")
    print(f"{'='*80}")
    
    # –§–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã
    files = ["neira_memory.json", "neira_experience.json", "neira_short_term.json", "neira_chat_contexts.json"]
    print("\nüìä –†–ê–ó–ú–ï–†–´ –§–ê–ô–õ–û–í –ü–û–°–õ–ï –û–ß–ò–°–¢–ö–ò:")
    for fname in files:
        path = Path(fname)
        if path.exists():
            size_kb = path.stat().st_size / 1024
            print(f"  ‚Ä¢ {fname}: {size_kb:.2f} KB")
