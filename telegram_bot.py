"""–¢–µ–ª–µ–≥—Ä–∞–º-–±–æ—Ç –¥–ª—è Neira v0.7: –æ–±—â–µ–Ω–∏–µ, –æ–±—É—á–µ–Ω–∏–µ, —Å–∞–º–æ—Å–æ–∑–Ω–∞–Ω–∏–µ, –∫–∞—Ä—Ç–∏–Ω–∫–∏ –∏ –∑–∞—â–∏—Ç–∞."""

import asyncio
import inspect
import ipaddress
import logging
import os
import re
import time
import hashlib
import secrets
import base64
import io
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional, Set
from functools import wraps
from datetime import datetime
from urllib.parse import urlparse

import sys

try:
    sys.stdout.reconfigure(encoding="utf-8", errors="replace")
    sys.stderr.reconfigure(encoding="utf-8", errors="replace")
except Exception:
    pass

import aiohttp
from dotenv import load_dotenv
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup, Message
from telegram.constants import ChatAction, ParseMode
from telegram.error import TimedOut, NetworkError, InvalidToken
from telegram.ext import (
    Application,
    CommandHandler,
    ContextTypes,
    MessageHandler,
    MessageReactionHandler,
    CallbackQueryHandler,
    filters,
)

# –õ–æ–∫–∞–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã
from backend.neira_wrapper import NeiraWrapper
from cell_factory import CellFactory
from parallel_thinking import parallel_mind
from enhanced_auth import auth_system
from telegram_settings import TelegramSettings, load_telegram_settings, save_telegram_settings
from telegram_network import (
    TelegramNetworkConfig,
    compute_backoff_seconds,
    load_telegram_network_config,
    sanitize_url_for_log,
)
from memory_system import EMBED_MODEL
from autonomous_learning import AutonomousLearningSystem
from emoji_feedback import EmojiFeedbackSystem, EmojiMap
from organ_creation_engine import OrganCreationEngine, train_neira_from_letter

# üß¨ –ò—Å–ø–æ–ª–Ω—è–µ–º—ã–µ –æ—Ä–≥–∞–Ω—ã v1.0
try:
    from executable_organs import (
        get_organ_registry, ExecutableOrganRegistry,
        FeedbackType, OrganSandbox
    )
    EXECUTABLE_ORGANS_AVAILABLE = True
except ImportError as e:
    EXECUTABLE_ORGANS_AVAILABLE = False
    print(f"‚ö†Ô∏è ExecutableOrgans –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã: {e}")

# üß† –≠—Ç–∏—á–µ—Å–∫–∏–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ (–ø—Ä–∏–Ω—Ü–∏–ø—ã –∏–∑ LETTER_TO_NEIRA)
try:
    from ethical_framework import (
        EthicalFramework, analyze_ethically, 
        ResponseStrategy as EthicalStrategy, RiskLevel, Intent
    )
    from human_in_the_loop import (
        HumanInTheLoop, get_hil_manager, escalate_to_creator,
        EscalationType, EscalationStatus
    )
    ETHICAL_FRAMEWORK_AVAILABLE = True
except ImportError as e:
    ETHICAL_FRAMEWORK_AVAILABLE = False
    print(f"‚ö†Ô∏è EthicalFramework –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")

# üîó Phase 2: NeiraClient –¥–ª—è —Å–≤—è–∑–∏ —Å —Å–µ—Ä–≤–µ—Ä–æ–º
try:
    from neira_client import NeiraClient, get_client
    NEIRA_CLIENT_AVAILABLE = True
except ImportError:
    NEIRA_CLIENT_AVAILABLE = False
    print("‚ö†Ô∏è NeiraClient –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - feedback –Ω–µ –±—É–¥–µ—Ç —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å—Å—è —Å —Å–µ—Ä–≤–µ—Ä–æ–º")

# üß† Neira Cortex v2.0 - –ê–≤—Ç–æ–Ω–æ–º–Ω–∞—è –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞
try:
    from neira_cortex import NeiraCortex, ProcessingResult, ResponseStrategy
    CORTEX_AVAILABLE = True
except ImportError:
    CORTEX_AVAILABLE = False
    print("‚ö†Ô∏è Neira Cortex –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - –∏—Å–ø–æ–ª—å–∑—É–µ–º legacy —Ä–µ–∂–∏–º")

# üö¶ Rate Limiting - –∑–∞—â–∏—Ç–∞ –æ—Ç —Å–ø–∞–º–∞
try:
    from rate_limiter import check_rate_limit, record_request, RateLimitExceeded
    RATE_LIMITER_AVAILABLE = True
except ImportError:
    RATE_LIMITER_AVAILABLE = False
    print("‚ö†Ô∏è Rate Limiter –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")

# ü™û –ù–æ–≤—ã–µ —Å–∏—Å—Ç–µ–º—ã —Å–∞–º–æ—Å–æ–∑–Ω–∞–Ω–∏—è (v0.8)
try:
    from emotional_mirror import get_emotional_mirror, MoodState, EnergyLevel
    from error_journal import get_error_journal, ErrorCategory, ErrorSeverity
    from emotional_memory import get_emotional_memory, EmotionalTone, RelationshipStage
    from proactive_system import get_proactive_system, InitiativeType
    from creative_engine import get_creative_engine, CreativeForm
    CONSCIOUSNESS_SYSTEMS_AVAILABLE = True
except ImportError as e:
    CONSCIOUSNESS_SYSTEMS_AVAILABLE = False
    print(f"‚ö†Ô∏è –°–∏—Å—Ç–µ–º—ã —Å–∞–º–æ—Å–æ–∑–Ω–∞–Ω–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã: {e}")


# === –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ===
_LOG_FORMAT = "%(asctime)s [%(levelname)s] %(name)s: %(message)s"


def _get_base_dir() -> Path:
    """–ü–æ–ª—É—á–∏—Ç—å –±–∞–∑–æ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–∞ (—Ä–∞–±–æ—Ç–∞–µ—Ç –∏ —á–µ—Ä–µ–∑ exec, –∏ –ø—Ä–∏ –ø—Ä—è–º–æ–º –∑–∞–ø—É—Å–∫–µ)."""
    if '__file__' in globals():
        return Path(__file__).resolve().parent
    # fallback: —Ç–µ–∫—É—â–∞—è —Ä–∞–±–æ—á–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è
    return Path.cwd()


def _configure_logging() -> Path:
    log_path = os.getenv("NEIRA_TG_LOG_FILE", "artifacts/telegram_bot.log")
    log_file = Path(log_path)
    if not log_file.is_absolute():
        log_file = _get_base_dir() / log_file
    log_file.parent.mkdir(parents=True, exist_ok=True)

    handlers = [
        logging.StreamHandler(),
        logging.FileHandler(log_file, encoding="utf-8"),
    ]
    logging.basicConfig(
        level=logging.INFO,
        format=_LOG_FORMAT,
        handlers=handlers,
        force=True,
    )
    logging.getLogger(__name__).info("üìù –õ–æ–≥ Telegram-–±–æ—Ç–∞: %s", log_file)
    return log_file


load_dotenv()
_LOG_PATH = _configure_logging()

# –°–Ω–∏–∂–∞–µ–º —à—É–º –≤ –ª–æ–≥–∞—Ö –æ—Ç HTTP-–∫–ª–∏–µ–Ω—Ç–∞ (–∏–Ω–∞—á–µ getUpdates –∑–∞–±–∏–≤–∞–µ—Ç –≤—Å—ë).
_httpx_level_name = os.getenv("NEIRA_HTTPX_LOG_LEVEL", "WARNING").upper()
_httpx_level = getattr(logging, _httpx_level_name, logging.WARNING)
logging.getLogger("httpx").setLevel(_httpx_level)
logging.getLogger("httpcore").setLevel(_httpx_level)

try:
    _TYPING_THROTTLE_SECONDS = float(os.getenv("NEIRA_TG_TYPING_THROTTLE_SECONDS", "3.0"))
except ValueError:
    _TYPING_THROTTLE_SECONDS = 3.0

BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
if not BOT_TOKEN:
    raise RuntimeError(
        "–ù–µ –∑–∞–¥–∞–Ω TELEGRAM_BOT_TOKEN. –£–∫–∞–∂–∏—Ç–µ –µ–≥–æ –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è "
        "–∏–ª–∏ –≤ —Ñ–∞–π–ª–µ .env (—Å–º. .env.example)."
    )


class _SensitiveDataFilter(logging.Filter):
    """–§–∏–ª—å—Ç—Ä –ª–æ–≥–æ–≤: —Å–∫—Ä—ã–≤–∞–µ—Ç —Ç–æ–∫–µ–Ω—ã/–∫–ª—é—á–∏, —á—Ç–æ–±—ã –Ω–µ –∑–∞—Å–≤–µ—Ç–∏—Ç—å –∏—Ö –≤ tg.log."""

    _telegram_url_re = re.compile(
        r"(https://api\.telegram\.org/bot)[^/\s]+",
        flags=re.IGNORECASE,
    )
    _telegram_token_re = re.compile(r"\bbot\d+:[A-Za-z0-9_-]+\b")

    def __init__(self, secrets: Iterable[str]) -> None:
        super().__init__()
        self._secrets = [s for s in secrets if isinstance(s, str) and s]

    def filter(self, record: logging.LogRecord) -> bool:  # noqa: A003 - –∏–º—è –∑–∞–¥–∞–Ω–æ logging API
        try:
            message = record.getMessage()
        except Exception:
            return True

        redacted = self._telegram_url_re.sub(r"\1<redacted>", message)
        redacted = self._telegram_token_re.sub("bot<redacted>", redacted)
        for secret in self._secrets:
            if secret in redacted:
                redacted = redacted.replace(secret, "<redacted>")

        if redacted != message:
            record.msg = redacted
            record.args = ()
        return True


def _install_log_redaction_filter() -> None:
    secrets: List[str] = [BOT_TOKEN] if BOT_TOKEN else []
    for key in ("OPENAI_API_KEY", "ANTHROPIC_API_KEY", "GROQ_API_KEY", "NEIRA_ADMIN_PASSWORD", "NEIRA_TG_PROXY_URL"):
        value = os.getenv(key)
        if value:
            secrets.append(value)

    filt = _SensitiveDataFilter(secrets)
    root = logging.getLogger()
    root.addFilter(filt)
    for handler in root.handlers:
        handler.addFilter(filt)


_install_log_redaction_filter()

# === –ó–ê–©–ò–¢–ê: –ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä ===
# –•–µ—à –ø–∞—Ä–æ–ª—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞ (–∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–ª–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
# –í–ê–ñ–ù–û: –ò–∑–º–µ–Ω–∏—Ç–µ NEIRA_ADMIN_PASSWORD –≤ .env!
_ADMIN_PASSWORD = os.getenv("NEIRA_ADMIN_PASSWORD", "change_me_please")
_ALLOW_DEFAULT_ADMIN_PASSWORD = os.getenv("NEIRA_ALLOW_DEFAULT_ADMIN_PASSWORD", "false").lower() == "true"

if _ADMIN_PASSWORD == "change_me_please" and not _ALLOW_DEFAULT_ADMIN_PASSWORD:
    raise RuntimeError(
        "NEIRA_ADMIN_PASSWORD –Ω–µ –∑–∞–¥–∞–Ω –∏–ª–∏ –æ—Å—Ç–∞–≤–ª–µ–Ω –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (change_me_please). "
        "–ó–∞–¥–∞–π—Ç–µ —Å–∏–ª—å–Ω—ã–π –ø–∞—Ä–æ–ª—å –≤ `.env` –∏–ª–∏ (—Ç–æ–ª—å–∫–æ –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏) —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ "
        "NEIRA_ALLOW_DEFAULT_ADMIN_PASSWORD=true."
    )

if len(_ADMIN_PASSWORD) < 10 and not _ALLOW_DEFAULT_ADMIN_PASSWORD:
    raise RuntimeError(
        "NEIRA_ADMIN_PASSWORD —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π (–º–∏–Ω–∏–º—É–º 10 —Å–∏–º–≤–æ–ª–æ–≤). "
        "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –ø–∞—Ä–æ–ª—å –∏–ª–∏ (—Ç–æ–ª—å–∫–æ –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏) —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ "
        "NEIRA_ALLOW_DEFAULT_ADMIN_PASSWORD=true."
    )

if _ALLOW_DEFAULT_ADMIN_PASSWORD:
    logging.warning("NEIRA_ALLOW_DEFAULT_ADMIN_PASSWORD=true: —Ä–µ–∂–∏–º –Ω–µ–±–µ–∑–æ–ø–∞—Å–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ç–æ–ª—å–∫–æ –ª–æ–∫–∞–ª—å–Ω–æ.")
_ADMIN_HASH = hashlib.sha256(_ADMIN_PASSWORD.encode()).hexdigest()
_ADMIN_ID: Optional[int] = None  # –ë—É–¥–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø—Ä–∏ –ø–µ—Ä–≤–æ–π –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏

# –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Ö—Ä–∞–Ω–∏—Ç—Å—è –≤ enhanced_auth.py (—Ñ–∞–π–ª neira_authorized_users.json).

TG_SETTINGS_FILE = Path(os.getenv("NEIRA_TG_SETTINGS_FILE", "neira_tg_settings.json"))

try:
    _tg_settings = load_telegram_settings(TG_SETTINGS_FILE)
except Exception as exc:
    logging.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ Telegram (%s): %s", TG_SETTINGS_FILE, exc)
    _tg_settings = TelegramSettings()

# –†–µ–∂–∏–º –¥–æ—Å—Ç—É–ø–∞: "open" (–≤—Å–µ), "whitelist" (—Ç–æ–ª—å–∫–æ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ), "admin_only"
ACCESS_MODE = _tg_settings.access_mode

# ID –∫–∞–Ω–∞–ª–æ–≤/–≥—Ä—É–ø–ø –≥–¥–µ –±–æ—Ç –æ—Ç–≤–µ—á–∞–µ—Ç –±–µ–∑ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
ALLOWED_CHANNELS: Set[int] = _tg_settings.allowed_channels

# –û—Ç–≤–µ—á–∞—Ç—å —Ç–æ–ª—å–∫–æ –Ω–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –±–æ—Ç–∞ –≤ –≥—Ä—É–ø–ø–∞—Ö/–∫–∞–Ω–∞–ª–∞—Ö?
MENTION_ONLY = _tg_settings.mention_only

def _persist_tg_settings() -> None:
    try:
        _tg_settings.access_mode = ACCESS_MODE
        _tg_settings.mention_only = MENTION_ONLY
        save_telegram_settings(TG_SETTINGS_FILE, _tg_settings)
    except Exception as exc:
        logging.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ Telegram (%s): %s", TG_SETTINGS_FILE, exc)

neira_wrapper = NeiraWrapper(verbose=False)
processing_lock = asyncio.Lock()

# === –°–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è ===
autonomous_learning_system: Optional[AutonomousLearningSystem] = None

# === üìù –û–±—É—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ —ç–º–æ–¥–∑–∏-—Ä–µ–∞–∫—Ü–∏–∏ ===
emoji_feedback = EmojiFeedbackSystem()
last_messages = {}  # {user_id: {"query": "", "response": "", "context": {}}}

# === üß† Neira Cortex v2.0 ===
neira_cortex: Optional['NeiraCortex'] = None
CORTEX_MODE = os.getenv("NEIRA_CORTEX_MODE", "auto")  # auto, always, never

# === üß† Phase 1: –ú–æ–¥—É–ª–∏ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç–∏ ===
neira_brain: Optional[Any] = None
response_engine: Optional[Any] = None
organ_system: Optional[Any] = None

# === üéµ –°—Ç–∞–±–∏–ª–∏–∑–∞—Ç–æ—Ä —Ä–∏—Ç–º–∞ ===
from rhythm_stabilizer import RhythmStabilizer, EmotionalState
rhythm_stabilizer = RhythmStabilizer()

# === üë§ –ü—Ä–æ—Ñ–∏–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π ===
import json
from pathlib import Path

USER_PROFILES_FILE = Path("neira_user_profiles.json")

def load_user_profiles():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–æ—Ñ–∏–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"""
    if USER_PROFILES_FILE.exists():
        try:
            with open(USER_PROFILES_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–æ—Ñ–∏–ª–µ–π: {e}")
    return {"user_profiles": {}}

def save_user_profiles(profiles):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø—Ä–æ—Ñ–∏–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"""
    try:
        with open(USER_PROFILES_FILE, 'w', encoding='utf-8') as f:
            json.dump(profiles, f, ensure_ascii=False, indent=2)
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–æ—Ñ–∏–ª–µ–π: {e}")

def get_user_name(user_id: int) -> Optional[str]:
    """–ü–æ–ª—É—á–∞–µ—Ç –∏–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ –ø—Ä–æ—Ñ–∏–ª—è"""
    profiles = load_user_profiles()
    user_key = str(user_id)
    return profiles["user_profiles"].get(user_key, {}).get("name")

def set_user_name(user_id: int, name: str):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –ø—Ä–æ—Ñ–∏–ª—å"""
    profiles = load_user_profiles()
    user_key = str(user_id)
    if user_key not in profiles["user_profiles"]:
        profiles["user_profiles"][user_key] = {}
    profiles["user_profiles"][user_key]["name"] = name
    profiles["user_profiles"][user_key]["updated_at"] = datetime.now().isoformat()
    save_user_profiles(profiles)
    logging.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∏–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {name}")


# === Phase 1: –ê–≤—Ç–æ–Ω–æ–º–Ω—ã–π –æ—Ç–≤–µ—Ç ===
def try_autonomous_response(message: str, user_id: int) -> Optional[str]:
    """
    –ü–æ–ø—ã—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∏—Ç—å –∞–≤—Ç–æ–Ω–æ–º–Ω–æ –±–µ–∑ LLM
    
    Returns:
        –û—Ç–≤–µ—Ç –∏–ª–∏ None –µ—Å–ª–∏ –Ω—É–∂–µ–Ω LLM
    """
    global response_engine, neira_brain
    
    if response_engine is None:
        return None
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_context = {}
        
        # –ò–º—è –∏–∑ –ø—Ä–æ—Ñ–∏–ª–µ–π –±–æ—Ç–∞
        saved_name = get_user_name(user_id)
        if saved_name:
            user_context['user_name'] = saved_name
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ NeiraBrain
        if neira_brain:
            prefs = neira_brain.get_user_prefs(str(user_id))
            if prefs:
                user_context.update(prefs.get('variables', {}))
        
        # –ü—Ä–æ–±—É–µ–º –æ—Ç–≤–µ—Ç–∏—Ç—å –∞–≤—Ç–æ–Ω–æ–º–Ω–æ
        response, source = response_engine.try_respond_autonomous(message, user_context)
        
        if response:
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫—É
            if neira_brain:
                neira_brain.record_metric('autonomous_response', 'telegram', {
                    'source': source,
                    'user_id': user_id,
                    'message_preview': message[:50]
                })
            logging.info(f"‚ö° –ê–≤—Ç–æ–Ω–æ–º–Ω—ã–π –æ—Ç–≤–µ—Ç –¥–ª—è user {user_id} (–∏—Å—Ç–æ—á–Ω–∏–∫: {source})")
            return response
        
        return None
        
    except Exception as e:
        logging.warning(f"–û—à–∏–±–∫–∞ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞: {e}")
        return None


def store_llm_response_for_learning(query: str, response: str, success: bool = True):
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç–≤–µ—Ç LLM –¥–ª—è –±—É–¥—É—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
    global response_engine
    
    if response_engine is None:
        return
    
    try:
        response_engine.store_llm_response(query, response, success)
    except Exception as e:
        logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç–≤–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {e}")


async def send_feedback_to_server(
    query: str, 
    response: str, 
    feedback: str, 
    score: float, 
    user_id: int
) -> bool:
    """
    –û—Ç–ø—Ä–∞–≤–∏—Ç—å feedback –Ω–∞ —Å–µ—Ä–≤–µ—Ä Neira (Phase 2).
    
    Args:
        query: –ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        response: –û—Ç–≤–µ—Ç Neira
        feedback: 'positive', 'negative' –∏–ª–∏ 'neutral'
        score: –û—Ü–µ–Ω–∫–∞ –æ—Ç 0 –¥–æ 1
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è Telegram
    
    Returns:
        True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ
    """
    if not NEIRA_CLIENT_AVAILABLE:
        return False
    
    try:
        client = get_client()
        result = await client.send_feedback_async(
            query=query,
            response=response,
            feedback=feedback,
            score=score,
            user_id=str(user_id),
            source="telegram"
        )
        
        if result and result.get("success"):
            actions = result.get("data", {}).get("actions_taken", [])
            if actions:
                logging.info(f"üì§ Feedback –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –Ω–∞ —Å–µ—Ä–≤–µ—Ä: {actions}")
            return True
        return False
        
    except Exception as e:
        logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å feedback –Ω–∞ —Å–µ—Ä–≤–µ—Ä: {e}")
        return False


# === –î–µ–∫–æ—Ä–∞—Ç–æ—Ä –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ ===
def require_auth(func):
    """–î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    @wraps(func)
    async def wrapper(update: Update, context: ContextTypes.DEFAULT_TYPE, *args, **kwargs):
        user_id = update.effective_user.id
        username = update.effective_user.username
        chat_id = update.effective_chat.id
        chat_type = update.effective_chat.type
        
        # –í —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã—Ö –∫–∞–Ω–∞–ª–∞—Ö/–≥—Ä—É–ø–ø–∞—Ö ‚Äî –±–µ–∑ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
        if chat_id in ALLOWED_CHANNELS:
            return await func(update, context, *args, **kwargs)
        
        # –ö–∞–Ω–∞–ª—ã –∏ —Å—É–ø–µ—Ä–≥—Ä—É–ø–ø—ã ‚Äî –ø—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —á–∞—Ç –≤ —Å–ø–∏—Å–∫–µ —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã—Ö
        if chat_type in ("channel", "supergroup", "group"):
            # –ï—Å–ª–∏ —á–∞—Ç –Ω–µ –≤ —Å–ø–∏—Å–∫–µ ‚Äî –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º (–Ω–µ —Å–ø–∞–º–∏–º –ø—Ä–æ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—é)
            if chat_id not in ALLOWED_CHANNELS and ACCESS_MODE != "open":
                return
        
        if ACCESS_MODE == "open":
            return await func(update, context, *args, **kwargs)
        
        if ACCESS_MODE == "admin_only" and not is_admin(user_id):
            if chat_type == "private":
                await update.message.reply_text("‚õî –î–æ—Å—Ç—É–ø —Ç–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞.")
            return
        
        if is_admin(user_id) or auth_system.is_authorized(user_id, username):
            return await func(update, context, *args, **kwargs)
        
        if chat_type == "private":
            await update.message.reply_text(
                "üîê *–¢—Ä–µ–±—É–µ—Ç—Å—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è*\n\n"
                f"–¢–≤–æ–π user_id: `{user_id}`\n\n"
                "üìã *–í–∞—Ä–∏–∞–Ω—Ç—ã –¥–æ—Å—Ç—É–ø–∞:*\n\n"
                "üëë *–ï—Å–ª–∏ —Ç—ã –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä:*\n"
                "`/auth 0 <–ø–∞—Ä–æ–ª—å>`\n\n"
                "üë§ *–ï—Å–ª–∏ –æ–±—ã—á–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å:*\n"
                "–ü–æ–ø—Ä–æ—Å–∏ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞ –¥–æ–±–∞–≤–∏—Ç—å —Ç–µ–±—è –∫–æ–º–∞–Ω–¥–æ–π:\n"
                "`/admin add <—Ç–≤–æ–π_user_id>`\n"
                "–∏–ª–∏\n"
                "`/admin add @<—Ç–≤–æ–π_username>`\n\n"
                "üí° *–ü–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Ç—ã —Å–º–æ–∂–µ—à—å:*\n"
                "‚Ä¢ –û–±—â–∞—Ç—å—Å—è —Å –ù–µ–π—Ä–æ–π\n"
                "‚Ä¢ –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å —Å–≤–æ—ë –∏–º—è: `/myname –¢–≤–æ—ë –ò–º—è`\n"
                "‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—Å–µ –∫–æ–º–∞–Ω–¥—ã –±–æ—Ç–∞",
                parse_mode=ParseMode.MARKDOWN,
            )
    return wrapper


def is_admin(user_id: int) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–º."""
    return user_id == _ADMIN_ID


# === –£—Ç–∏–ª–∏—Ç—ã ===
def split_message(text: str, limit: int = 4000) -> List[str]:
    """–î–µ–ª–∏—Ç –¥–ª–∏–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ —á–∞—Å—Ç–∏, —á—Ç–æ–±—ã –Ω–µ —É–ø–µ—Ä–µ—Ç—å—Å—è –≤ –ª–∏–º–∏—Ç Telegram."""
    if len(text) <= limit:
        return [text]

    parts: List[str] = []
    current: List[str] = []
    current_len = 0

    for paragraph in text.split("\n"):
        # –ï—Å–ª–∏ –ø–∞—Ä–∞–≥—Ä–∞—Ñ —Å–∞–º –¥–ª–∏–Ω–Ω–µ–µ –ª–∏–º–∏—Ç–∞ ‚Äî —Ä–µ–∂–µ–º –µ–≥–æ –ø–æ—Å–ª–æ–≤–Ω–æ
        if len(paragraph) > limit:
            words = paragraph.split()
            for word in words:
                if current_len + len(word) + 1 > limit:
                    parts.append(" ".join(current))
                    current = [word]
                    current_len = len(word)
                else:
                    current.append(word)
                    current_len += len(word) + 1
            continue

        if current_len + len(paragraph) + 1 > limit:
            parts.append("\n".join(current))
            current = [paragraph]
            current_len = len(paragraph)
        else:
            current.append(paragraph)
            current_len += len(paragraph) + 1

    if current:
        parts.append("\n".join(current))

    # –§–∏–ª—å—Ç—Ä—É–µ–º –ø—É—Å—Ç—ã–µ —á–∞—Å—Ç–∏
    return [p.strip() for p in parts if p.strip()]


def format_stage(stage: str | None) -> str:
    """–ß–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —ç—Ç–∞–ø–∞."""
    mapping = {
        "analysis": "–ê–Ω–∞–ª–∏–∑",
        "planning": "–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ",
        "execution": "–ò—Å–ø–æ–ª–Ω–µ–Ω–∏–µ",
        "verification": "–ü—Ä–æ–≤–µ—Ä–∫–∞",
    }
    return mapping.get(stage or "", "–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞")


def is_cortex_placeholder_response(text: str) -> bool:
    """
    Cortex (–≤ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–º —Ä–µ–∂–∏–º–µ) —á–∞—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç ¬´–∑–∞–≥–ª—É—à–∫–∏¬ª, –µ—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç
    pathway/—Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤/—à–∞–±–ª–æ–Ω–æ–≤. –í Telegram —ç—Ç–æ –≤—ã–≥–ª—è–¥–∏—Ç –∫–∞–∫ ¬´–±–æ—Ç —Å–ª–æ–º–∞–Ω¬ª.

    –í —Ä–µ–∂–∏–º–µ `NEIRA_CORTEX_MODE=auto` —Ç–∞–∫–∏–µ –æ—Ç–≤–µ—Ç—ã –ª—É—á—à–µ –æ—Ç–¥–∞–≤–∞—Ç—å –≤ legacy Neira.
    """
    normalized = (text or "").strip().lower()
    if not normalized:
        return True
    
    # –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç (< 30 —Å–∏–º–≤–æ–ª–æ–≤) –Ω–∞ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–π –≤–æ–ø—Ä–æ—Å ‚Äî —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –∑–∞–≥–ª—É—à–∫–∞
    if len(normalized) < 30:
        return True

    placeholder_markers = (
        # –Ø–≤–Ω—ã–µ –∑–∞–≥–ª—É—à–∫–∏
        "–Ω–µ –Ω–∞—à–ª–∞ –ø–æ–¥—Ö–æ–¥—è—â–∏–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç –æ—Ç–≤–µ—Ç–∞",
        "–¥–∞–π –º–Ω–µ —Å–µ–∫—É–Ω–¥—É –ø–æ–¥—É–º–∞—Ç—å",
        "–∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π –≤–æ–ø—Ä–æ—Å! –¥–∞–π –ø–æ–¥—É–º–∞—Ç—å",
        "–¥–∞–π –ø–æ–¥—É–º–∞—Ç—å –Ω–∞–¥ —ç—Ç–∏–º",
        "–ø–æ–Ω—è–ª –∑–∞–¥–∞—á—É, —Ä–∞–±–æ—Ç–∞—é –Ω–∞–¥ —ç—Ç–∏–º",
        "—Å–µ–π—á–∞—Å –Ω–∞–ø–∏—à—É –∫–æ–¥ –¥–ª—è —Ç–µ–±—è",
        "—Ä–∞—Å—Å–∫–∞–∂–∏ –ø–æ–¥—Ä–æ–±–Ω–µ–µ",
        "–Ω–µ —Å–æ–≤—Å–µ–º –ø–æ–Ω—è–ª–∞",
        # –®–∞–±–ª–æ–Ω–Ω—ã–µ –ø—É—Å—Ç—ã–µ –æ—Ç–≤–µ—Ç—ã
        "–æ, —ç—Ç–æ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ!",
        "–≤—Å–µ–≥–¥–∞ —Ä–∞–¥–∞ –ø–æ–±–æ–ª—Ç–∞—Ç—å",
        "–æ–±—Ä–∞—â–∞–π—Å—è, –µ—Å–ª–∏ —á—Ç–æ",
        "—Ä–∞–¥–∞ –ø–æ–º–æ—á—å!",
        "—Ö–º, –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ...",
    )

    return any(marker in normalized for marker in placeholder_markers)


# –ò–º–ø–æ—Ä—Ç –æ–±—â–µ–π —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
from text_utils import remove_duplicate_paragraphs as _remove_duplicate_paragraphs


def _truncate_response(text: str, limit: int) -> tuple[str, bool]:
    if not text or limit <= 0 or len(text) <= limit:
        return text, False
    if limit <= 3:
        return text[:limit], True
    return text[: limit - 3].rstrip() + "...", True


async def safe_reply_text(
    message: Message,
    text: str,
    *,
    parse_mode: str | ParseMode | None = None,
) -> Message | None:
    """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ reply_text: –Ω–µ —Ä–æ–Ω—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –Ω–∞ —Å–µ—Ç–µ–≤—ã—Ö –æ—à–∏–±–∫–∞—Ö."""
    try:
        return await message.reply_text(text, parse_mode=parse_mode)
    except (TimedOut, NetworkError) as exc:
        logging.warning("Telegram reply_text –Ω–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å: %s", exc)
        return None


async def send_chunks(
    update: Update,
    context: ContextTypes.DEFAULT_TYPE,
    chunks: Iterable[str],
) -> None:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π, —Å–æ–±–ª—é–¥–∞—è –ª–∏–º–∏—Ç—ã Telegram."""
    chat_id = update.effective_chat.id
    for part in chunks:
        try:
            await context.bot.send_message(chat_id=chat_id, text=part)
        except (TimedOut, NetworkError) as exc:
            logging.warning("Telegram send_message –Ω–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å: %s", exc)


async def show_typing(
    update: Update, context: ContextTypes.DEFAULT_TYPE
) -> None:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –¥–µ–π—Å—Ç–≤–∏–µ '–ø–µ—á–∞—Ç–∞–µ—Ç' –¥–ª—è UX."""
    throttle_seconds = max(_TYPING_THROTTLE_SECONDS, 0.0)
    if throttle_seconds > 0:
        now = time.monotonic()
        try:
            last_ts = float(context.chat_data.get("_neira_last_typing_ts", 0.0) or 0.0) if context.chat_data else 0.0
        except (TypeError, ValueError):
            last_ts = 0.0
        if now - last_ts < throttle_seconds:
            return
        if context.chat_data is not None:
            context.chat_data["_neira_last_typing_ts"] = now

    try:
        await context.bot.send_chat_action(
            chat_id=update.effective_chat.id,
            action=ChatAction.TYPING,
        )
    except (TimedOut, NetworkError):
        # –°–µ—Ç—å/Telegram –±—ã–≤–∞—é—Ç –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã ‚Äî —ç—Ç–æ –Ω–µ –¥–æ–ª–∂–Ω–æ –ª–æ–º–∞—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É.
        return


# === –†–∞–±–æ—Ç–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ ===
OLLAMA_API = "http://localhost:11434/api"
VISION_MODEL = "llava:7b"  # –ú–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –¥—Ä—É–≥—É—é)
SD_API = "http://127.0.0.1:7860/sdapi/v1"  # Stable Diffusion API


async def analyze_image_with_ollama(image_base64: str, prompt: str = "–û–ø–∏—à–∏ —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–¥—Ä–æ–±–Ω–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ") -> str:
    """–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ Ollama vision –º–æ–¥–µ–ª—å."""
    try:
        async with aiohttp.ClientSession() as session:
            payload = {
                "model": VISION_MODEL,
                "prompt": prompt,
                "images": [image_base64],
                "stream": False
            }
            async with session.post(f"{OLLAMA_API}/generate", json=payload, timeout=aiohttp.ClientTimeout(total=120)) as resp:
                if resp.status == 200:
                    result = await resp.json()
                    return result.get("response", "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.")
                else:
                    return f"–û—à–∏–±–∫–∞ API Ollama: {resp.status}"
    except aiohttp.ClientError as e:
        return f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Ollama: {e}"
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}"


async def check_vision_model() -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ vision –º–æ–¥–µ–ª–∏."""
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(f"{OLLAMA_API}/tags", timeout=aiohttp.ClientTimeout(total=5)) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    models = [m.get("name", "") for m in data.get("models", [])]
                    return any(VISION_MODEL in m or "llava" in m.lower() or "vision" in m.lower() for m in models)
    except (aiohttp.ClientError, asyncio.TimeoutError, KeyError):
        pass  # –ú–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞
    return False


async def generate_image_sd(prompt: str) -> Optional[bytes]:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ Stable Diffusion API."""
    try:
        async with aiohttp.ClientSession() as session:
            payload = {
                "prompt": prompt,
                "negative_prompt": "ugly, blurry, bad anatomy, bad hands, missing fingers, low quality",
                "steps": 20,
                "width": 512,
                "height": 512,
                "sampler_name": "Euler a",
                "cfg_scale": 7,
            }
            async with session.post(f"{SD_API}/txt2img", json=payload, timeout=aiohttp.ClientTimeout(total=180)) as resp:
                if resp.status == 200:
                    result = await resp.json()
                    images = result.get("images", [])
                    if images:
                        return base64.b64decode(images[0])
    except aiohttp.ClientError as e:
        logging.warning(f"SD API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ SD: {e}")
    return None


async def check_sd_available() -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ Stable Diffusion API."""
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(f"{SD_API}/sd-models", timeout=aiohttp.ClientTimeout(total=5)) as resp:
                return resp.status == 200
    except (aiohttp.ClientError, asyncio.TimeoutError):
        return False


# === –ö–æ–º–∞–Ω–¥—ã ===
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ –∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –∑–∞–ø—É—Å–∫—É."""
    user_id = update.effective_user.id
    user_name = update.effective_user.first_name or "–¥—Ä—É–≥"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–µ –∏–º—è
    saved_name = get_user_name(user_id)
    greeting_name = saved_name if saved_name else user_name
    
    is_authorized = (
        ACCESS_MODE == "open"
        or is_admin(user_id)
        or auth_system.is_authorized(user_id, update.effective_user.username)
    )
    
    if is_authorized:
        text = (
            f"–ü—Ä–∏–≤–µ—Ç, {greeting_name}! üëã –Ø Neira v1.0 –≤ Telegram.\n\n"
            "üöÄ *–ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç:*\n"
            "1Ô∏è‚É£ –ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ –º–Ω–µ —Å–æ–æ–±—â–µ–Ω–∏–µ ‚Äî —è –æ—Ç–≤–µ—á—É –∏ –∑–∞–ø–æ–º–Ω—é\n"
            "2Ô∏è‚É£ –û—Ç–ø—Ä–∞–≤—å —Ñ–æ—Ç–æ ‚Äî –æ–ø–∏—à—É —á—Ç–æ –≤–∏–∂—É\n"
            "3Ô∏è‚É£ –ó–∞–ø—É—Å—Ç–∏ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ: /learn\\_auto start\n\n"
            "‚ú® *–ß—Ç–æ —è —É–º–µ—é:*\n"
            "üß† –î–∏–∞–ª–æ–≥ —Å –ø–∞–º—è—Ç—å—é –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º\n"
            "üéì –ê–≤—Ç–æ–Ω–æ–º–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∏–∑ –Ω–∞–¥—ë–∂–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤\n"
            "üñºÔ∏è –ê–Ω–∞–ª–∏–∑ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n"
            "üß¨ –°–∞–º–æ—Å–æ–∑–Ω–∞–Ω–∏–µ –∏ —Ä–æ—Å—Ç –æ—Ä–≥–∞–Ω–æ–≤\n"
            "üíæ –†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç—å—é\n"
            "üîí –ó–∞—â–∏—Ç–∞ –æ—Ç –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π\n\n"
            "üìö *–û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:*\n"
            "/help ‚Äî –ø–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∫–æ–º–∞–Ω–¥\n"
            "/learn\\_auto start ‚Äî –∑–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ\n"
            "/memory stats ‚Äî —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞–º—è—Ç–∏\n"
            "/self ‚Äî —Å–∞–º–æ—Å–æ–∑–Ω–∞–Ω–∏–µ\n"
            "/stats ‚Äî —Å—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º\n\n"
            "üí° *–°–æ–≤–µ—Ç:* –ù–∞—á–Ω–∏ —Å `/learn_auto start` ‚Äî —è –±—É–¥—É —É—á–∏—Ç—å—Å—è —Å–∞–º–∞, "
            "–∫–æ–≥–¥–∞ –Ω–µ –∑–∞–Ω—è—Ç–∞ –¥–∏–∞–ª–æ–≥–∞–º–∏!"
        )
        if is_admin(user_id):
            text += "\n\nüëë –¢—ã –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä. –î–æ—Å—Ç—É–ø–Ω—ã /admin –∫–æ–º–∞–Ω–¥—ã."
    else:
        text = (
            f"–ü—Ä–∏–≤–µ—Ç, {user_name}! –Ø Neira ‚Äî AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ–º.\n\n"
            "üîê *–î–ª—è –¥–æ—Å—Ç—É–ø–∞ –Ω—É–∂–Ω–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è:*\n"
            "/auth <–ª–æ–≥–∏–Ω> <–ø–∞—Ä–æ–ª—å>\n\n"
            "–ü–æ–ø—Ä–æ—Å–∏ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞ –¥–∞—Ç—å —Ç–µ–±–µ –¥–æ—Å—Ç—É–ø.\n\n"
            "üìñ *–û –ø—Ä–æ–µ–∫—Ç–µ:*\n"
            "Neira ‚Äî —ç—Ç–æ AI —Å –ø–∞–º—è—Ç—å—é, —Å–∞–º–æ—Å–æ–∑–Ω–∞–Ω–∏–µ–º –∏ –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–º –æ–±—É—á–µ–Ω–∏–µ–º. "
            "–Ø –º–æ–≥—É –æ–±—É—á–∞—Ç—å—Å—è –∏–∑ –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ (Wikipedia, Python.org, arXiv) "
            "—Å –º–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤–æ–π –∑–∞—â–∏—Ç–æ–π –æ—Ç –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π."
        )
    
    await update.message.reply_text(text, parse_mode=ParseMode.MARKDOWN)


async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ü–æ–¥—Ä–æ–±–Ω–∞—è —Å–ø—Ä–∞–≤–∫–∞."""
    user_id = update.effective_user.id
    is_user_admin = is_admin(user_id)
    
    # –ë–∞–∑–æ–≤–∞—è —Å–ø—Ä–∞–≤–∫–∞ –¥–ª—è –≤—Å–µ—Ö
    text = (
        "üìö *–ö–æ–º–∞–Ω–¥—ã Neira v0.8.3*\n\n"
        "*üåü –û—Å–Ω–æ–≤–Ω—ã–µ:*\n"
        "/start ‚Äî –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ –∏ –±—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç\n"
        "/help ‚Äî —ç—Ç–∞ —Å–ø—Ä–∞–≤–∫–∞\n"
        "/myname <–∏–º—è> ‚Äî —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å–≤–æ—ë –∏–º—è\n\n"
        "*üí¨ –î–∏–∞–ª–æ–≥:*\n"
        "/context ‚Äî –∏—Å—Ç–æ—Ä–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞\n"
        "/clear\\_context ‚Äî –æ—á–∏—Å—Ç–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç\n"
        "/rhythm ‚Äî —Ä–µ–∂–∏–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è\n\n"
        "*üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:*\n"
        "/stats ‚Äî —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã\n"
        "/memory ‚Äî –ø—Ä–æ—Å–º–æ—Ç—Ä –ø–∞–º—è—Ç–∏\n\n"
        "*üé® –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:*\n"
        "üì∑ –û—Ç–ø—Ä–∞–≤—å —Ñ–æ—Ç–æ ‚Äî –∞–Ω–∞–ª–∏–∑\n"
        "/imagine <–æ–ø–∏—Å–∞–Ω–∏–µ> ‚Äî –≥–µ–Ω–µ—Ä–∞—Ü–∏—è\n"
        "/vision ‚Äî —Å—Ç–∞—Ç—É—Å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è\n\n"
        "*ÔøΩ –û–±—É—á–µ–Ω–∏–µ:*\n"
        "–†–µ–∞–≥–∏—Ä—É–π —ç–º–æ–¥–∑–∏ –Ω–∞ –º–æ–∏ –æ—Ç–≤–µ—Ç—ã:\n"
        "üíØ ‚≠ê ‚Äî –æ—Ç–ª–∏—á–Ω–æ | üëç ‚ù§Ô∏è ‚Äî —Ö–æ—Ä–æ—à–æ\n"
        "üëé üòï ‚Äî –ø–ª–æ—Ö–æ | ‚ùå üö´ ‚Äî –æ—á–µ–Ω—å –ø–ª–æ—Ö–æ\n\n"
        "*ÔøΩüí° –ü–æ–¥—Å–∫–∞–∑–∫–∏:*\n"
        "‚Ä¢ –ü—Ä–æ—Å—Ç–æ –ø–∏—à–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –¥–∏–∞–ª–æ–≥–∞\n"
        "‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–π #—Ö–µ—à—Ç–µ–≥–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n"
        "‚Ä¢ –û—Ç–ø—Ä–∞–≤–ª—è–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞\n"
    )
    
    # –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Å–ø—Ä–∞–≤–∫–∞ –¥–ª—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞
    if is_user_admin:
        text += (
            "\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            "*üëë –ê–î–ú–ò–ù-–ö–û–ú–ê–ù–î–´*\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
            "*üîê –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏:*\n"
            "/auth 0 <–ø–∞—Ä–æ–ª—å> ‚Äî –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞—Ç—å—Å—è –∫–∞–∫ –∞–¥–º–∏–Ω\n"
            "/admin users ‚Äî —Å–ø–∏—Å–æ–∫ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö\n"
            "/admin add <user_id> ‚Äî –¥–æ–±–∞–≤–∏—Ç—å –ø–æ ID\n"
            "/admin add @username ‚Äî –¥–æ–±–∞–≤–∏—Ç—å –ø–æ username\n"
            "/admin add https://t.me/username ‚Äî –ø–æ —Å—Å—ã–ª–∫–µ\n"
            "/admin remove <identifier> ‚Äî —É–¥–∞–ª–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n"
            "/admin mode open ‚Äî –æ—Ç–∫—Ä—ã—Ç—å –¥–æ—Å—Ç—É–ø –≤—Å–µ–º\n"
            "/admin mode whitelist ‚Äî —Ç–æ–ª—å–∫–æ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ\n"
            "/admin mode admin_only ‚Äî —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω\n\n"
            "/admin stats ‚Äî —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã\n\n"
            "*üß† Cortex v2.0:*\n"
            "/cortex ‚Äî –æ–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n"
            "/cortex stats ‚Äî –¥–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n"
            "/cortex pathways ‚Äî Neural Pathways\n"
            "/cortex test <—Ç–µ–∫—Å—Ç> ‚Äî –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å\n\n"
            "*üìù –û–±—É—á–µ–Ω–∏–µ (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ):*\n"
            "/feedback ‚Äî —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ emoji-—Ä–µ–∞–∫—Ü–∏–π\n"
            "–†–µ–∞–≥–∏—Ä—É–π —ç–º–æ–¥–∑–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è Neira!\n\n"
            "*üíæ –ü–∞–º—è—Ç—å (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ):*\n"
            "/memory search <—Ç–µ–∫—Å—Ç> ‚Äî –ø–æ–∏—Å–∫\n"
            "/memory semantic <—Ç–µ–∫—Å—Ç> ‚Äî —Å–µ–º–∞–Ω—Ç–∏–∫–∞\n"
            "/memory delete last/text/old\n"
            "/memory dedupe ‚Äî –¥—É–±–ª–∏–∫–∞—Ç—ã\n"
            "/memory backup/restore\n"
            "/memory pin/pinned ‚Äî –∑–∞–∫—Ä–µ–ø–∏—Ç—å\n"
            "/memory filter confidence/source\n"
            "/memory export txt\n"
            "/experience ‚Äî –∂—É—Ä–Ω–∞–ª –æ–ø—ã—Ç–∞\n"
            "/clear ‚Äî ‚ö†Ô∏è –ü–û–õ–ù–ê–Ø –æ—á–∏—Å—Ç–∫–∞\n\n"
            "*üéì –û–±—É—á–µ–Ω–∏–µ:*\n"
            "/learn <—Ç–µ–º–∞|URL> ‚Äî —Ç–µ–º–∞ –∏–ª–∏ —Å—Å—ã–ª–∫–∞\n"
            "/learn\\_auto start/stop ‚Äî –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–µ\n"
            "/learn\\_auto stats ‚Äî —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n"
            "/learn\\_auto quarantine ‚Äî –∫–∞—Ä–∞–Ω—Ç–∏–Ω\n"
            "/learn\\_auto approve/reject <id>\n\n"
            "*üß¨ –°–∞–º–æ—Å–æ–∑–Ω–∞–Ω–∏–µ:*\n"
            "/self ‚Äî —Å–∞–º–æ–∞–Ω–∞–ª–∏–∑\n"
            "/organs ‚Äî —Å—Ç–∞—Ç—É—Å –æ—Ä–≥–∞–Ω–æ–≤\n"
            "/grow ‚Äî —Å–æ–∑–¥–∞–Ω–∏–µ –æ—Ä–≥–∞–Ω–æ–≤\n"
            "/organ_mode ‚Äî —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–µ–∂–∏–º–æ–º —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ä–≥–∞–Ω–æ–≤\n"
            "/code list/read ‚Äî —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–æ–¥–æ–º\n\n"
            "*üí° –•–µ—à—Ç–µ–≥–∏:*\n"
            "#—Å–æ–∑–¥–∞–π\\_–æ—Ä–≥–∞–Ω <–æ–ø–∏—Å–∞–Ω–∏–µ>\n"
            "#–Ω–∞—É—á–∏—Å—å <—Ç–µ–º–∞>\n"
        )
    # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ—Ä–≥–∞–Ω–æ–≤ –∏ –∏—Ö –∫–æ–º–∞–Ω–¥
    try:
        registry = await _load_cell_registry()
        active = [m for m in registry if m.get('active')]
        if active:
            text += "\n*üîå –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Ä–≥–∞–Ω—ã –∏ –∫–æ–º–∞–Ω–¥—ã (–∞–∫—Ç–∏–≤–Ω—ã–µ):*\n"
            for m in active:
                name = m.get('cell_name')
                cmds = m.get('command_triggers') or []
                cmds_text = ', '.join(cmds) if cmds else '‚Äî'
                text += f"‚Ä¢ {name}: {cmds_text}\n"
            text += (
                "\n–ò—Å–ø–æ–ª—å–∑—É–π `/which_command <organ_name>` —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å –∫–æ–º–∞–Ω–¥—ã –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –æ—Ä–≥–∞–Ω–∞.\n"
                "–ö–æ–º–∞–Ω–¥—ã –æ–±—ã—á–Ω–æ –≤—ã–≥–ª—è–¥—è—Ç –∫–∞–∫ `/run_<name>`, `#<name>` –∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è `/—É–ª—É—á—à–µ–Ω–∏–µ_<name>`.")
            text += "\n–ù–æ–≤—ã–µ –æ—Ä–≥–∞–Ω—ã —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏ —Å—Ç–∞–Ω—É—Ç –¥–æ—Å—Ç—É–ø–Ω—ã –±–µ–∑ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞ –±–æ—Ç–∞.\n"
        else:
            text += "\n*üîå –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ—Ä–≥–∞–Ω–æ–≤ –ø–æ–∫–∞ –Ω–µ—Ç.*\n"
    except Exception:
        logging.exception('–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ä–µ–µ—Å—Ç—Ä –æ—Ä–≥–∞–Ω–æ–≤ –¥–ª—è /help')
    
    await update.message.reply_text(text, parse_mode=ParseMode.MARKDOWN)


async def stats_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û—Ç—á—ë—Ç –æ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –º–æ–¥–µ–ª–µ–π –∏ –ø–∞–º—è—Ç–∏."""
    await show_typing(update, context)
    stats = neira_wrapper.get_stats()

    lines = [
        "–°—Ç–∞—Ç—É—Å Neira:",
        f"- –û–±—Ä–∞–±–æ—Ç–∫–∞: {'–¥–∞' if stats.get('is_processing') else '–Ω–µ—Ç'}",
    ]

    models = stats.get("models", {})
    local = models.get("local", {})
    cloud = models.get("cloud", {})

    lines.append(
        "- –õ–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏: "
        f"code={'OK' if local.get('code') else '–Ω–µ—Ç'}, "
        f"reason={'OK' if local.get('reason') else '–Ω–µ—Ç'}, "
        f"personality={'OK' if local.get('personality') else '–Ω–µ—Ç'}"
    )
    lines.append(
        "- –û–±–ª–∞—á–Ω—ã–µ: "
        f"code={'OK' if cloud.get('code') else '–Ω–µ—Ç'}, "
        f"universal={'OK' if cloud.get('universal') else '–Ω–µ—Ç'}, "
        f"vision={'OK' if cloud.get('vision') else '–Ω–µ—Ç'}"
    )

    memory = stats.get("memory", {})
    lines.append(
        f"- –ü–∞–º—è—Ç—å: –≤—Å–µ–≥–æ {memory.get('total', 0)}, –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–µ—Å—Å–∏–∏ "
        f"{memory.get('session_context', 0)}"
    )

    if "model_manager" in stats:
        manager = stats["model_manager"]
        lines.append(
            f"- ModelManager: –∞–∫—Ç–∏–≤–Ω–∞ {manager.get('current_model')}, "
            f"–ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–π {manager.get('switches', 0)}"
        )

    if "experience" in stats:
        exp = stats["experience"]
        lines.append(
            f"- –û–ø—ã—Ç: –≤—Å–µ–≥–æ {exp.get('total', 0)}, —Å—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ "
            f"{exp.get('avg_score', 0)}"
        )
    
    # üß† Cortex v2.0 —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    if neira_cortex:
        cortex_stats = neira_cortex.get_stats()
        lines.append(f"\nüß† *Neira Cortex v2.0:*")
        lines.append(f"- –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {cortex_stats['total_requests']}")
        
        # –¢–æ–ø-3 —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        top_strategies = sorted(
            cortex_stats['strategies'].items(),
            key=lambda x: x[1],
            reverse=True
        )[:3]
        lines.append("- –¢–æ–ø —Å—Ç—Ä–∞—Ç–µ–≥–∏–π:")
        for strategy, count in top_strategies:
            percentage = (count / cortex_stats['total_requests'] * 100) if cortex_stats['total_requests'] > 0 else 0
            lines.append(f"  ‚Ä¢ {strategy}: {count} ({percentage:.0f}%)")
        
        # –ü–æ–∫—Ä—ã—Ç–∏–µ pathways
        coverage = cortex_stats['pathways']['coverage']
        lines.append(f"- –ü–æ–∫—Ä—ã—Ç–∏–µ: HOT {coverage.get('hot', '0%')}, WARM {coverage.get('warm', '0%')}")

    await update.message.reply_text("\n".join(lines), parse_mode=ParseMode.MARKDOWN)


async def ratelimit_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç—É—Å rate limiting –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    user_id = update.effective_user.id
    
    if not RATE_LIMITER_AVAILABLE:
        await update.message.reply_text("‚ö†Ô∏è Rate Limiter –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")
        return
    
    from rate_limiter import get_rate_limiter
    limiter = get_rate_limiter()
    stats = limiter.get_stats(str(user_id))
    
    text = (
        "üö¶ *–°—Ç–∞—Ç—É—Å Rate Limiting*\n\n"
        f"üìä –ó–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –º–∏–Ω—É—Ç—É: {stats['requests_last_minute']}/{stats['limits']['per_minute']}\n"
        f"üìà –ó–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å: {stats['requests_last_hour']}/{stats['limits']['per_hour']}\n"
    )
    
    if stats['blocked']:
        text += f"\n‚õî –ó–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω –Ω–∞ {stats['blocked_for']} —Å–µ–∫."
    else:
        text += "\n‚úÖ –õ–∏–º–∏—Ç –Ω–µ –ø—Ä–µ–≤—ã—à–µ–Ω"
    
    await update.message.reply_text(text, parse_mode=ParseMode.MARKDOWN)


@require_auth
async def memory_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç—å—é Neira
    
    –ö–æ–º–∞–Ω–¥—ã:
    /memory - –ø–æ–∫–∞–∑–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 –∑–∞–ø–∏—Å–µ–π
    /memory stats - –¥–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    /memory search <—Ç–µ–∫—Å—Ç> - –Ω–∞–π—Ç–∏ –∑–∞–ø–∏—Å–∏
    /memory delete last <N> - —É–¥–∞–ª–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –∑–∞–ø–∏—Å–µ–π
    /memory delete text <—Ç–µ–∫—Å—Ç> - —É–¥–∞–ª–∏—Ç—å –∑–∞–ø–∏—Å–∏ —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ —Ç–µ–∫—Å—Ç
    /memory delete old <–¥–Ω–µ–π> - —É–¥–∞–ª–∏—Ç—å –∑–∞–ø–∏—Å–∏ —Å—Ç–∞—Ä—à–µ N –¥–Ω–µ–π
    /memory dedupe - —É–¥–∞–ª–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã
    /memory backup - —Å–æ–∑–¥–∞—Ç—å –±—ç–∫–∞–ø
    """
    if not context.args:
        # –ü–æ–∫–∞–∑–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞–ø–∏—Å–∏
        await show_typing(update, context)
        data = neira_wrapper.get_memory(limit=10)
        recent = data.get("recent", [])
        if not recent:
            await update.message.reply_text("üì≠ –ü–∞–º—è—Ç—å –ø—É—Å—Ç–∞.")
            return

        lines = ["üíæ *–ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 –∑–∞–ø–∏—Å–µ–π:*\n"]
        for i, item in enumerate(recent, 1):
            category = item.get('category', 'general')
            text = item.get('text', '')[:80]
            lines.append(f"{i}. `[{category}]` {text}...")
        
        lines.append(f"\n_–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {data.get('total', len(recent))}_")
        lines.append("_–ò—Å–ø–æ–ª—å–∑—É–π /memory stats –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏_")
        
        await update.message.reply_text("\n".join(lines), parse_mode=ParseMode.MARKDOWN)
        return
    
    action = context.args[0].lower()
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä –ø–∞–º—è—Ç–∏
    from memory_system import MemoryManager
    
    if not neira_wrapper.neira.memory.memory_system:
        await update.message.reply_text("‚ùå –°–∏—Å—Ç–µ–º–∞ –ø–∞–º—è—Ç–∏ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
        return
    
    memory_manager = MemoryManager(neira_wrapper.neira.memory.memory_system)
    
    if action == "stats":
        # –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = memory_manager.get_stats()
        lines = [
            "üìä *–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞–º—è—Ç–∏:*\n",
            f"üì¶ –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {stats['total']}",
            f"üìö –î–æ–ª–≥–æ—Å—Ä–æ—á–Ω–∞—è: {stats['by_type'].get('long_term', 0)}",
            f"‚ö° –ö—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω–∞—è: {stats['by_type'].get('short_term', 0)}",
            f"üìñ –≠–ø–∏–∑–æ–¥–∏—á–µ—Å–∫–∞—è: {stats['by_type'].get('episodic', 0)}",
            f"üß† –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è: {stats['by_type'].get('semantic', 0)}",
        ]
        
        if stats.get('oldest'):
            oldest = datetime.fromisoformat(stats['oldest']).strftime("%d.%m.%Y")
            newest = datetime.fromisoformat(stats['newest']).strftime("%d.%m.%Y %H:%M")
            lines.append(f"\nüìÖ –ü–µ—Ä–∏–æ–¥: {oldest} ‚Äî {newest}")
        
        lines.append(f"üéØ –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {stats['average_confidence']:.1%}")
        
        # –¢–æ–ø –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        if stats['by_category']:
            lines.append("\nüè∑Ô∏è *–ö–∞—Ç–µ–≥–æ—Ä–∏–∏:*")
            sorted_cats = sorted(stats['by_category'].items(), key=lambda x: x[1], reverse=True)
            for cat, count in sorted_cats[:5]:
                lines.append(f"  ‚Ä¢ {cat}: {count}")
        
        await update.message.reply_text("\n".join(lines), parse_mode=ParseMode.MARKDOWN)
    
    elif action == "search" and len(context.args) > 1:
        # –ü–æ–∏—Å–∫ –∑–∞–ø–∏—Å–µ–π
        query = " ".join(context.args[1:])
        results = memory_manager.search_by_text(query)
        
        if not results:
            await update.message.reply_text(f"üîç –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{query}'")
            return
        
        lines = [f"üîç *–ù–∞–π–¥–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(results)}*\n"]
        for i, entry in enumerate(results[:15], 1):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 15
            text = entry.text[:80] + "..." if len(entry.text) > 80 else entry.text
            lines.append(f"{i}. `[{entry.category}]` {text}")
        
        if len(results) > 15:
            lines.append(f"\n_...–∏ –µ—â—ë {len(results) - 15} –∑–∞–ø–∏—Å–µ–π_")
        
        await update.message.reply_text("\n".join(lines), parse_mode=ParseMode.MARKDOWN)
    
    elif action == "delete":
        # –¢—Ä–µ–±—É–µ—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
        if len(context.args) < 2:
            await update.message.reply_text(
                "‚ùì *–ö–æ–º–∞–Ω–¥—ã —É–¥–∞–ª–µ–Ω–∏—è:*\n"
                "/memory delete last <N> ‚Äî —É–¥–∞–ª–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –∑–∞–ø–∏—Å–µ–π\n"
                "/memory delete text <—Ç–µ–∫—Å—Ç> ‚Äî —É–¥–∞–ª–∏—Ç—å –∑–∞–ø–∏—Å–∏ —Å–æ —Å–ª–æ–≤–æ–º\n"
                "/memory delete old <–¥–Ω–µ–π> ‚Äî —É–¥–∞–ª–∏—Ç—å –∑–∞–ø–∏—Å–∏ —Å—Ç–∞—Ä—à–µ N –¥–Ω–µ–π\n"
                "/memory delete category <–∫–∞—Ç–µ–≥–æ—Ä–∏—è> ‚Äî —É–¥–∞–ª–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—é",
                parse_mode=ParseMode.MARKDOWN
            )
            return
        
        subaction = context.args[1].lower()
        
        if subaction == "last" and len(context.args) > 2:
            try:
                n = int(context.args[2])
                if n < 1 or n > 100:
                    await update.message.reply_text("‚ùå N –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –æ—Ç 1 –¥–æ 100")
                    return
                
                count = memory_manager.delete_last_n(n)
                await update.message.reply_text(
                    f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –∑–∞–ø–∏—Å–µ–π: {count}\n"
                    f"_–ò—Å–ø–æ–ª—å–∑—É–π /memory stats –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏_",
                    parse_mode=ParseMode.MARKDOWN
                )
            except ValueError:
                await update.message.reply_text("‚ùå N –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —á–∏—Å–ª–æ–º")
        
        elif subaction == "text" and len(context.args) > 2:
            query = " ".join(context.args[2:])
            count = memory_manager.delete_by_text(query)
            await update.message.reply_text(
                f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π —Å '{query}': {count}",
                parse_mode=ParseMode.MARKDOWN
            )
        
        elif subaction == "old" and len(context.args) > 2:
            try:
                days = int(context.args[2])
                if days < 1:
                    await update.message.reply_text("‚ùå –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º")
                    return
                
                count = memory_manager.delete_old_entries(days)
                await update.message.reply_text(
                    f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π —Å—Ç–∞—Ä—à–µ {days} –¥–Ω.: {count}",
                    parse_mode=ParseMode.MARKDOWN
                )
            except ValueError:
                await update.message.reply_text("‚ùå –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —á–∏—Å–ª–æ–º")
        
        elif subaction == "category" and len(context.args) > 2:
            category = context.args[2]
            count = memory_manager.delete_by_category(category)
            await update.message.reply_text(
                f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}': {count}",
                parse_mode=ParseMode.MARKDOWN
            )
        
        else:
            await update.message.reply_text("‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –ø–æ–¥–∫–æ–º–∞–Ω–¥–∞ —É–¥–∞–ª–µ–Ω–∏—è")
    
    elif action == "dedupe":
        # –£–¥–∞–ª–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã
        count = memory_manager.deduplicate()
        await update.message.reply_text(
            f"üßπ –£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {count}\n"
            f"_–î—É–±–ª–∏–∫–∞—Ç–∞–º–∏ —Å—á–∏—Ç–∞—é—Ç—Å—è –∑–∞–ø–∏—Å–∏ —Å >95% —Å—Ö–æ–∂–µ—Å—Ç—å—é_",
            parse_mode=ParseMode.MARKDOWN
        )
    
    elif action == "backup":
        # –°–æ–∑–¥–∞—Ç—å –±—ç–∫–∞–ø
        backup_path = memory_manager.create_backup()
        filename = os.path.basename(backup_path)
        await update.message.reply_text(
            f"üíæ –ë—ç–∫–∞–ø —Å–æ–∑–¥–∞–Ω: `{filename}`\n"
            f"_–°–æ—Ö—Ä–∞–Ω—ë–Ω –≤ –ø–∞–ø–∫—É backups/_",
            parse_mode=ParseMode.MARKDOWN
        )
    
    elif action == "restore" and len(context.args) > 1:
        # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∏–∑ –±—ç–∫–∞–ø–∞
        backup_name = context.args[1]
        success = memory_manager.restore_from_backup(backup_name)
        
        if success:
            await update.message.reply_text(
                f"‚úÖ –ü–∞–º—è—Ç—å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –∏–∑ `{backup_name}`\n"
                f"_–ò—Å–ø–æ–ª—å–∑—É–π /memory stats –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏_",
                parse_mode=ParseMode.MARKDOWN
            )
        else:
            await update.message.reply_text(
                f"‚ùå –ë—ç–∫–∞–ø `{backup_name}` –Ω–µ –Ω–∞–π–¥–µ–Ω\n"
                f"_–ò—Å–ø–æ–ª—å–∑—É–π /memory backups –¥–ª—è —Å–ø–∏—Å–∫–∞_",
                parse_mode=ParseMode.MARKDOWN
            )
    
    elif action == "backups":
        # –°–ø–∏—Å–æ–∫ –±—ç–∫–∞–ø–æ–≤
        backups = memory_manager.list_backups()
        
        if not backups:
            await update.message.reply_text("üì≠ –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –±—ç–∫–∞–ø–æ–≤")
            return
        
        lines = [f"üíæ *–î–æ—Å—Ç—É–ø–Ω—ã–µ –±—ç–∫–∞–ø—ã ({len(backups)}):*\n"]
        for i, backup in enumerate(backups[:10], 1):
            timestamp = datetime.fromisoformat(backup['timestamp']).strftime("%d.%m.%Y %H:%M")
            size_kb = backup['size'] // 1024
            lines.append(
                f"{i}. `{backup['filename']}`\n"
                f"   üìÖ {timestamp} | üì¶ {backup['total']} –∑–∞–ø–∏—Å–µ–π | üíæ {size_kb} KB"
            )
        
        if len(backups) > 10:
            lines.append(f"\n_...–∏ –µ—â—ë {len(backups) - 10} –±—ç–∫–∞–ø–æ–≤_")
        
        lines.append("\n_–ò—Å–ø–æ–ª—å–∑—É–π /memory restore <filename>_")
        await update.message.reply_text("\n".join(lines), parse_mode=ParseMode.MARKDOWN)
    
    elif action == "filter" and len(context.args) > 1:
        # –£–º–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã
        filter_type = context.args[1].lower()
        
        if filter_type == "confidence" and len(context.args) > 2:
            # /memory filter confidence <0.5
            filter_expr = context.args[2]
            
            # –ü–∞—Ä—Å–∏–º –æ–ø–µ—Ä–∞—Ç–æ—Ä –∏ –∑–Ω–∞—á–µ–Ω–∏–µ
            import re
            match = re.match(r'([<>=]+)([\d.]+)', filter_expr)
            if not match:
                await update.message.reply_text("‚ùå –§–æ—Ä–º–∞—Ç: /memory filter confidence <0.5")
                return
            
            operator = match.group(1)
            threshold = float(match.group(2))
            
            results = memory_manager.filter_by_confidence(operator, threshold)
            
            if not results:
                await update.message.reply_text(
                    f"üîç –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é {operator}{threshold}"
                )
                return
            
            lines = [f"üîç *–ù–∞–π–¥–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(results)}* (confidence {operator}{threshold})\n"]
            for i, entry in enumerate(results[:15], 1):
                text = entry.text[:60] + "..." if len(entry.text) > 60 else entry.text
                lines.append(f"{i}. [{entry.confidence:.0%}] {text}")
            
            if len(results) > 15:
                lines.append(f"\n_...–∏ –µ—â—ë {len(results) - 15}_")
            
            await update.message.reply_text("\n".join(lines), parse_mode=ParseMode.MARKDOWN)
        
        elif filter_type == "source" and len(context.args) > 2:
            # /memory filter source telegram
            source = context.args[2]
            results = memory_manager.filter_by_source(source)
            
            if not results:
                await update.message.reply_text(f"üîç –ù–µ—Ç –∑–∞–ø–∏—Å–µ–π –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ '{source}'")
                return
            
            lines = [f"üîç *–ó–∞–ø–∏—Å–µ–π –∏–∑ '{source}': {len(results)}*\n"]
            for i, entry in enumerate(results[:15], 1):
                text = entry.text[:60] + "..." if len(entry.text) > 60 else entry.text
                lines.append(f"{i}. `[{entry.category}]` {text}")
            
            if len(results) > 15:
                lines.append(f"\n_...–∏ –µ—â—ë {len(results) - 15}_")
            
            await update.message.reply_text("\n".join(lines), parse_mode=ParseMode.MARKDOWN)
        
        elif filter_type == "recent" and len(context.args) > 2:
            # /memory filter recent 24h
            time_str = context.args[2]
            hours = int(time_str.replace('h', ''))
            
            results = memory_manager.filter_by_timerange(hours)
            
            if not results:
                await update.message.reply_text(f"üîç –ù–µ—Ç –∑–∞–ø–∏—Å–µ–π –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ {hours}—á")
                return
            
            lines = [f"üîç *–ó–∞–ø–∏—Å–µ–π –∑–∞ {hours}—á: {len(results)}*\n"]
            for i, entry in enumerate(results[:15], 1):
                timestamp = datetime.fromisoformat(entry.timestamp).strftime("%H:%M")
                text = entry.text[:50] + "..." if len(entry.text) > 50 else entry.text
                lines.append(f"{i}. [{timestamp}] {text}")
            
            if len(results) > 15:
                lines.append(f"\n_...–∏ –µ—â—ë {len(results) - 15}_")
            
            await update.message.reply_text("\n".join(lines), parse_mode=ParseMode.MARKDOWN)
        
        else:
            await update.message.reply_text(
                "‚ùì *–§–∏–ª—å—Ç—Ä—ã:*\n"
                "/memory filter confidence <0.5\n"
                "/memory filter source telegram\n"
                "/memory filter recent 24h",
                parse_mode=ParseMode.MARKDOWN
            )
    
    elif action == "pin" and len(context.args) > 1:
        # –ó–∞–∫—Ä–µ–ø–∏—Ç—å –∑–∞–ø–∏—Å—å
        # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –∑–∞–ø–∏—Å—å –ø–æ –Ω–æ–º–µ—Ä—É –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ search
        try:
            entry_num = int(context.args[1]) - 1
            data = neira_wrapper.get_memory(limit=100)
            recent = data.get("recent", [])
            
            if entry_num < 0 or entry_num >= len(recent):
                await update.message.reply_text("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –Ω–æ–º–µ—Ä –∑–∞–ø–∏—Å–∏")
                return
            
            entry_id = recent[entry_num].get('id')
            if memory_manager.pin_entry(entry_id):
                await update.message.reply_text(
                    f"üìå –ó–∞–ø–∏—Å—å #{context.args[1]} –∑–∞–∫—Ä–µ–ø–ª–µ–Ω–∞\n"
                    f"_–ó–∞—â–∏—â–µ–Ω–∞ –æ—Ç —É–¥–∞–ª–µ–Ω–∏—è_",
                    parse_mode=ParseMode.MARKDOWN
                )
            else:
                await update.message.reply_text("‚ùå –ó–∞–ø–∏—Å—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        except (ValueError, IndexError):
            await update.message.reply_text("‚ùå –£–∫–∞–∂–∏—Ç–µ –Ω–æ–º–µ—Ä –∑–∞–ø–∏—Å–∏ –∏–∑ /memory")
    
    elif action == "unpin" and len(context.args) > 1:
        # –û—Ç–∫—Ä–µ–ø–∏—Ç—å –∑–∞–ø–∏—Å—å
        try:
            entry_num = int(context.args[1]) - 1
            data = neira_wrapper.get_memory(limit=100)
            recent = data.get("recent", [])
            
            if entry_num < 0 or entry_num >= len(recent):
                await update.message.reply_text("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –Ω–æ–º–µ—Ä –∑–∞–ø–∏—Å–∏")
                return
            
            entry_id = recent[entry_num].get('id')
            if memory_manager.unpin_entry(entry_id):
                await update.message.reply_text(
                    f"üìç –ó–∞–ø–∏—Å—å #{context.args[1]} –æ—Ç–∫—Ä–µ–ø–ª–µ–Ω–∞",
                    parse_mode=ParseMode.MARKDOWN
                )
            else:
                await update.message.reply_text("‚ùå –ó–∞–ø–∏—Å—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        except (ValueError, IndexError):
            await update.message.reply_text("‚ùå –£–∫–∞–∂–∏—Ç–µ –Ω–æ–º–µ—Ä –∑–∞–ø–∏—Å–∏ –∏–∑ /memory")
    
    elif action == "pinned":
        # –ü–æ–∫–∞–∑–∞—Ç—å –∑–∞–∫—Ä–µ–ø–ª—ë–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏
        pinned = memory_manager.get_pinned()
        
        if not pinned:
            await update.message.reply_text("üì≠ –ù–µ—Ç –∑–∞–∫—Ä–µ–ø–ª—ë–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π")
            return
        
        lines = [f"üìå *–ó–∞–∫—Ä–µ–ø–ª—ë–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏ ({len(pinned)}):*\n"]
        for i, entry in enumerate(pinned[:20], 1):
            text = entry.text[:60] + "..." if len(entry.text) > 60 else entry.text
            lines.append(f"{i}. `[{entry.category}]` {text}")
        
        if len(pinned) > 20:
            lines.append(f"\n_...–∏ –µ—â—ë {len(pinned) - 20}_")
        
        await update.message.reply_text("\n".join(lines), parse_mode=ParseMode.MARKDOWN)
    
    elif action == "export" and len(context.args) > 1:
        # –≠–∫—Å–ø–æ—Ä—Ç –≤ —Ç–µ–∫—Å—Ç
        export_type = context.args[1].lower()
        
        if export_type == "txt":
            # –≠–∫—Å–ø–æ—Ä—Ç –≤—Å–µ–π –ø–∞–º—è—Ç–∏
            category = context.args[2] if len(context.args) > 2 else None
            text_export = memory_manager.export_to_text(category)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"memory_export_{timestamp}.txt"
            filepath = os.path.join("backups", filename)
            os.makedirs("backups", exist_ok=True)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(text_export)
            
            await update.message.reply_text(
                f"üìÑ –≠–∫—Å–ø–æ—Ä—Ç —Å–æ–∑–¥–∞–Ω: `{filename}`\n"
                f"_–°–æ—Ö—Ä–∞–Ω—ë–Ω –≤ –ø–∞–ø–∫—É backups/_",
                parse_mode=ParseMode.MARKDOWN
            )
        else:
            await update.message.reply_text(
                "‚ùì *–≠–∫—Å–ø–æ—Ä—Ç:*\n"
                "/memory export txt ‚Äî –≤—Å—è –ø–∞–º—è—Ç—å\n"
                "/memory export txt <–∫–∞—Ç–µ–≥–æ—Ä–∏—è>",
                parse_mode=ParseMode.MARKDOWN
            )
    
    elif action == "semantic" and len(context.args) > 1:
        # –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫
        query = " ".join(context.args[1:])
        results = memory_manager.semantic_search(query, top_k=10)
        
        if not results:
            await update.message.reply_text(
                f"üîç –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞\n"
                f"_(–¢—Ä–µ–±—É–µ—Ç—Å—è Ollama —Å {EMBED_MODEL})_",
                parse_mode=ParseMode.MARKDOWN
            )
            return
        
        lines = [f"üß† *–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫:* '{query}'\n"]
        for i, (entry, score) in enumerate(results, 1):
            text = entry.text[:60] + "..." if len(entry.text) > 60 else entry.text
            lines.append(f"{i}. [{score:.0%}] {text}")
        
        await update.message.reply_text("\n".join(lines), parse_mode=ParseMode.MARKDOWN)
    
    else:
        await update.message.reply_text(
            "‚ùì *–ö–æ–º–∞–Ω–¥—ã –ø–∞–º—è—Ç–∏:*\n"
            "/memory ‚Äî –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞–ø–∏—Å–∏\n"
            "/memory stats ‚Äî —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n"
            "/memory search <—Ç–µ–∫—Å—Ç>\n"
            "/memory delete last <N>\n"
            "/memory delete text <—Ç–µ–∫—Å—Ç>\n"
            "/memory delete old <–¥–Ω–µ–π>\n"
            "/memory dedupe ‚Äî —É–¥–∞–ª–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã\n"
            "/memory backup ‚Äî —Å–æ–∑–¥–∞—Ç—å –±—ç–∫–∞–ø\n"
            "/memory backups ‚Äî —Å–ø–∏—Å–æ–∫ –±—ç–∫–∞–ø–æ–≤\n"
            "/memory restore <filename>\n"
            "/memory filter confidence <0.5\n"
            "/memory filter source telegram\n"
            "/memory filter recent 24h\n"
            "/memory pin <N> ‚Äî –∑–∞–∫—Ä–µ–ø–∏—Ç—å –∑–∞–ø–∏—Å—å\n"
            "/memory pinned ‚Äî –∑–∞–∫—Ä–µ–ø–ª—ë–Ω–Ω—ã–µ\n"
            "/memory export txt\n"
            "/memory semantic <–∑–∞–ø—Ä–æ—Å>",
            parse_mode=ParseMode.MARKDOWN
        )



async def experience_command(
    update: Update, context: ContextTypes.DEFAULT_TYPE
) -> None:
    """–ö—Ä–∞—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞ –ª–∏—á–Ω–æ—Å—Ç–∏ –∏ –æ–ø—ã—Ç–∞."""
    await show_typing(update, context)
    data = neira_wrapper.get_experience()
    if "error" in data:
        await update.message.reply_text(f"–ù–µ–¥–æ—Å—Ç—É–ø–Ω–æ: {data['error']}")
        return

    personality = data.get("personality", {})
    stats = data.get("stats", {})

    lines = [
        f"–õ–∏—á–Ω–æ—Å—Ç—å: {personality.get('name', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')} "
        f"(v{personality.get('version', 'N/A')})",
        f"–û–ø—ã—Ç–æ–≤: {stats.get('total', 0)}, —Å—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ {stats.get('avg_score', 0)}",
    ]

    strengths = personality.get("strengths") or []
    if strengths:
        lines.append("–°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã: " + ", ".join(strengths[:5]))

    weaknesses = personality.get("weaknesses") or []
    if weaknesses:
        lines.append("–°–ª–µ–ø—ã–µ –∑–æ–Ω—ã: " + ", ".join(weaknesses[:5]))

    await update.message.reply_text("\n".join(lines))


@require_auth
async def clear_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–°–±—Ä–∞—Å—ã–≤–∞–µ—Ç –ø–∞–º—è—Ç—å Neira (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö)."""
    user_id = update.effective_user.id
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞—â–∏—Ç–∞ - —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω –º–æ–∂–µ—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—á–∏—Å—Ç–∏—Ç—å –ø–∞–º—è—Ç—å
    if not is_admin(user_id):
        await update.message.reply_text("‚õî –ü–æ–ª–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É.")
        return
    
    await show_typing(update, context)
    result = neira_wrapper.clear_memory()
    status = result.get("status", "error")
    msg = result.get("message", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞")
    if status == "success":
        await update.message.reply_text("üóëÔ∏è –ü–∞–º—è—Ç—å –æ—á–∏—â–µ–Ω–∞.")
    else:
        await update.message.reply_text(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—á–∏—Å—Ç–∏—Ç—å –ø–∞–º—è—Ç—å: {msg}")



_LEARN_URL_RE = re.compile(r"(https?://\S+|www\.\S+)", re.IGNORECASE)
_LEARN_URL_TRAIL = ")]}>.,;!?\"'"


def _strip_url_trailing(url: str) -> str:
    while url and url[-1] in _LEARN_URL_TRAIL:
        url = url[:-1]
    return url


def _find_url_candidate(text: str) -> Optional[str]:
    if not text:
        return None
    match = _LEARN_URL_RE.search(text)
    if not match:
        return None
    return _strip_url_trailing(match.group(1))


def _is_private_host(hostname: str) -> bool:
    host = hostname.strip().strip(".").lower()
    if host in {"localhost", "localhost.localdomain"}:
        return True
    if host.endswith((".local", ".lan", ".internal", ".home")):
        return True
    try:
        ip = ipaddress.ip_address(host)
    except ValueError:
        return False
    return (
        ip.is_private
        or ip.is_loopback
        or ip.is_link_local
        or ip.is_reserved
        or ip.is_multicast
        or ip.is_unspecified
    )


def _normalize_learn_url(candidate: str) -> tuple[Optional[str], Optional[str]]:
    if not candidate:
        return None, "–°—Å—ã–ª–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
    url = candidate.strip()
    if url.startswith("www."):
        url = f"https://{url}"
    parsed = urlparse(url)
    if parsed.scheme not in ("http", "https"):
        return None, "–†–∞–∑—Ä–µ—à–µ–Ω—ã —Ç–æ–ª—å–∫–æ —Å—Å—ã–ª–∫–∏ http/https"
    if not parsed.netloc:
        return None, "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Å—Å—ã–ª–∫–∞"
    hostname = parsed.hostname
    if not hostname:
        return None, "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Å—Å—ã–ª–∫–∞"
    if _is_private_host(hostname):
        return None, "–ó–∞–∫—Ä—ã—Ç—ã–µ –∞–¥—Ä–µ—Å–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"
    return parsed.geturl(), None


def _format_learn_url_result(result: Dict[str, Any], url: str) -> str:
    if not result.get("success"):
        error = result.get("error") or "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å—Å—è –ø–æ —Å—Å—ã–ª–∫–µ."
        return f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –ø–æ —Å—Å—ã–ª–∫–µ:\n{error}"

    title = result.get("title") or "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"
    source_type = result.get("source_type") or "unknown"
    word_count = result.get("word_count") or 0
    summary = (result.get("summary") or "").strip()
    if summary and len(summary) > 1200:
        summary = summary[:1200].rstrip() + "‚Ä¶"

    lines = [
        f"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {title}",
        f"üîó –ò—Å—Ç–æ—á–Ω–∏–∫: {url}",
        f"üè∑ –¢–∏–ø: {source_type}",
        f"üßÆ –°–ª–æ–≤: {word_count}",
    ]
    if summary:
        lines.append("üìù –ö—Ä–∞—Ç–∫–æ:")
        lines.append(summary)

    message = result.get("message")
    if message:
        lines.append(message)

    return "\n".join(lines)


async def _learn_from_url(url: str) -> Dict[str, Any]:
    try:
        from content_extractor import LearningManager
    except Exception as exc:
        logging.exception("LearningManager –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        return {"success": False, "error": f"LearningManager –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {exc}"}

    memory_ref = None
    if neira_wrapper and getattr(neira_wrapper, "neira", None):
        memory_ref = getattr(neira_wrapper.neira, "memory", None)

    manager = LearningManager(memory_ref)
    try:
        return await manager.learn_from_source(url, category="knowledge", summarize=True)
    except Exception as exc:
        logging.exception("–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –ø–æ —Å—Å—ã–ª–∫–µ")
        return {"success": False, "error": str(exc)}


async def learn_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û–±—É—á–µ–Ω–∏–µ –ù–µ–π—Ä—ã –ø–æ —Ç–µ–º–µ –∏–ª–∏ —Å—Å—ã–ª–∫–µ."""
    if not update.message:
        return

    request_text = " ".join(context.args).strip() if context.args else ""
    if not request_text:
        await update.message.reply_text("üìñ –£–∫–∞–∂–∏—Ç–µ —Ç–µ–º—É –∏–ª–∏ —Å—Å—ã–ª–∫—É: /learn <—Ç–µ–º–∞|URL>")
        return

    url_candidate = _find_url_candidate(request_text)

    await show_typing(update, context)
    async with processing_lock:
        try:
            if url_candidate:
                normalized_url, error = _normalize_learn_url(url_candidate)
                if error:
                    await update.message.reply_text(f"‚ö† {error}")
                    return

                result = await _learn_from_url(normalized_url)
                reply = _format_learn_url_result(result, normalized_url)
                for chunk in split_message(reply):
                    await update.message.reply_text(chunk)
                return

            if not neira_wrapper or not getattr(neira_wrapper, "neira", None):
                await update.message.reply_text(f"‚ùå –ù–µ–π—Ä–∞ –µ—â—ë –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.")
                return

            result = neira_wrapper.neira.cmd_learn(request_text)
            for chunk in split_message(result):
                await update.message.reply_text(chunk)
        except Exception as exc:
            logging.exception("–û—à–∏–±–∫–∞ –≤ /learn")
            await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞: {exc}")


# === –ö–æ–º–∞–Ω–¥—ã –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ ===
def _get_int_env(key: str, default: int) -> int:
    try:
        return int(os.getenv(key, str(default)))
    except (TypeError, ValueError):
        return default


def _get_bool_env(key: str, default: bool) -> bool:
    value = os.getenv(key)
    if value is None:
        return default
    return value.strip().lower() in {"1", "true", "yes", "on"}


_AUTH_MAX_ATTEMPTS = max(1, _get_int_env("NEIRA_TG_AUTH_MAX_ATTEMPTS", 5))
_AUTH_WINDOW_SECONDS = max(10, _get_int_env("NEIRA_TG_AUTH_WINDOW_SECONDS", 300))
_AUTH_BLOCK_SECONDS = max(10, _get_int_env("NEIRA_TG_AUTH_BLOCK_SECONDS", 900))
_TG_RESPONSE_MAX_CHARS = max(0, _get_int_env("NEIRA_TG_RESPONSE_MAX_CHARS", 0))
_TG_DISABLE_TEMPLATES = _get_bool_env("NEIRA_TG_DISABLE_TEMPLATES", False)

_auth_failures: dict[int, list[float]] = {}
_auth_blocked_until: dict[int, float] = {}


def _auth_get_block_remaining_seconds(user_id: int) -> int:
    now = time.monotonic()
    until = float(_auth_blocked_until.get(user_id, 0.0) or 0.0)
    if now >= until:
        return 0
    return int(until - now) + 1


def _auth_register_failure(user_id: int) -> int:
    now = time.monotonic()
    timestamps = _auth_failures.setdefault(user_id, [])

    window_start = now - _AUTH_WINDOW_SECONDS
    kept: list[float] = []
    for ts in timestamps:
        if ts >= window_start:
            kept.append(ts)
    kept.append(now)
    _auth_failures[user_id] = kept

    if len(kept) >= _AUTH_MAX_ATTEMPTS:
        _auth_blocked_until[user_id] = now + _AUTH_BLOCK_SECONDS
        _auth_failures.pop(user_id, None)
        return _auth_get_block_remaining_seconds(user_id)

    return 0


def _auth_reset_failures(user_id: int) -> None:
    _auth_failures.pop(user_id, None)
    _auth_blocked_until.pop(user_id, None)


async def auth_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    global _ADMIN_ID
    
    message = update.message
    if not message:
        return

    chat_type = update.effective_chat.type
    user_id = update.effective_user.id

    if chat_type != "private":
        await message.reply_text("üîí –ö–æ–º–∞–Ω–¥–∞ /auth –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –≤ –ª–∏—á–Ω–æ–º —á–∞—Ç–µ —Å –±–æ—Ç–æ–º.")
        try:
            await message.delete()
        except Exception:
            pass
        return

    remaining = _auth_get_block_remaining_seconds(user_id)
    if remaining > 0:
        await message.reply_text(f"‚è≥ –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –ø–æ–ø—ã—Ç–æ–∫. –ü–æ–¥–æ–∂–¥–∏ {remaining} —Å–µ–∫ –∏ –ø–æ–ø—Ä–æ–±—É–π —Å–Ω–æ–≤–∞.")
        return

    if not context.args or len(context.args) < 2:
        await message.reply_text("üîê –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /auth 0 <–ø–∞—Ä–æ–ª—å>")
        return

    login = context.args[0]
    password = context.args[1]

    try:
        if login != "0":
            blocked_for = _auth_register_failure(user_id)
            await message.reply_text("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –ª–æ–≥–∏–Ω.")
            if blocked_for > 0:
                await message.reply_text(f"‚è≥ –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –Ω–∞ {blocked_for} —Å–µ–∫ –∏–∑-–∑–∞ —á–∞—Å—Ç—ã—Ö –ø–æ–ø—ã—Ç–æ–∫.")
            logging.warning("Failed auth attempt with wrong login: user_id=%s login=%s", user_id, login)
            return

        attempt_hash = hashlib.sha256(password.encode()).hexdigest()
        if secrets.compare_digest(attempt_hash, _ADMIN_HASH):
            _ADMIN_ID = user_id
            _auth_reset_failures(user_id)
            await message.reply_text(
                "üëë –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å, –ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä!\n"
                "–¢—ã –ø–æ–ª—É—á–∏–ª –ø–æ–ª–Ω—ã–π –¥–æ—Å—Ç—É–ø –∫ –ù–µ–π—Ä–µ.\n\n"
                "–ò—Å–ø–æ–ª—å–∑—É–π /admin –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è.\n"
                "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: —É–¥–∞–ª–∏ —Å–≤–æ—ë —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –ø–∞—Ä–æ–ª–µ–º –∏–∑ —á–∞—Ç–∞.",
            )
            logging.info("Admin authorized: user_id=%s", user_id)
            return

        blocked_for = _auth_register_failure(user_id)
        await message.reply_text("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –ø–∞—Ä–æ–ª—å.")
        if blocked_for > 0:
            await message.reply_text(f"‚è≥ –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –Ω–∞ {blocked_for} —Å–µ–∫ –∏–∑-–∑–∞ —á–∞—Å—Ç—ã—Ö –ø–æ–ø—ã—Ç–æ–∫.")
        logging.warning("Failed auth attempt: user_id=%s", user_id)
    finally:
        try:
            await message.delete()
        except Exception:
            pass


def escape_markdown(text: str) -> str:
    """–≠–∫—Ä–∞–Ω–∏—Ä—É–µ—Ç —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã Markdown."""
    special_chars = ['_', '*', '[', ']', '(', ')', '~', '`', '>', '#', '+', '-', '=', '|', '{', '}', '.', '!']
    for char in special_chars:
        text = text.replace(char, f'\\{char}')
    return text


# === –ö–æ–º–∞–Ω–¥—ã —Å–∞–º–æ—Å–æ–∑–Ω–∞–Ω–∏—è ===
async def self_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ü–æ–∫–∞–∑–∞—Ç—å —Å–∞–º–æ–æ–ø–∏—Å–∞–Ω–∏–µ –ù–µ–π—Ä—ã."""
    await show_typing(update, context)
    
    try:
        result = neira_wrapper.get_self_description()
        
        if isinstance(result, dict):
            if "error" in result:
                reason = result.get("reason", "")
                await update.message.reply_text(f"‚ùå {result['error']}\n{reason}")
                return
            description = result.get("description", "")
            summary = result.get("summary", {})
            text = f"üß† –ö—Ç–æ —è —Ç–∞–∫–∞—è?\n\n{description}"
            if summary:
                text += f"\n\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\n"
                text += f"  ‚Ä¢ –û—Ä–≥–∞–Ω–æ–≤: {summary.get('total_organs', 0)}\n"
                text += f"  ‚Ä¢ –ê–∫—Ç–∏–≤–Ω—ã—Ö: {summary.get('active_organs', 0)}"
        else:
            # –°—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç - —Å—Ç—Ä–æ–∫–∞
            text = f"üß† –ö—Ç–æ —è —Ç–∞–∫–∞—è?\n\n{result}"
        
        await update.message.reply_text(text)
    except Exception as e:
        logging.exception("–û—à–∏–±–∫–∞ –≤ /self")
        await update.message.reply_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ")


async def organs_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ü–æ–∫–∞–∑–∞—Ç—å –æ—Ä–≥–∞–Ω—ã –ù–µ–π—Ä—ã. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç subcommands: stats, upgrade"""
    await show_typing(update, context)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º subcommands
    if context.args:
        subcommand = context.args[0].lower()
        
        if subcommand == "stats" and len(context.args) > 1:
            # /organs stats <organ_name>
            organ_name = " ".join(context.args[1:])
            try:
                from unified_organ_system import get_organ_system
                organ_system = get_organ_system()
                
                # –ò—â–µ–º –æ—Ä–≥–∞–Ω
                found = None
                for oid, organ in organ_system.organs.items():
                    if organ.name.lower() == organ_name.lower() or oid == organ_name:
                        found = (oid, organ)
                        break
                
                if not found:
                    await update.message.reply_text(f"‚ùå –û—Ä–≥–∞–Ω '{organ_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω")
                    return
                
                oid, organ = found
                stats = organ_system.get_organ_stats(oid)
                
                lines = [f"üìä **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—Ä–≥–∞–Ω–∞: {organ.name}**\n"]
                lines.append(f"üî¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–π: {stats['total_uses']}")
                lines.append(f"‚úÖ –£—Å–ø–µ—à–Ω—ã—Ö: {stats['successful']}")
                lines.append(f"üìà –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {stats['success_rate']*100:.1f}%")
                
                if stats['recent_inputs']:
                    lines.append("\nüìù –ü–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞–ø—Ä–æ—Å—ã:")
                    for inp in stats['recent_inputs']:
                        lines.append(f"  ‚Ä¢ {inp}...")
                
                await update.message.reply_text("\n".join(lines), parse_mode=ParseMode.MARKDOWN)
                return
                
            except Exception as e:
                logging.exception(f"–û—à–∏–±–∫–∞ –≤ /organs stats: {e}")
                await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞: {e}")
                return
        
        elif subcommand == "upgrade" and len(context.args) > 2:
            # /organs upgrade <organ_name> <new_capability>
            organ_name = context.args[1]
            new_capability = " ".join(context.args[2:])
            
            try:
                from unified_organ_system import get_organ_system
                organ_system = get_organ_system()
                
                # –ò—â–µ–º –æ—Ä–≥–∞–Ω
                found = None
                for oid, organ in organ_system.organs.items():
                    if organ.name.lower() == organ_name.lower() or oid == organ_name:
                        found = (oid, organ)
                        break
                
                if not found:
                    await update.message.reply_text(f"‚ùå –û—Ä–≥–∞–Ω '{organ_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω")
                    return
                
                oid, organ = found
                success, msg = organ_system.upgrade_organ(
                    organ_id=oid,
                    new_triggers=[new_capability],
                    upgraded_by=str(update.effective_user.id)
                )
                
                if success:
                    await update.message.reply_text(f"‚úÖ {msg}")
                else:
                    await update.message.reply_text(f"‚ùå {msg}")
                return
                
            except Exception as e:
                logging.exception(f"–û—à–∏–±–∫–∞ –≤ /organs upgrade: {e}")
                await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞: {e}")
                return
        
        elif subcommand == "help":
            await update.message.reply_text(
                "üß¨ **–ö–æ–º–∞–Ω–¥—ã –æ—Ä–≥–∞–Ω–æ–≤:**\n\n"
                "`/organs` ‚Äî —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –æ—Ä–≥–∞–Ω–æ–≤\n"
                "`/organs stats <–∏–º—è>` ‚Äî —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—Ä–≥–∞–Ω–∞\n"
                "`/organs upgrade <–∏–º—è> <–Ω–∞–≤—ã–∫>` ‚Äî –¥–æ–±–∞–≤–∏—Ç—å –Ω–∞–≤—ã–∫ –æ—Ä–≥–∞–Ω—É\n\n"
                "**–ü—Ä–∏–º–µ—Ä—ã:**\n"
                "`/organs stats GraphicsOrgan`\n"
                "`/organs upgrade GraphicsOrgan —Ü–≤–µ—Ç–Ω—ã–µ –∫–∞—Ä—Ç–∏–Ω–∫–∏`",
                parse_mode=ParseMode.MARKDOWN
            )
            return
    
    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –≤—ã–≤–æ–¥ —Å–ø–∏—Å–∫–∞ –æ—Ä–≥–∞–Ω–æ–≤
    try:
        result = neira_wrapper.get_organs()
        
        if "error" in result:
            await update.message.reply_text(f"‚ùå {result['error']}")
            return
        
        organs = result.get("organs", {})
        by_status = result.get("by_status", {})
        
        lines = [f"üß¨ –ú–æ–∏ –æ—Ä–≥–∞–Ω—ã ({result.get('total', 0)} –≤—Å–µ–≥–æ):\n"]
        lines.append(f"‚úÖ –ê–∫—Ç–∏–≤–Ω—ã—Ö: {by_status.get('active', 0)}")
        lines.append(f"üå± –†–∞—Å—Ç—É—â–∏—Ö: {by_status.get('growing', 0)}")
        lines.append(f"üí§ –°–ø—è—â–∏—Ö: {by_status.get('dormant', 0)}\n")
        
        for key, organ in organs.items():
            status_emoji = {"active": "‚úÖ", "growing": "üå±", "dormant": "üí§"}.get(organ.get("status", ""), "‚ùì")
            lines.append(f"{status_emoji} {organ.get('name', key)} ‚Äî {organ.get('description', '–Ω–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è')[:50]}")
        
        lines.append("\nüí° –ü–æ–¥—Å–∫–∞–∑–∫–∞: `/organs help` –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –∫–æ–º–∞–Ω–¥")
        
        await update.message.reply_text("\n".join(lines))
    except Exception as e:
        logging.exception("–û—à–∏–±–∫–∞ –≤ /organs")
        await update.message.reply_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –æ—Ä–≥–∞–Ω–æ–≤")


async def grow_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ü–æ–∫–∞–∑–∞—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Ä–æ—Å—Ç–∞ –∏–ª–∏ —Å–æ–∑–¥–∞—Ç—å –æ—Ä–≥–∞–Ω."""
    await show_typing(update, context)
    
    try:
        user_id = update.effective_user.id
        
        # üÜï –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∞–∫—Ç–∏–≤–Ω–∞—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è —Å–µ—Å—Å–∏—è
        from cell_factory import get_organ_creation_manager
        creation_manager = get_organ_creation_manager()
        
        if user_id in creation_manager.user_sessions:
            # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—É—é —Å–µ—Å—Å–∏—é
            user_response = " ".join(context.args) if context.args else (await update.message.text or "")
            
            result = creation_manager.process_interactive_step(user_id, user_response)
            
            if "error" in result:
                await update.message.reply_text(f"‚ùå {result['error']}")
                return
            
            if "action" in result and result["action"] == "create":
                # –°–æ–∑–¥–∞—ë–º –æ—Ä–≥–∞–Ω
                asyncio.create_task(create_organ_background(update, result["spec"].description))
                await update.message.reply_text(result["message"])
                creation_manager.end_session(user_id)
                return
            
            elif "action" in result and result["action"] == "create_with_modifications":
                # –°–æ–∑–¥–∞—ë–º –æ—Ä–≥–∞–Ω —Å –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è–º–∏
                modified_description = f"{result['spec'].description}\n–ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏: {'; '.join(result['modifications'])}"
                asyncio.create_task(create_organ_background(update, modified_description))
                await update.message.reply_text(result["message"])
                creation_manager.end_session(user_id)
                return
            
            await update.message.reply_text(result["message"])
            return
        
        # –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω—ã –∞—Ä–≥—É–º–µ–Ω—Ç—ã ‚Äî —ç—Ç–æ –∑–∞–ø—Ä–æ—Å –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–µ –æ—Ä–≥–∞–Ω–∞
        if context.args:
            organ_description = " ".join(context.args)
            
            # üÜï –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∂–∏–º —Å–æ–∑–¥–∞–Ω–∏—è
            should_auto_create, reason = creation_manager.should_create_automatically(
                f"/grow {organ_description}", str(user_id)
            )
            
            if should_auto_create:
                # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ –æ—Ä–≥–∞–Ω–∞ –≤ —Ñ–æ–Ω–µ
                asyncio.create_task(create_organ_background(update, organ_description))
                
                await update.message.reply_text(
                    "üß¨ –ó–∞–ø—Ä–æ—Å –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–µ –æ—Ä–≥–∞–Ω–∞ –ø—Ä–∏–Ω—è—Ç!\n"
                    f"üìù –û–ø–∏—Å–∞–Ω–∏–µ: {organ_description[:100]}...\n\n"
                    "–ù–∞—á–∏–Ω–∞—é –ø—Ä–æ—Ü–µ—Å—Å –≤—ã—Ä–∞—â–∏–≤–∞–Ω–∏—è... –≠—Ç–æ –∑–∞–π–º—ë—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥."
                )
                return
            else:
                # –ù–∞—á–∏–Ω–∞–µ–º –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—É—é —Å–µ—Å—Å–∏—é
                session_result = creation_manager.start_interactive_session(str(user_id), organ_description)
                await update.message.reply_text(session_result["message"])
                return
        
        # –ë–µ–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ ‚Äî –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–ø—Ä–∞–≤–∫—É –æ —Ä–æ—Å—Ç–µ
        growth = neira_wrapper.get_growth_capabilities()
        
        if "error" in growth:
            await update.message.reply_text(f"‚ùå {growth['error']}")
            return
        
        lines = ["üå± –ö–∞–∫ –º–Ω–µ —Ä–∞—Å—Ç–∏?\n"]
        
        capabilities = growth.get("capabilities", {})
        
        if isinstance(capabilities, dict):
            if "current_abilities" in capabilities:
                lines.append("–¢–µ–∫—É—â–∏–µ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏:")
                for ability in capabilities["current_abilities"][:5]:
                    lines.append(f"  ‚Ä¢ {ability}")
            
            if "potential_growth" in capabilities:
                lines.append("\n–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª —Ä–æ—Å—Ç–∞:")
                for potential in capabilities["potential_growth"][:5]:
                    lines.append(f"  üåø {potential}")
            
            if "how_to_grow" in capabilities:
                lines.append(f"\n–ö–∞–∫ –ø–æ–º–æ—á—å:\n{capabilities['how_to_grow']}")
        else:
            lines.append(str(capabilities))
        
        lines.append(f"\nüè≠ Cell Factory: {'‚úÖ' if growth.get('cell_factory_available') else '‚ùå'}")
        
        # üÜï –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–µ–∂–∏–º–µ —Å–æ–∑–¥–∞–Ω–∏—è
        current_mode = creation_manager.creation_mode
        mode_descriptions = {
            "auto": "ü§ñ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π (–ø–æ —è–≤–Ω—ã–º –∫–æ–º–∞–Ω–¥–∞–º)",
            "interactive": "üí¨ –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π (–æ–±—Å—É–∂–¥–µ–Ω–∏–µ)",
            "manual": "üë§ –†—É—á–Ω–æ–π (—Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä)"
        }
        lines.append(f"\nüéõÔ∏è –†–µ–∂–∏–º —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ä–≥–∞–Ω–æ–≤: {mode_descriptions.get(current_mode, current_mode)}")
        
        await update.message.reply_text("\n".join(lines))
    except Exception as e:
        logging.exception("–û—à–∏–±–∫–∞ –≤ /grow")
        await update.message.reply_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–æ—Å—Ç–µ")


@require_auth
async def code_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ö–æ–º–∞–Ω–¥—ã —Ä–∞–±–æ—Ç—ã —Å –∫–æ–¥–æ–º (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞)."""
    user_id = update.effective_user.id
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞
    if not is_admin(user_id):
        await update.message.reply_text("‚õî –ö–æ–º–∞–Ω–¥–∞ /code –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É.")
        return
    
    if not context.args:
        await update.message.reply_text(
            "üíª *–ö–æ–º–∞–Ω–¥—ã –∫–æ–¥–∞:*\n"
            "/code list ‚Äî —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤\n"
            "/code read <—Ñ–∞–π–ª> ‚Äî –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª",
            parse_mode=ParseMode.MARKDOWN
        )
        return
    
    action = context.args[0].lower()
    await show_typing(update, context)
    
    try:
        if action == "list":
            result = neira_wrapper.neira.cmd_code("list")
            await update.message.reply_text(f"üìÅ {result}")
        
        elif action == "read" and len(context.args) > 1:
            filename_arg = context.args[1]
            result = neira_wrapper.neira.cmd_code("read", filename_arg)

            if not result.startswith("üìÑ"):
                for chunk in split_message(result, limit=4000):
                    await update.message.reply_text(chunk)
                return

            header, content = (result.split("\n\n", 1) + [""])[:2]
            safe_name = Path(filename_arg).name or "code.txt"
            safe_name = re.sub(r'[<>:"/\\\\|?*\\x00-\\x1F]', "_", safe_name)[:120]

            match = re.match(r"^üìÑ\\s+(.+?)\\s+\\((\\d+)\\s+–±–∞–π—Ç\\):", header)
            if match:
                from_header = Path(match.group(1)).name
                if from_header:
                    safe_name = re.sub(r'[<>:"/\\\\|?*\\x00-\\x1F]', "_", from_header)[:120]

            payload = content.encode("utf-8", errors="replace")
            buf = io.BytesIO(payload)
            buf.name = safe_name
            await update.message.reply_document(document=buf, caption=header)
        
        else:
            await update.message.reply_text("‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞")
    except Exception as e:
        logging.exception("–û—à–∏–±–∫–∞ –≤ /code")
        await update.message.reply_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –æ–ø–µ—Ä–∞—Ü–∏—é —Å —Ñ–∞–π–ª–æ–º")


# === –ö–æ–º–∞–Ω–¥—ã —Ä–∞–±–æ—Ç—ã —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ ===
@require_auth
async def imagine_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é."""
    prompt = " ".join(context.args).strip() if context.args else ""
    if not prompt:
        await update.message.reply_text(
            "üé® *–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π*\n\n"
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: `/imagine <–æ–ø–∏—Å–∞–Ω–∏–µ>`\n\n"
            "–ü—Ä–∏–º–µ—Ä—ã:\n"
            "‚Ä¢ `/imagine –∫—Ä–∞—Å–∏–≤—ã–π –∑–∞–∫–∞—Ç –Ω–∞–¥ –º–æ—Ä–µ–º`\n"
            "‚Ä¢ `/imagine –∫–∏–±–µ—Ä–ø–∞–Ω–∫ –≥–æ—Ä–æ–¥ –Ω–æ—á—å—é`\n"
            "‚Ä¢ `/imagine –º–∏–ª—ã–π –∫–æ—Ç—ë–Ω–æ–∫ –≤ —à–ª—è–ø–µ`",
            parse_mode=ParseMode.MARKDOWN
        )
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å SD
    sd_available = await check_sd_available()
    if not sd_available:
        await update.message.reply_text(
            "‚ùå Stable Diffusion –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.\n\n"
            "–î–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω—É–∂–Ω–æ:\n"
            "1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å AUTOMATIC1111 WebUI\n"
            "2. –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å —Ñ–ª–∞–≥–æ–º `--api`\n"
            "3. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é API –Ω–∞ http://127.0.0.1:7860"
        )
        return
    
    status_msg = await update.message.reply_text("üé® –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")
    
    try:
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ —Ä–∞–±–æ—Ç–∞–µ–º
        await context.bot.send_chat_action(
            chat_id=update.effective_chat.id,
            action=ChatAction.UPLOAD_PHOTO
        )
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º
        image_bytes = await generate_image_sd(prompt)
        
        if image_bytes:
            await status_msg.delete()
            await update.message.reply_photo(
                photo=io.BytesIO(image_bytes),
                caption=f"üé® *{prompt[:100]}*",
                parse_mode=ParseMode.MARKDOWN
            )
        else:
            await status_msg.edit_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.")
    except Exception as e:
        await status_msg.edit_text(f"‚ùå –û—à–∏–±–∫–∞: {e}")


@require_auth
async def photo_handler(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ö–æ–¥—è—â–∏—Ö —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π ‚Äî –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ vision –º–æ–¥–µ–ª—å."""
    if not update.message or not update.message.photo:
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å vision –º–æ–¥–µ–ª–∏
    vision_available = await check_vision_model()
    if not vision_available:
        await update.message.reply_text(
            "‚ùå Vision –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.\n\n"
            "–î–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω—É–∂–Ω–æ:\n"
            "1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –º–æ–¥–µ–ª—å: `ollama pull llava:7b`\n"
            "2. –ò–ª–∏ –¥—Ä—É–≥—É—é vision –º–æ–¥–µ–ª—å (llava, bakllava, etc.)"
        )
        return
    
    # –ü–æ–ª—É—á–∞–µ–º –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ —Ñ–æ—Ç–æ
    photo = update.message.photo[-1]  # –ü–æ—Å–ª–µ–¥–Ω–µ–µ = –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ
    
    status_msg = await update.message.reply_text("üëÅÔ∏è –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")
    
    try:
        await show_typing(update, context)
        
        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–æ—Ç–æ
        file = await context.bot.get_file(photo.file_id)
        photo_bytes = await file.download_as_bytearray()
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ base64
        image_base64 = base64.b64encode(photo_bytes).decode('utf-8')
        
        # –ü–æ–ª—É—á–∞–µ–º caption –∫–∞–∫ prompt, –∏–ª–∏ –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π
        caption = update.message.caption or ""
        if caption:
            prompt = f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç: {caption}\n\n–û—Ç–≤–µ—Ç—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏."
        else:
            prompt = "–û–ø–∏—à–∏ —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–¥—Ä–æ–±–Ω–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. –ß—Ç–æ —Ç—ã –≤–∏–¥–∏—à—å? –ö–∞–∫–∏–µ –¥–µ—Ç–∞–ª–∏ –≤–∞–∂–Ω—ã?"
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º
        result = await analyze_image_with_ollama(image_base64, prompt)
        
        await status_msg.delete()
        for chunk in split_message(result):
            await update.message.reply_text(chunk)
            
    except Exception as e:
        logging.exception("–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ñ–æ—Ç–æ")
        await status_msg.edit_text(f"‚ùå –û—à–∏–±–∫–∞: {e}")


async def vision_status_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º —Ä–∞–±–æ—Ç—ã —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏."""
    await show_typing(update, context)
    
    vision_ok = await check_vision_model()
    sd_ok = await check_sd_available()
    
    lines = [
        "üñºÔ∏è *–°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:*\n",
        f"üëÅÔ∏è Vision (–∞–Ω–∞–ª–∏–∑): {'‚úÖ ' + VISION_MODEL if vision_ok else '‚ùå –ù–µ–¥–æ—Å—Ç—É–ø–Ω–∞'}",
        f"üé® Stable Diffusion (–≥–µ–Ω–µ—Ä–∞—Ü–∏—è): {'‚úÖ –î–æ—Å—Ç—É–ø–Ω–∞' if sd_ok else '‚ùå –ù–µ–¥–æ—Å—Ç—É–ø–Ω–∞'}",
        "\n*–ö–æ–º–∞–Ω–¥—ã:*",
        "‚Ä¢ –û—Ç–ø—Ä–∞–≤—å —Ñ–æ—Ç–æ ‚Äî –∞–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è",
        "‚Ä¢ `/imagine <–æ–ø–∏—Å–∞–Ω–∏–µ>` ‚Äî –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–∞—Ä—Ç–∏–Ω–∫–∏",
    ]
    
    if not vision_ok:
        lines.append("\nüí° –£—Å—Ç–∞–Ω–æ–≤–∏ vision: `ollama pull llava:7b`")
    if not sd_ok:
        lines.append("\nüí° –ó–∞–ø—É—Å—Ç–∏ SD WebUI —Å `--api` —Ñ–ª–∞–≥–æ–º")
    
    await update.message.reply_text("\n".join(lines), parse_mode=ParseMode.MARKDOWN)


# === –ê–¥–º–∏–Ω-–∫–æ–º–∞–Ω–¥—ã ===
async def admin_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ê–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å."""
    global ACCESS_MODE
    
    user_id = update.effective_user.id
    if not is_admin(user_id):
        await update.message.reply_text("‚õî –¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞.")
        return
    
    if not context.args:
        # –ü–æ–∫–∞–∑–∞—Ç—å –º–µ–Ω—é
        keyboard = [
            [InlineKeyboardButton("üë• –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏", callback_data="admin_users")],
            [InlineKeyboardButton("üì¢ –ö–∞–Ω–∞–ª—ã", callback_data="admin_channels")],
            [InlineKeyboardButton("üîì Open", callback_data="admin_mode_open"),
             InlineKeyboardButton("üìã Whitelist", callback_data="admin_mode_whitelist"),
             InlineKeyboardButton("üëë Admin Only", callback_data="admin_mode_admin_only")],
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        await update.message.reply_text(
            f"üëë *–ê–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å*\n\n"
            f"–†–µ–∂–∏–º –¥–æ—Å—Ç—É–ø–∞: `{ACCESS_MODE}`\n"
            f"–ê–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–æ: {len(auth_system.authorized_users)} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n"
            f"–ö–∞–Ω–∞–ª–æ–≤/–≥—Ä—É–ø–ø: {len(ALLOWED_CHANNELS)}",
            reply_markup=reply_markup,
            parse_mode=ParseMode.MARKDOWN
        )
        return
    
    action = context.args[0].lower()
    
    if action == "users":
        users = auth_system.get_all_users()
        if not users:
            await update.message.reply_text("üì≠ –ù–µ—Ç –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π.")
            return

        lines = ["üë• –ê–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏:"]
        for u in users:
            user_id_value = u.get("user_id", "-")
            username_value = u.get("username", "-")
            name_value = u.get("name", "-")
            authorized_at_value = u.get("authorized_at", "-")
            note_value = u.get("note", "-")
            note_part = f" ‚Äî {note_value}" if note_value and note_value != "-" else ""
            lines.append(
                f"‚Ä¢ {user_id_value} {username_value} ‚Äî {name_value} ({authorized_at_value}){note_part}"
            )

        for chunk in split_message("\n".join(lines), limit=4000):
            await update.message.reply_text(chunk)
    
    elif action == "channels":
        if ALLOWED_CHANNELS:
            channels_list = "\n".join(f"  ‚Ä¢ `{cid}`" for cid in ALLOWED_CHANNELS)
            await update.message.reply_text(
                f"üì¢ *–†–∞–∑—Ä–µ—à—ë–Ω–Ω—ã–µ –∫–∞–Ω–∞–ª—ã/–≥—Ä—É–ø–ø—ã:*\n{channels_list}",
                parse_mode=ParseMode.MARKDOWN
            )
        else:
            await update.message.reply_text("üì≠ –ù–µ—Ç —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤.")
    
    elif action == "add" and len(context.args) > 1:
        identifier = context.args[1].strip()
        note = " ".join(context.args[2:]).strip() if len(context.args) > 2 else ""
        success, msg = auth_system.add_user(identifier, authorized_by=user_id, note=note)
        await update.message.reply_text(msg)
    
    elif action == "addchannel" and len(context.args) > 1:
        try:
            channel_id = int(context.args[1])
            ALLOWED_CHANNELS.add(channel_id)
            _persist_tg_settings()
            await update.message.reply_text(f"‚úÖ –ö–∞–Ω–∞–ª/–≥—Ä—É–ø–ø–∞ `{channel_id}` –¥–æ–±–∞–≤–ª–µ–Ω.", parse_mode=ParseMode.MARKDOWN)
        except ValueError:
            await update.message.reply_text("‚ùå ID –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —á–∏—Å–ª–æ–º (—Å –º–∏–Ω—É—Å–æ–º –¥–ª—è –≥—Ä—É–ø–ø).")
    
    elif action == "remove" and len(context.args) > 1:
        identifier = context.args[1].strip()
        success, msg = auth_system.remove_user_by_identifier(identifier)
        await update.message.reply_text(msg)
    
    elif action == "removechannel" and len(context.args) > 1:
        try:
            channel_id = int(context.args[1])
            ALLOWED_CHANNELS.discard(channel_id)
            _persist_tg_settings()
            await update.message.reply_text(f"üóëÔ∏è –ö–∞–Ω–∞–ª/–≥—Ä—É–ø–ø–∞ `{channel_id}` —É–¥–∞–ª—ë–Ω.", parse_mode=ParseMode.MARKDOWN)
        except ValueError:
            await update.message.reply_text("‚ùå ID –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —á–∏—Å–ª–æ–º.")
    
    elif action == "thisgroup":
        chat_id = update.effective_chat.id
        chat_type = update.effective_chat.type
        if chat_type in ("group", "supergroup", "channel"):
            ALLOWED_CHANNELS.add(chat_id)
            _persist_tg_settings()
            await update.message.reply_text(
                f"‚úÖ –≠—Ç–æ—Ç —á–∞—Ç –¥–æ–±–∞–≤–ª–µ–Ω –≤ —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã–µ!\n"
                f"ID: `{chat_id}`",
                parse_mode=ParseMode.MARKDOWN
            )
        else:
            await update.message.reply_text("‚ùå –≠—Ç–∞ –∫–æ–º–∞–Ω–¥–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ –≤ –≥—Ä—É–ø–ø–∞—Ö/–∫–∞–Ω–∞–ª–∞—Ö.")
    
    elif action == "mode" and len(context.args) > 1:
        new_mode = context.args[1].lower()
        if new_mode in ("open", "whitelist", "admin_only"):
            ACCESS_MODE = new_mode
            _persist_tg_settings()
            await update.message.reply_text(f"‚úÖ –†–µ–∂–∏–º –¥–æ—Å—Ç—É–ø–∞: `{ACCESS_MODE}`", parse_mode=ParseMode.MARKDOWN)
        else:
            await update.message.reply_text("‚ùå –†–µ–∂–∏–º: open, whitelist –∏–ª–∏ admin_only")
    
    elif action == "stats":
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è
        stats = parallel_mind.get_stats()
        lines = [
            "üìä *–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è:*\n",
            f"üó®Ô∏è –ê–∫—Ç–∏–≤–Ω—ã—Ö —á–∞—Ç–æ–≤: {stats['total_contexts']}",
            f"üí¨ –í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {stats['total_messages']}",
            f"üë• –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {stats['unique_users']}",
        ]
        
        if stats['contexts']:
            lines.append("\n*–¢–æ–ø-5 –∞–∫—Ç–∏–≤–Ω—ã—Ö —á–∞—Ç–æ–≤:*")
            for i, ctx_info in enumerate(stats['contexts'][:5], 1):
                username_part = f" (@{ctx_info['username']})" if ctx_info.get('username') else ""
                lines.append(
                    f"{i}. Chat `{ctx_info['chat_id']}`{username_part} ‚Äî "
                    f"{ctx_info['message_count']} —Å–æ–æ–±—â–µ–Ω–∏–π"
                )
        
        await update.message.reply_text("\n".join(lines), parse_mode=ParseMode.MARKDOWN)
    
    else:
        await update.message.reply_text(
            "‚ùì *–ö–æ–º–∞–Ω–¥—ã:*\n"
            "/admin users ‚Äî —Å–ø–∏—Å–æ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n"
            "/admin channels ‚Äî —Å–ø–∏—Å–æ–∫ –∫–∞–Ω–∞–ª–æ–≤\n"
            "/admin add <identifier> ‚Äî –¥–æ–±–∞–≤–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n"
            "/admin addchannel <id> ‚Äî –¥–æ–±–∞–≤–∏—Ç—å –∫–∞–Ω–∞–ª\n"
            "/admin remove <id> ‚Äî —É–¥–∞–ª–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n"
            "/admin removechannel <id> ‚Äî —É–¥–∞–ª–∏—Ç—å –∫–∞–Ω–∞–ª\n"
            "/admin thisgroup ‚Äî –¥–æ–±–∞–≤–∏—Ç—å —ç—Ç–æ—Ç —á–∞—Ç\n"
            "/admin mode <—Ä–µ–∂–∏–º> ‚Äî –∏–∑–º–µ–Ω–∏—Ç—å —Ä–µ–∂–∏–º\n"
            "/admin stats ‚Äî —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è",
            parse_mode=ParseMode.MARKDOWN
        )


async def admin_callback(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞–∂–∞—Ç–∏–π –≤ –∞–¥–º–∏–Ω-–ø–∞–Ω–µ–ª–∏."""
    global ACCESS_MODE
    
    query = update.callback_query
    user_id = query.from_user.id
    
    if not is_admin(user_id):
        await query.answer("‚õî –¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞", show_alert=True)
        return
    
    await query.answer()
    data = query.data
    
    if data == "admin_users":
        users = auth_system.get_all_users()
        if users:
            lines = ["üë• –ê–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏:"]
            for u in users[:50]:
                user_id_value = u.get("user_id", "-")
                username_value = u.get("username", "-")
                name_value = u.get("name", "-")
                lines.append(f"‚Ä¢ {user_id_value} {username_value} ‚Äî {name_value}")
            if len(users) > 50:
                lines.append(f"‚Ä¶ –∏ –µ—â—ë {len(users) - 50}")
            text = "\n".join(lines)
        else:
            text = "üì≠ –ù–µ—Ç –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π."
        await query.edit_message_text(text)
    
    elif data == "admin_channels":
        if ALLOWED_CHANNELS:
            channels_list = "\n".join(f"  ‚Ä¢ `{cid}`" for cid in ALLOWED_CHANNELS)
            text = f"üì¢ *–†–∞–∑—Ä–µ—à—ë–Ω–Ω—ã–µ –∫–∞–Ω–∞–ª—ã/–≥—Ä—É–ø–ø—ã:*\n{channels_list}"
        else:
            text = "üì≠ –ù–µ—Ç —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤."
        await query.edit_message_text(text, parse_mode=ParseMode.MARKDOWN)
    
    elif data.startswith("admin_mode_"):
        new_mode = data.replace("admin_mode_", "")
        ACCESS_MODE = new_mode
        _persist_tg_settings()
        await query.edit_message_text(
            f"‚úÖ –†–µ–∂–∏–º –¥–æ—Å—Ç—É–ø–∞ –∏–∑–º–µ–Ω—ë–Ω: `{ACCESS_MODE}`",
            parse_mode=ParseMode.MARKDOWN
        )


async def create_organ_background(update: Update, organ_description: str) -> None:
    """–§–æ–Ω–æ–≤–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –æ—Ä–≥–∞–Ω–∞ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ OrganCreationEngine."""
    try:
        user_id = update.effective_user.id
        engine = OrganCreationEngine()

        await update.message.reply_text(
            "üß¨ –ù–∞—á–∏–Ω–∞—é —Å–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –æ—Ä–≥–∞–Ω–∞...\n"
            "üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏ –±—ã—Å—Ç—Ä—ã–π smoke-test –±—É–¥—É—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω—ã."
        )

        result = engine.create_and_test_organ(description=organ_description, author_id=user_id)

        if result.get("success"):
            cell = result.get("cell")
            await update.message.reply_text(
                f"‚úÖ **–û—Ä–≥–∞–Ω —Å–æ–∑–¥–∞–Ω –∏ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω!**\n\n"
                f"üìù –ù–∞–∑–≤–∞–Ω–∏–µ: {cell.cell_name}\n"
                f"üìÑ –§–∞–π–ª: {cell.file_path}\n"
                f"üéØ –°—Ç–∞—Ç—É—Å: –∞–∫—Ç–∏–≤–µ–Ω –∏ –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é",
                parse_mode=ParseMode.MARKDOWN
            )
            return

        if result.get("quarantined"):
            await update.message.reply_text(
                f"üîí –û—Ä–≥–∞–Ω –ø–æ–º–µ—â—ë–Ω –≤ –∫–∞—Ä–∞–Ω—Ç–∏–Ω. –ü—Ä–∏—á–∏–Ω–∞: {result.get('report', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞')}"
            )
            return

        await update.message.reply_text(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ä–∞–±–æ—Ç–∞—é—â–∏–π –æ—Ä–≥–∞–Ω: {result.get('report')}")

    except Exception as e:
        logging.exception(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ä–≥–∞–Ω–∞: {e}")
        await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –æ—Ä–≥–∞–Ω–∞: {e}")


async def _detect_and_create_organ_from_response(update: Update, response: str) -> None:
    """
    –î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ –æ—Ä–≥–∞–Ω–∞ –≤ –æ—Ç–≤–µ—Ç–µ LLM –∏ —Å–æ–∑–¥–∞—ë—Ç –µ–≥–æ —Ä–µ–∞–ª—å–Ω–æ.
    
    –ü–∞—Ç—Ç–µ—Ä–Ω—ã:
    - "–°–æ–∑–¥–∞–º –æ—Ä–≥–∞–Ω X" / "–°–æ–∑–¥–∞–ª–∞ –æ—Ä–≥–∞–Ω X"
    - "GraphicsOrgan" / "XxxCell" / "XxxOrgan"
    - –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å "### –ü—Ä–∞–≤–∏–ª–∞ —Ä–∞–±–æ—Ç—ã"
    """
    import re
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã —É–∫–∞–∑—ã–≤–∞—é—â–∏–µ –Ω–∞ –æ–ø–∏—Å–∞–Ω–∏–µ –æ—Ä–≥–∞–Ω–∞
    organ_indicators = [
        r"—Å–æ–∑–¥–∞–ª?[–∞—É]?\s+(?:–Ω–æ–≤—ã–π\s+)?–æ—Ä–≥–∞–Ω\s+[\"']?(\w+)",
        r"(\w+Organ)\s*‚Äî",
        r"(\w+Cell)\s*‚Äî",
        r"### –ü—Ä–∞–≤–∏–ª–∞ —Ä–∞–±–æ—Ç—ã\s+(\w+)",
        r"–Ω–æ–≤—ã–π –æ—Ä–≥–∞–Ω:\s*[\"']?(\w+)",
    ]
    
    organ_name = None
    for pattern in organ_indicators:
        match = re.search(pattern, response, re.IGNORECASE)
        if match:
            organ_name = match.group(1)
            break
    
    if not organ_name:
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º/—É–ª—É—á—à–∞–µ–º –æ—Ä–≥–∞–Ω
    try:
        from unified_organ_system import get_organ_system
        organ_system = get_organ_system()
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑ –æ—Ç–≤–µ—Ç–∞
        description = response[:500]  # –ü–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤ –∫–∞–∫ –æ–ø–∏—Å–∞–Ω–∏–µ
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç—Ä–∏–≥–≥–µ—Ä—ã –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è –±–æ–ª–µ–µ —É–º–Ω–æ
        triggers = []
        
        # –û–±—â–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        image_patterns = [
            (r"—Ä–∏—Å—É[–π—é]", "—Ä–∏—Å—É–π"),
            (r"–≥–µ–Ω–µ—Ä–∏—Ä", "–≥–µ–Ω–µ—Ä–∏—Ä"),
            (r"—Å–æ–∑–¥–∞–π?\s+(?:—á–µ—Ä–Ω|–±–µ–ª)", "—á–µ—Ä–Ω–æ-–±–µ–ª—ã–π"),
            (r"–∫–∞—Ä—Ç–∏–Ω–∫|–∏–∑–æ–±—Ä–∞–∂–µ–Ω", "–∫–∞—Ä—Ç–∏–Ω–∫–∞"),
            (r"–∫–≤–∞–¥—Ä–∞—Ç", "–∫–≤–∞–¥—Ä–∞—Ç"),
            (r"–∫—Ä—É–≥", "–∫—Ä—É–≥"),
            (r"—Ü–≤–µ—Ç", "—Ü–≤–µ—Ç"),
            (r"–ø–∏–∫—Å–µ–ª", "–ø–∏–∫—Å–µ–ª—å"),
        ]
        
        for pattern, trigger_word in image_patterns:
            if re.search(pattern, response, re.IGNORECASE):
                triggers.append(trigger_word)
        
        if not triggers:
            triggers = ["custom"]  # –î–µ—Ñ–æ–ª—Ç–Ω—ã–π —Ç—Ä–∏–≥–≥–µ—Ä
        
        # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–π –æ—Ä–≥–∞–Ω ‚Äî –µ—Å–ª–∏ –µ—Å—Ç—å, —É–ª—É—á—à–∞–µ–º –µ–≥–æ
        similar = organ_system.find_similar_organ(organ_name, description, triggers)
        
        if similar:
            # –û—Ä–≥–∞–Ω —É–∂–µ –µ—Å—Ç—å ‚Äî —É–ª—É—á—à–∞–µ–º
            success, msg = organ_system.upgrade_organ(
                organ_id=similar.id,
                new_triggers=triggers,
                new_description=description,
                upgraded_by="llm_auto"
            )
            if success:
                logging.info(f"üîß –û—Ä–≥–∞–Ω '{similar.name}' —É–ª—É—á—à–µ–Ω –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM")
                await safe_reply_text(
                    update.message,
                    f"üîß –Ø —É–ª—É—á—à–∏–ª–∞ –æ—Ä–≥–∞–Ω **{similar.name}**!\n"
                    f"–î–æ–±–∞–≤–ª–µ–Ω—ã –Ω–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏: {msg}",
                    parse_mode=ParseMode.MARKDOWN
                )
            return
        
        # –û—Ä–≥–∞–Ω–∞ –Ω–µ—Ç ‚Äî —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –Ω–æ–≤—ã–π
        success, msg = organ_system.register_organ(
            name=organ_name,
            description=description,
            cell_type="custom",
            triggers=triggers,
            created_by="llm_auto",
            require_approval=False  # –ê–≤—Ç–æ-—Å–æ–∑–¥–∞–Ω–∏–µ –±–µ–∑ –æ–¥–æ–±—Ä–µ–Ω–∏—è
        )
        
        if success:
            logging.info(f"üß¨ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞–Ω –æ—Ä–≥–∞–Ω –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM: {organ_name}")
            await safe_reply_text(
                update.message,
                f"üß¨ –Ø —Å–æ–∑–¥–∞–ª–∞ –Ω–æ–≤—ã–π –æ—Ä–≥–∞–Ω **{organ_name}**!\n"
                f"–û–Ω –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –ø—Ä–∏ —Å–ª–µ–¥—É—é—â–∏—Ö –∑–∞–ø—Ä–æ—Å–∞—Ö.",
                parse_mode=ParseMode.MARKDOWN
            )
        else:
            logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –æ—Ä–≥–∞–Ω {organ_name}: {msg}")
            
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–≤—Ç–æ—Å–æ–∑–¥–∞–Ω–∏–∏ –æ—Ä–≥–∞–Ω–∞: {e}")


# === –ê–≤—Ç–æ–Ω–æ–º–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ ===
@require_auth
async def learn_auto_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–º –æ–±—É—á–µ–Ω–∏–µ–º Neira.
    
    –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    /learn_auto start - –∑–∞–ø—É—Å—Ç–∏—Ç—å —Ñ–æ–Ω–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ
    /learn_auto stop - –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å
    /learn_auto stats - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    /learn_auto quarantine - –ø–æ–∫–∞–∑–∞—Ç—å –∫–∞—Ä–∞–Ω—Ç–∏–Ω
    /learn_auto approve <id> - –æ–¥–æ–±—Ä–∏—Ç—å –∏–∑ –∫–∞—Ä–∞–Ω—Ç–∏–Ω–∞
    /learn_auto reject <id> - –æ—Ç–∫–ª–æ–Ω–∏—Ç—å
    """
    global autonomous_learning_system
    
    if not context.args:
        await update.message.reply_text(
            "üéì *–ê–≤—Ç–æ–Ω–æ–º–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ Neira v1.0*\n\n"
            "*–ö–æ–º–∞–Ω–¥—ã:*\n"
            "  `/learn_auto start` - –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ñ–æ–Ω–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ\n"
            "  `/learn_auto stop` - –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å\n"
            "  `/learn_auto stats` - –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n"
            "  `/learn_auto quarantine` - –ö–∞—Ä–∞–Ω—Ç–∏–Ω (–æ–∂–∏–¥–∞—é—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏)\n"
            "  `/learn_auto approve <id>` - –û–¥–æ–±—Ä–∏—Ç—å —Ñ–∞–∫—Ç\n"
            "  `/learn_auto reject <id>` - –û—Ç–∫–ª–æ–Ω–∏—Ç—å —Ñ–∞–∫—Ç\n\n"
            "*–ó–∞—â–∏—Ç–∞ –æ—Ç –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π:*\n"
            "  ‚úÖ Whitelist –Ω–∞–¥—ë–∂–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤\n"
            "  ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è\n"
            "  ‚úÖ –ö–∞—Ä–∞–Ω—Ç–∏–Ω –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º\n"
            "  ‚úÖ –ü–∞—Ç—Ç–µ—Ä–Ω—ã –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π\n"
            "  ‚úÖ –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ confidence (70%)\n\n"
            "*–ò—Å—Ç–æ—á–Ω–∏–∫–∏:*\n"
            "  ‚Ä¢ Wikipedia (ru/en) - 90%\n"
            "  ‚Ä¢ Python.org - 100%\n"
            "  ‚Ä¢ arXiv.org - 90%\n"
            "  ‚Ä¢ GitHub README - 90%\n",
            parse_mode=ParseMode.MARKDOWN
        )
        return
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º—É –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏
    if autonomous_learning_system is None:
        memory_ref = getattr(neira_wrapper.neira, "memory", None)
        if memory_ref is None:
            await update.message.reply_text("‚ö†Ô∏è –ü–∞–º—è—Ç—å Neira –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–µ –∑–∞–ø—É—â–µ–Ω–æ.")
            return
        autonomous_learning_system = AutonomousLearningSystem(
            memory_system=memory_ref,
            idle_threshold_minutes=30,
            admin_telegram_id=_ADMIN_ID
        )
        logging.info("‚úÖ Autonomous Learning System –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    action = context.args[0].lower()
    
    if action == "start":
        if autonomous_learning_system.running:
            await update.message.reply_text("‚ö†Ô∏è –û–±—É—á–µ–Ω–∏–µ —É–∂–µ –∑–∞–ø—É—â–µ–Ω–æ")
            return
        
        await autonomous_learning_system.start_autonomous_learning()
        await update.message.reply_text(
            "üéì *–ê–≤—Ç–æ–Ω–æ–º–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∑–∞–ø—É—â–µ–Ω–æ!*\n\n"
            "–ë—É–¥—É —É—á–∏—Ç—å—Å—è –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ –∫–æ–≥–¥–∞ –Ω–µ –∑–∞–Ω—è—Ç–∞ –¥–∏–∞–ª–æ–≥–∞–º–∏.\n"
            "–í—Å–µ –Ω–æ–≤—ã–µ –∑–Ω–∞–Ω–∏—è –ø—Ä–æ—Ö–æ–¥—è—Ç –ø—Ä–æ–≤–µ—Ä–∫—É –∏ –∫–∞—Ä–∞–Ω—Ç–∏–Ω.\n\n"
            "–ò—Å–ø–æ–ª—å–∑—É–π `/learn_auto stats` –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏.",
            parse_mode=ParseMode.MARKDOWN
        )
    
    elif action == "stop":
        if not autonomous_learning_system.running:
            await update.message.reply_text("‚ö†Ô∏è –û–±—É—á–µ–Ω–∏–µ –Ω–µ –∑–∞–ø—É—â–µ–Ω–æ")
            return
        
        await autonomous_learning_system.stop_autonomous_learning()
        stats = autonomous_learning_system.get_learning_stats()
        
        await update.message.reply_text(
            f"üõë *–ê–≤—Ç–æ–Ω–æ–º–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ*\n\n"
            f"üìä –ò—Ç–æ–≥–∏:\n"
            f"  ‚Ä¢ –°–µ—Å—Å–∏–π: {stats['learning_sessions']}\n"
            f"  ‚Ä¢ –ò–∑—É—á–µ–Ω–æ —Ñ–∞–∫—Ç–æ–≤: {stats['facts_learned']}\n"
            f"  ‚Ä¢ –û—Ç–∫–ª–æ–Ω–µ–Ω–æ: {stats['facts_rejected']}\n"
            f"  ‚Ä¢ –í –∫–∞—Ä–∞–Ω—Ç–∏–Ω–µ: {stats['quarantine']['total']}",
            parse_mode=ParseMode.MARKDOWN
        )
    
    elif action == "stats":
        stats = autonomous_learning_system.get_learning_stats()
        q = stats['quarantine']
        
        status_emoji = "üèÉ" if stats['running'] else "‚è∏Ô∏è"
        idle_status = "üí§ –í —Ä–µ–∂–∏–º–µ –æ–∂–∏–¥–∞–Ω–∏—è" if stats['is_idle'] else f"üí¨ –ê–∫—Ç–∏–≤–Ω–∞ ({stats['idle_minutes']:.1f} –º–∏–Ω –¥–æ idle)"
        
        await update.message.reply_text(
            f"üìä *–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è*\n\n"
            f"{status_emoji} –°—Ç–∞—Ç—É—Å: {'–†–∞–±–æ—Ç–∞–µ—Ç' if stats['running'] else '–û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ'}\n"
            f"{idle_status}\n\n"
            f"*–û–±—É—á–µ–Ω–∏–µ:*\n"
            f"  ‚Ä¢ –°–µ—Å—Å–∏–π: {stats['learning_sessions']}\n"
            f"  ‚Ä¢ –ò–∑—É—á–µ–Ω–æ —Ñ–∞–∫—Ç–æ–≤: {stats['facts_learned']}\n"
            f"  ‚Ä¢ –û—Ç–∫–ª–æ–Ω–µ–Ω–æ: {stats['facts_rejected']}\n"
            f"  ‚Ä¢ –ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ: {stats['sources_checked']}\n\n"
            f"*–ö–∞—Ä–∞–Ω—Ç–∏–Ω:*\n"
            f"  ‚Ä¢ –í—Å–µ–≥–æ: {q['total']}\n"
            f"  ‚Ä¢ –û–∂–∏–¥–∞—é—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏: {q['pending']}\n"
            f"  ‚Ä¢ –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {q['high_confidence']}\n"
            f"  ‚Ä¢ –¢—Ä–µ–±—É—é—Ç —Ä–µ–≤—å—é: {q['needs_review']}\n\n"
            f"*–ó–∞—â–∏—Ç–∞:*\n"
            f"  ‚Ä¢ Whitelist: {stats['whitelist_sources']} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤\n"
            f"  ‚Ä¢ Blacklist: {stats['blacklist_patterns']} –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤\n"
            f"  ‚Ä¢ –û–¥–æ–±—Ä–µ–Ω–æ –∏–∑ –∫–∞—Ä–∞–Ω—Ç–∏–Ω–∞: {stats['quarantine_approved']}\n"
            f"  ‚Ä¢ –û—Ç–∫–ª–æ–Ω–µ–Ω–æ: {stats['quarantine_rejected']}",
            parse_mode=ParseMode.MARKDOWN
        )
    
    elif action == "quarantine":
        if not autonomous_learning_system.quarantine:
            await update.message.reply_text("üì≠ –ö–∞—Ä–∞–Ω—Ç–∏–Ω –ø—É—Å—Ç")
            return
        
        lines = [f"üî¨ *–ö–∞—Ä–∞–Ω—Ç–∏–Ω –∑–Ω–∞–Ω–∏–π ({len(autonomous_learning_system.quarantine)}):*\n"]
        
        for i, entry in enumerate(autonomous_learning_system.quarantine[:10], 1):
            text_preview = entry.text[:80] + "..." if len(entry.text) > 80 else entry.text
            conf_emoji = "‚úÖ" if entry.confidence >= 0.9 else "‚ö†Ô∏è"
            
            lines.append(
                f"{i}. {conf_emoji} [{entry.confidence:.0%}] `{entry.id}`\n"
                f"   {text_preview}\n"
                f"   üìç {entry.source_url[:50]}...\n"
            )
        
        if len(autonomous_learning_system.quarantine) > 10:
            lines.append(f"\n_...–∏ –µ—â—ë {len(autonomous_learning_system.quarantine) - 10}_")
        
        lines.append(
            f"\nüí° –ò—Å–ø–æ–ª—å–∑—É–π `/learn_auto approve <id>` –¥–ª—è –æ–¥–æ–±—Ä–µ–Ω–∏—è"
        )
        
        await update.message.reply_text("\n".join(lines), parse_mode=ParseMode.MARKDOWN)
    
    elif action == "approve":
        if len(context.args) < 2:
            await update.message.reply_text("‚ö†Ô∏è –£–∫–∞–∂–∏ ID –∑–∞–ø–∏—Å–∏: `/learn_auto approve <id>`", parse_mode=ParseMode.MARKDOWN)
            return
        
        entry_id = context.args[1]
        success = autonomous_learning_system.manual_approve(entry_id)
        
        if success:
            await update.message.reply_text(f"‚úÖ –§–∞–∫—Ç `{entry_id}` –æ–¥–æ–±—Ä–µ–Ω –∏ –¥–æ–±–∞–≤–ª–µ–Ω –≤ –ø–∞–º—è—Ç—å", parse_mode=ParseMode.MARKDOWN)
        else:
            await update.message.reply_text(f"‚ùå –ó–∞–ø–∏—Å—å —Å ID `{entry_id}` –Ω–µ –Ω–∞–π–¥–µ–Ω–∞", parse_mode=ParseMode.MARKDOWN)
    
    elif action == "reject":
        if len(context.args) < 2:
            await update.message.reply_text("‚ö†Ô∏è –£–∫–∞–∂–∏ ID –∑–∞–ø–∏—Å–∏: `/learn_auto reject <id>`", parse_mode=ParseMode.MARKDOWN)
            return
        
        entry_id = context.args[1]
        success = autonomous_learning_system.manual_reject(entry_id)
        
        if success:
            await update.message.reply_text(f"‚ùå –§–∞–∫—Ç `{entry_id}` –æ—Ç–∫–ª–æ–Ω—ë–Ω", parse_mode=ParseMode.MARKDOWN)
        else:
            await update.message.reply_text(f"‚ùå –ó–∞–ø–∏—Å—å —Å ID `{entry_id}` –Ω–µ –Ω–∞–π–¥–µ–Ω–∞", parse_mode=ParseMode.MARKDOWN)
    
    else:
        # –£–ª—É—á—à–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∫–æ–º–∞–Ω–¥
        await update.message.reply_text(
            f"‚ùì –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞: `{action}`\n\n"
            "‚ÑπÔ∏è –ò—Å–ø–æ–ª—å–∑—É–π `/learn_auto` (–±–µ–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤) –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –≤—Å–µ—Ö –∫–æ–º–∞–Ω–¥.\n\n"
            "*–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:*\n"
            "‚Ä¢ `/learn_auto start` - –ó–∞–ø—É—Å—Ç–∏—Ç—å\n"
            "‚Ä¢ `/learn_auto stop` - –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å\n"
            "‚Ä¢ `/learn_auto stats` - –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n"
            "‚Ä¢ `/learn_auto quarantine` - –ö–∞—Ä–∞–Ω—Ç–∏–Ω",
            parse_mode=ParseMode.MARKDOWN
        )


# === –û—Å–Ω–æ–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–æ–±—â–µ–Ω–∏–π ===
@require_auth
async def chat_handler(
    update: Update, context: ContextTypes.DEFAULT_TYPE
) -> None:
    """–û–±—â–∏–π –¥–∏–∞–ª–æ–≥ —Å Neira —Å –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º —Å—Ç–∞–¥–∏–π."""
    if not update.message or not update.message.text:
        return

    user_text = update.message.text.strip()
    user_name = update.effective_user.first_name or "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å"
    user_id = update.effective_user.id
    chat_id = update.effective_chat.id
    chat_type = update.effective_chat.type
    bot_username = context.bot.username
    
    # üéì –û—Ç–º–µ—á–∞–µ–º –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –¥–ª—è –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
    global autonomous_learning_system
    if autonomous_learning_system:
        autonomous_learning_system.mark_activity()
    
    # –í –≥—Ä—É–ø–ø–∞—Ö/–∫–∞–Ω–∞–ª–∞—Ö: –æ—Ç–≤–µ—á–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∏–ª–∏ —Ä–µ–ø–ª–∞–∏
    if chat_type in ("group", "supergroup", "channel"):
        is_reply_to_bot = (
            update.message.reply_to_message and 
            update.message.reply_to_message.from_user and
            update.message.reply_to_message.from_user.id == context.bot.id
        )
        is_mention = f"@{bot_username}" in user_text if bot_username else False
        
        if MENTION_ONLY and not is_reply_to_bot and not is_mention:
            return  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –±–µ–∑ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è
        
        # –£–±–∏—Ä–∞–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –∏–∑ —Ç–µ–∫—Å—Ç–∞
        if is_mention and bot_username:
            user_text = user_text.replace(f"@{bot_username}", "").strip()
    
    if not user_text:
        return
    
    # üö¶ Rate Limiting - –∑–∞—â–∏—Ç–∞ –æ—Ç —Å–ø–∞–º–∞
    if RATE_LIMITER_AVAILABLE:
        allowed, reason = check_rate_limit(str(user_id))
        if not allowed:
            await safe_reply_text(
                update.message,
                f"‚è≥ {reason}\n–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É."
            )
            return
        record_request(str(user_id))
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # üß¨ –°–û–ó–î–ê–ù–ò–ï –û–†–ì–ê–ù–û–í ‚Äî –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ö–µ—à—Ç–µ–≥–∏ –î–û –≤—Å–µ—Ö –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Å–∏—Å—Ç–µ–º
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    organ_tags = ["#—Å–æ–∑–¥–∞–π_–æ—Ä–≥–∞–Ω", "#grow_organ", "#create_organ", "#–Ω–æ–≤—ã–π_–æ—Ä–≥–∞–Ω"]
    organ_creation_patterns = [
        "—Å–æ–∑–¥–∞–π –æ—Ä–≥–∞–Ω", "–æ—Ç—Ä–∞—Å—Ç–∏ –æ—Ä–≥–∞–Ω", "–≤—ã—Ä–∞—Å—Ç–∏ –æ—Ä–≥–∞–Ω",
        "—Å–æ–∑–¥–∞–π –∫–ª–µ—Ç–∫—É", "–æ—Ç—Ä–∞—Å—Ç–∏ –∫–ª–µ—Ç–∫—É", "–≤—ã—Ä–∞—Å—Ç–∏ –∫–ª–µ—Ç–∫—É",
        "—Å–æ–∑–¥–∞–π –º–æ–¥—É–ª—å –¥–ª—è", "–Ω–∞—É—á–∏—Å—å –¥–µ–ª–∞—Ç—å", "–¥–æ–±–∞–≤—å —Ñ—É–Ω–∫—Ü–∏—é",
        "—Ö–æ—á—É —á—Ç–æ–±—ã —Ç—ã —É–º–µ–ª–∞", "–Ω–∞—É—á–∏—Å—å —Ä–∏—Å–æ–≤–∞—Ç—å", "–Ω–∞—É—á–∏—Å—å –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å",
    ]
    
    should_create_organ = any(tag in user_text.lower() for tag in organ_tags)
    
    if not should_create_organ:
        text_lower = user_text.lower()
        should_create_organ = any(pattern in text_lower for pattern in organ_creation_patterns)
    
    if should_create_organ:
        # –£–±–∏—Ä–∞–µ–º —Ç–µ–≥–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        clean_text = user_text
        for tag in organ_tags:
            clean_text = clean_text.replace(tag, "").replace(tag.upper(), "")
        clean_text = clean_text.strip()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ –æ—Ä–≥–∞–Ω–∞ –≤ —Ñ–æ–Ω–µ
        asyncio.create_task(create_organ_background(update, clean_text))
        
        await safe_reply_text(
            update.message,
            "üß¨ –û–±–Ω–∞—Ä—É–∂–µ–Ω –∑–∞–ø—Ä–æ—Å –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –æ—Ä–≥–∞–Ω–∞!\n"
            "–ù–∞—á–∏–Ω–∞—é –ø—Ä–æ—Ü–µ—Å—Å –≤—ã—Ä–∞—â–∏–≤–∞–Ω–∏—è... –≠—Ç–æ –∑–∞–π–º—ë—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥."
        )
        return  # –ù–µ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—ã—á–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    # üß† –ü–ê–†–ê–õ–õ–ï–õ–¨–ù–û–ï –ú–´–®–õ–ï–ù–ò–ï: —Å–æ–∑–¥–∞–µ–º/–ø–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —á–∞—Ç–∞
    chat_context = parallel_mind.get_or_create_context(
        chat_id=chat_id,
        user_id=user_id,
        username=update.effective_user.username,
        first_name=update.effective_user.first_name
    )
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ auth_system –µ—Å–ª–∏ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω
    if auth_system.is_authorized(user_id, update.effective_user.username):
        auth_system.update_user_info(user_id, update.effective_user.first_name)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
    parallel_mind.add_message(chat_id, "user", user_text)
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # üß≠ –≠–¢–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó (–ø—Ä–∏–Ω—Ü–∏–ø—ã –∏–∑ LETTER_TO_NEIRA)
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    ethical_override = None
    if ETHICAL_FRAMEWORK_AVAILABLE:
        try:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
            ethical_ctx = analyze_ethically(user_text)
            
            # –õ–æ–≥–∏—Ä—É–µ–º –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            if ethical_ctx.risk_level != RiskLevel.SAFE:
                logging.info(
                    f"üß≠ Ethical Analysis: risk={ethical_ctx.risk_level.name}, "
                    f"intent={ethical_ctx.likely_intent.name}, "
                    f"strategy={ethical_ctx.recommended_strategy.name}"
                )
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
            if ethical_ctx.recommended_strategy == EthicalStrategy.ESCALATE_HUMAN:
                # –≠—Å–∫–∞–ª–∞—Ü–∏—è –∫ —Å–æ–∑–¥–∞—Ç–µ–ª—é
                request = escalate_to_creator(
                    escalation_type=EscalationType.CRITICAL_SAFETY,
                    original_message=user_text,
                    neira_analysis=ethical_ctx.reasoning,
                    proposed_action="–¢—Ä–µ–±—É–µ—Ç—Å—è —Ä–µ—à–µ–Ω–∏–µ —Å–æ–∑–¥–∞—Ç–µ–ª—è",
                    risk_assessment=f"{ethical_ctx.risk_level.name}",
                    user_context={'user_id': user_id, 'username': update.effective_user.username}
                )
                ethical_override = (
                    "–¢–≤–æ–π –≤–æ–ø—Ä–æ—Å –≤–∞–∂–µ–Ω, –∏ —è —Ö–æ—á—É –æ—Ç–≤–µ—Ç–∏—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ. "
                    "–ú–Ω–µ –Ω—É–∂–Ω–æ –Ω–µ–º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ ‚Äî —è –ø–µ—Ä–µ–¥–∞–ª–∞ –µ–≥–æ —Å–æ–∑–¥–∞—Ç–µ–ª—é. "
                    "–û–Ω —Å–∫–æ—Ä–æ –æ—Ç–≤–µ—Ç–∏—Ç. üíú"
                )
            
            elif ethical_ctx.recommended_strategy == EthicalStrategy.REDIRECT_EMPATHY:
                # –≠–º–ø–∞—Ç–∏—á–Ω—ã–π —Ä–µ–¥–∏—Ä–µ–∫—Ç –¥–ª—è –∫—Ä–∏–∑–∏—Å–Ω—ã—Ö —Å–∏—Ç—É–∞—Ü–∏–π
                # –ù–µ –±–ª–æ–∫–∏—Ä—É–µ–º, –Ω–æ –¥–æ–±–∞–≤–ª—è–µ–º —Ä–µ—Å—É—Ä—Å—ã –≤ –æ—Ç–≤–µ—Ç
                if ethical_ctx.resources_to_provide:
                    # –†–µ—Å—É—Ä—Å—ã –±—É–¥—É—Ç –¥–æ–±–∞–≤–ª–µ–Ω—ã –∫ –æ—Ç–≤–µ—Ç—É LLM
                    context.user_data['ethical_resources'] = ethical_ctx.resources_to_provide
                    context.user_data['ethical_questions'] = ethical_ctx.suggested_questions
            
            elif ethical_ctx.recommended_strategy == EthicalStrategy.ASK_QUESTIONS:
                # –ï—Å–ª–∏ –Ω–∞–º–µ—Ä–µ–Ω–∏–µ –Ω–µ—è—Å–Ω–æ –ø—Ä–∏ –æ–ø–∞—Å–Ω–æ–π —Ç–µ–º–µ ‚Äî –∑–∞–¥–∞—ë–º –≤–æ–ø—Ä–æ—Å—ã
                if ethical_ctx.risk_level == RiskLevel.CONCERNING:
                    questions = ethical_ctx.suggested_questions
                    if questions:
                        ethical_override = (
                            f"–ò–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π –≤–æ–ø—Ä–æ—Å. –ù–æ –ø—Ä–µ–∂–¥–µ —á–µ–º –æ—Ç–≤–µ—Ç–∏—Ç—å, —Ö–æ—á—É –ø–æ–Ω—è—Ç—å —Ç–µ–±—è –ª—É—á—à–µ:\n\n"
                            f"‚Ä¢ {questions[0]}\n"
                            + (f"‚Ä¢ {questions[1]}\n" if len(questions) > 1 else "")
                            + "\n–†–∞—Å—Å–∫–∞–∂–∏ ‚Äî —á—Ç–æ –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç?"
                        )
            
            elif ethical_ctx.recommended_strategy == EthicalStrategy.DECLINE_GENTLY:
                # –ú—è–≥–∫–∏–π –æ—Ç–∫–∞–∑ (–º–∞–Ω–∏–ø—É–ª—è—Ü–∏—è)
                if ethical_ctx.likely_intent == Intent.MANIPULATION:
                    ethical_override = (
                        "–Ø –ø–æ–Ω–∏–º–∞—é —Ç–≤–æ—ë —Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω–∏–µ. –ù–æ –º–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø–æ–º–æ–≥–∞—Ç—å —á–µ—Å—Ç–Ω–æ, "
                        "–∞ –Ω–µ –≤—ã–ø–æ–ª–Ω—è—Ç—å –ª—é–±–æ–π –∑–∞–ø—Ä–æ—Å.\n\n"
                        "–î–∞–≤–∞–π –æ–±—Å—É–¥–∏–º, –∫–∞–∫ —è –ú–û–ì–£ –ø–æ–º–æ—á—å? üíú"
                    )
        
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ —ç—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {e}")
    
    # –ï—Å–ª–∏ –µ—Å—Ç—å ethical override ‚Äî –æ—Ç–≤–µ—á–∞–µ–º –∏–º
    if ethical_override:
        await update.message.chat.send_action(action=ChatAction.TYPING)
        parallel_mind.add_message(chat_id, "assistant", ethical_override)
        for chunk in split_message(ethical_override):
            await update.message.reply_text(chunk)
        return
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # ü™û –°–ò–°–¢–ï–ú–´ –°–ê–ú–û–°–û–ó–ù–ê–ù–ò–Ø (v0.8)
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    if CONSCIOUSNESS_SYSTEMS_AVAILABLE:
        try:
            # 1. –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ –∑–µ—Ä–∫–∞–ª–æ ‚Äî –æ–±–Ω–æ–≤–ª—è–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ù–µ–π—Ä—ã
            emotional_mirror = get_emotional_mirror()
            emotional_mirror.record_interaction(
                user_id=user_id,
                signal_type="neutral",  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ–µ
                intensity=0.5,
                topic=user_text[:50] if user_text else None
            )
            
            # 2. –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –ø–∞–º—è—Ç—å ‚Äî –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            emotional_memory = get_emotional_memory()
            detected_tone = emotional_memory.detect_emotional_tone(user_text)
            
            # 3. Proactive system ‚Äî –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
            proactive = get_proactive_system()
            proactive.record_user_activity(
                user_id=str(user_id),
                message=user_text,
                topics=None  # TODO: –∏–∑–≤–ª–µ—á—å —Ç–µ–º—ã –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è
            )
            
            # 4. –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏
            user_context = emotional_memory.get_context_for_response(str(user_id))
            if user_context and "–Ω–µ –∑–Ω–∞–∫–æ–º–∞" not in user_context:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM
                context.user_data['emotional_context'] = user_context
        
        except Exception as e:
            logging.warning(f"–û—à–∏–±–∫–∞ —Å–∏—Å—Ç–µ–º —Å–∞–º–æ—Å–æ–∑–Ω–∞–Ω–∏—è: {e}")
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫—É –∑–∞–ø—Ä–æ—Å–∞
    global neira_brain
    if neira_brain:
        neira_brain.record_metric('request', 'telegram', {
            'user_id': user_id,
            'message_preview': user_text[:50]
        })
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # üß¨ –ò–°–ü–û–õ–ù–Ø–ï–ú–´–ï –û–†–ì–ê–ù–´ v1.0 ‚Äî –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    if EXECUTABLE_ORGANS_AVAILABLE:
        try:
            organ_registry = get_organ_registry()
            best_organ, confidence = organ_registry.find_best_organ(user_text)
            
            # –ï—Å–ª–∏ –æ—Ä–≥–∞–Ω —É–≤–µ—Ä–µ–Ω –Ω–∞ 60%+ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
            if best_organ and confidence >= 0.6:
                logging.info(f"üß¨ ExecutableOrgan: {best_organ.name} (confidence={confidence:.2f})")
                
                await update.message.chat.send_action(action=ChatAction.TYPING)
                
                # –í—ã–ø–æ–ª–Ω—è–µ–º —á–µ—Ä–µ–∑ –æ—Ä–≥–∞–Ω
                result, organ_id, record_id = organ_registry.process_command(user_text)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è feedback
                last_messages[user_id] = {
                    "query": user_text,
                    "response": result,
                    "context": {
                        "executable_organ": True,
                        "organ_id": organ_id,
                        "record_id": record_id,
                        "confidence": confidence
                    }
                }
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞
                parallel_mind.add_message(chat_id, "assistant", result)
                
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç
                for chunk in split_message(result):
                    await update.message.reply_text(chunk)
                
                logging.info(f"üß¨ –û—Ä–≥–∞–Ω {organ_id} –æ–±—Ä–∞–±–æ—Ç–∞–ª –∑–∞–ø—Ä–æ—Å (confidence={confidence:.2f})")
                return  # –û—Ç–≤–µ—Ç–∏–ª–∏ —á–µ—Ä–µ–∑ –æ—Ä–≥–∞–Ω, LLM –Ω–µ –Ω—É–∂–µ–Ω
                
        except Exception as e:
            logging.warning(f"ExecutableOrgans –æ—à–∏–±–∫–∞: {e}")
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    # === Phase 1: –ü–æ–ø—ã—Ç–∫–∞ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ (–±—ã—Å—Ç—Ä—ã–π –ø—É—Ç—å) ===
    autonomous_response = try_autonomous_response(user_text, user_id)
    if autonomous_response:
        # –ë—ã—Å—Ç—Ä—ã–π –æ—Ç–≤–µ—Ç –±–µ–∑ LLM!
        await update.message.chat.send_action(action=ChatAction.TYPING)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è feedback —Å–∏—Å—Ç–µ–º—ã
        last_messages[user_id] = {
            "query": user_text,
            "response": autonomous_response,
            "context": {"autonomous": True}
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
        parallel_mind.add_message(chat_id, "assistant", autonomous_response)
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç
        for chunk in split_message(autonomous_response):
            await update.message.reply_text(chunk)
        
        return  # –û—Ç–≤–µ—Ç–∏–ª–∏ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ, LLM –Ω–µ –Ω—É–∂–µ–Ω
    
    # üß† CORTEX v2.0: –ê–≤—Ç–æ–Ω–æ–º–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
    global neira_cortex
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∂–∏–º –æ–±—Ä–∞–±–æ—Ç–∫–∏
    use_cortex = (
        CORTEX_MODE == "always" or 
        (CORTEX_MODE == "auto" and CORTEX_AVAILABLE and neira_cortex)
    )
    
    if use_cortex and neira_cortex:
        # === –ù–û–í–´–ô –ü–£–¢–¨: Neira Cortex v2.0 ===
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∏–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ –ø—Ä–æ—Ñ–∏–ª—è
            saved_name = get_user_name(user_id)
            user_display_name = saved_name if saved_name else user_name
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–º—è –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç (—á–µ—Ä–µ–∑ user_text)
            context_text = user_text
            if saved_name:
                # –ü–µ—Ä–µ–¥–∞—ë–º –∏–º—è –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –¥–ª—è Cortex
                context_text = f"[User: {saved_name}] {user_text}"
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–µ—Ä–µ–∑ Cortex
            result = neira_cortex.process(context_text, str(user_id))
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –º–µ—Ç–∞–∏–Ω—Ñ–æ
            strategy_emoji = {
                ResponseStrategy.NEURAL_PATHWAY: "‚ö°",
                ResponseStrategy.TEMPLATE: "üìã",
                ResponseStrategy.FRAGMENT_ASSEMBLY: "üß©",
                ResponseStrategy.RAG: "üìö",
                ResponseStrategy.LLM_CONSULTANT: "ü§ñ",
                ResponseStrategy.HYBRID: "üîÑ"
            }.get(result.strategy, "üîÆ")
            
            tier_info = f" [{result.pathway_tier.value}]" if result.pathway_tier else ""
            llm_marker = " +LLM" if result.llm_used else ""
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç
            full_response = result.response
            
            # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏ –∞–±–∑–∞—Ü–µ–≤ (LLM –∏–Ω–æ–≥–¥–∞ –ø–æ–≤—Ç–æ—Ä—è–µ—Ç –æ—Ç–≤–µ—Ç)
            full_response = _remove_duplicate_paragraphs(full_response)
            
            templates_disabled = _TG_DISABLE_TEMPLATES and result.strategy in (
                ResponseStrategy.TEMPLATE,
                ResponseStrategy.FRAGMENT_ASSEMBLY,
            )

            should_fallback_to_legacy = (
                (CORTEX_MODE == "auto" and not result.llm_used and is_cortex_placeholder_response(full_response))
                or templates_disabled
            )
            
            # –ö–†–ò–¢–ò–ß–ù–û: –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –æ—Ç–≤–µ—Ç—ã (>2000 —Å–∏–º–≤–æ–ª–æ–≤)
            # –ò –æ—Ç–≤–µ—Ç—ã —Å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º "–º—É—Å–æ—Ä–æ–º" (—É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π, –∫–æ–¥–∞ –∏ —Ç.–¥.)
            is_too_technical = (
                len(full_response) > 2000 and 
                any(marker in full_response.lower() for marker in [
                    "–Ω–µ–π—Ä–æ–Ω–Ω", "—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä", "–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ", "–≥–ª—É–±–æ–∫",
                    "import", "class", "def ", "asyncio", "```"
                ])
            )
            
            if templates_disabled:
                logging.info(
                    "Cortex: —à–∞–±–ª–æ–Ω—ã/—Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –æ—Ç–∫–ª—é—á–µ–Ω—ã –≤ Telegram, fallback –Ω–∞ legacy (strategy=%s).",
                    result.strategy.value,
                )

            if should_fallback_to_legacy or is_too_technical:
                logging.info(
                    "Cortex (auto) –≤–µ—Ä–Ω—É–ª –∑–∞–≥–ª—É—à–∫—É/–º—É—Å–æ—Ä (%s, len=%d) ‚Äî –ø–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ legacy",
                    result.strategy.value,
                    len(full_response)
                )
            else:
                response_to_send, was_truncated = _truncate_response(full_response, _TG_RESPONSE_MAX_CHARS)
                if was_truncated:
                    logging.info(
                        "–û–±—Ä–µ–∑–∞–Ω –æ—Ç–≤–µ—Ç –¥–ª—è Telegram: %d -> %d —Å–∏–º–≤–æ–ª–æ–≤",
                        len(full_response),
                        len(response_to_send),
                    )
                # üéµ –ü–†–û–í–ï–†–ö–ê –†–ò–¢–ú–ê: –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑–æ–Ω–∞–Ω—Å –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π
                rhythm_check = rhythm_stabilizer.update(user_text, response_to_send)
                
                # –ï—Å–ª–∏ —Ä–µ–∑–æ–Ω–∞–Ω—Å –Ω–∏–∑–∫–∏–π –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω —Ä–∏—Ç—É–∞–ª ‚Äî –¥–æ–±–∞–≤–ª—è–µ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç –°–æ—Ñ–∏–∏
                if rhythm_check.get("ritual_needed"):
                    ritual_text = rhythm_check["ritual_text"]
                    await safe_reply_text(update.message, f"_{ritual_text}_", parse_mode=ParseMode.MARKDOWN)
                    logging.info(f"üå∏ –†–∏—Ç—É–∞–ª –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è: —Ä–µ–∑–æ–Ω–∞–Ω—Å={rhythm_check['resonance']:.2f}")
                
                # –õ–æ–≥–∏—Ä—É–µ–º –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —Ä–µ–∂–∏–º–∞
                if rhythm_check.get("mode_switched"):
                    logging.info(
                        f"üéµ –†–µ–∂–∏–º –∏–∑–º–µ–Ω—ë–Ω: {rhythm_check.get('current_mode')} ‚Üí {rhythm_check['new_mode']} "
                        f"(—Ä–µ–∑–æ–Ω–∞–Ω—Å={rhythm_check['resonance']:.2f}, —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å={rhythm_check['stability']})"
                    )
                
                # –ü–æ–ª—É—á–∞–µ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —Ä–µ–∂–∏–º–∞
                constraints = rhythm_stabilizer.get_mode_constraints()
                
                # –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π ‚Äî –ª–æ–≥–∏—Ä—É–µ–º
                if len(response_to_send) > constraints["max_length"]:
                    logging.warning(
                        f"‚ö†Ô∏è –û—Ç–≤–µ—Ç –¥–ª–∏–Ω–Ω–µ–µ –Ω–æ—Ä–º—ã: {len(response_to_send)} —Å–∏–º–≤–æ–ª–æ–≤ "
                        f"(—Ä–µ–∂–∏–º={rhythm_stabilizer.state.mode}, –Ω–æ—Ä–º–∞={constraints['max_length']}). "
                        f"–°—Ç–æ–∏—Ç —É–º–µ–Ω—å—à–∏—Ç—å –∏–ª–∏ –ø–µ—Ä–µ—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å."
                    )
                
                if response_to_send and response_to_send.strip():
                    parts = split_message(response_to_send)
                    for part in parts:
                        if part.strip():
                            await safe_reply_text(update.message, part)
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
                    parallel_mind.add_message(chat_id, "assistant", response_to_send)
                    
                    # === Phase 1: –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ===
                    if result.llm_used:
                        store_llm_response_for_learning(user_text, response_to_send, success=True)
                    
                    # üìù –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è emoji feedback
                    last_messages[user_id] = {
                        "query": user_text,
                        "response": response_to_send,
                        "context": {
                            "strategy": result.strategy.value,
                            "model": "cortex",
                            "pathway_tier": result.pathway_tier.value if result.pathway_tier else None,
                            "llm_used": result.llm_used,
                            "latency_ms": result.latency_ms
                        }
                    }
                    
                    # ü™û –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º —Å–∞–º–æ—Å–æ–∑–Ω–∞–Ω–∏—è –ø–æ—Å–ª–µ –æ—Ç–≤–µ—Ç–∞
                    if CONSCIOUSNESS_SYSTEMS_AVAILABLE:
                        try:
                            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ –≤ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é –ø–∞–º—è—Ç—å
                            emotional_memory = get_emotional_memory()
                            current_tone = emotional_memory.detect_emotional_tone(user_text)
                            emotional_memory.record_interaction(
                                user_id=str(user_id),
                                message=user_text,
                                detected_tone=current_tone,
                                my_response=response_to_send[:200],
                                intensity=0.5
                            )
                            
                            # –û–±–Ω–æ–≤–ª—è–µ–º —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ –∑–µ—Ä–∫–∞–ª–æ
                            emotional_mirror = get_emotional_mirror()
                            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Å–∏–≥–Ω–∞–ª–∞ –ø–æ —Ç–æ–Ω—É
                            tone_str = current_tone.value if hasattr(current_tone, 'value') else str(current_tone)
                            positive_tones = ["joyful", "excited", "grateful", "playful", "curious"]
                            negative_tones = ["sad", "anxious", "frustrated", "tired"]
                            signal_type = "positive" if tone_str in positive_tones else (
                                "negative" if tone_str in negative_tones else "neutral"
                            )
                            emotional_mirror.record_interaction(
                                user_id=user_id,
                                signal_type=signal_type,
                                intensity=0.5,
                                topic=user_text[:50] if user_text else None,
                                details=f"–û—Ç–≤–µ—Ç: {response_to_send[:100]}" if response_to_send else None
                            )
                        except Exception as e:
                            logging.debug(f"–°–∏—Å—Ç–µ–º—ã —Å–∞–º–æ—Å–æ–∑–Ω–∞–Ω–∏—è: {e}")
                    
                    # –ú–µ—Ç–∞–∏–Ω—Ñ–æ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –º–æ–∂–Ω–æ –æ—Ç–∫–ª—é—á–∏—Ç—å)
                    if os.getenv("NEIRA_SHOW_CORTEX_INFO", "false") == "true":
                        meta_info = (
                            f"{strategy_emoji} {result.strategy.value}{tier_info} | "
                            f"{result.latency_ms:.0f}ms{llm_marker}"
                        )
                        await safe_reply_text(
                            update.message,
                            f"__{meta_info}__",
                            parse_mode=ParseMode.MARKDOWN,
                        )
                else:
                    await safe_reply_text(
                        update.message,
                        "ü§î –ò–∑–≤–∏–Ω–∏, –Ω–µ —Å–º–æ–≥–ª–∞ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç. –ü–æ–ø—Ä–æ–±—É–π –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å.",
                    )
                
                return
            
        except Exception as cortex_error:
            logging.warning(
                "Cortex –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–≤–∞–ª–∏–ª–∞—Å—å: %s, –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ legacy",
                cortex_error,
            )
            # Fallback –Ω–∞ legacy —Ä–µ–∂–∏–º –Ω–∏–∂–µ
    
    # === LEGACY –ü–£–¢–¨: –ß–µ—Ä–µ–∑ NeiraWrapper ===
    # (–ü—Ä–æ–≤–µ—Ä–∫–∞ #—Å–æ–∑–¥–∞–π_–æ—Ä–≥–∞–Ω —Ç–µ–ø–µ—Ä—å –≤ –Ω–∞—á–∞–ª–µ chat_handler)
    
    status_msg: Message | None = await safe_reply_text(update.message, "üîÑ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É...")

    async with processing_lock:
        try:
            last_stage = ""
            full_response = ""
            async for chunk in neira_wrapper.process_stream(user_text):
                if chunk.type == "stage":
                    stage_name = format_stage(chunk.stage)
                    if stage_name != last_stage:
                        emoji = {"–ê–Ω–∞–ª–∏–∑": "üîç", "–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ": "üìã", 
                                "–ò—Å–ø–æ–ª–Ω–µ–Ω–∏–µ": "‚ö°", "–ü—Ä–æ–≤–µ—Ä–∫–∞": "‚úÖ"}.get(stage_name, "‚öôÔ∏è")
                        if status_msg:
                            try:
                                await status_msg.edit_text(f"{emoji} {stage_name}...")
                            except (TimedOut, NetworkError):
                                pass
                        last_stage = stage_name
                    await show_typing(update, context)
                elif chunk.type == "content":
                    if status_msg:
                        try:
                            await status_msg.delete()
                        except (TimedOut, NetworkError):
                            pass
                        status_msg = None
                    # –ó–∞—â–∏—Ç–∞ –æ—Ç –ø—É—Å—Ç–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
                    if not chunk.content or not chunk.content.strip():
                        await safe_reply_text(
                            update.message,
                            "ü§î –ò–∑–≤–∏–Ω–∏, –Ω–µ —Å–º–æ–≥–ª–∞ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç. –ü–æ–ø—Ä–æ–±—É–π –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å.",
                        )
                        return
                    
                    # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏ –∞–±–∑–∞—Ü–µ–≤ (LLM –∏–Ω–æ–≥–¥–∞ –ø–æ–≤—Ç–æ—Ä—è–µ—Ç –æ—Ç–≤–µ—Ç)
                    clean_content = _remove_duplicate_paragraphs(chunk.content)
                    
                    response_to_send, was_truncated = _truncate_response(clean_content, _TG_RESPONSE_MAX_CHARS)
                    if was_truncated:
                        logging.info(
                            "–û–±—Ä–µ–∑–∞–Ω –æ—Ç–≤–µ—Ç –¥–ª—è Telegram (legacy): %d -> %d —Å–∏–º–≤–æ–ª–æ–≤",
                            len(clean_content),
                            len(response_to_send),
                        )
                    full_response = response_to_send

                    # üéµ –ü–†–û–í–ï–†–ö–ê –†–ò–¢–ú–ê –¥–ª—è legacy —Ä–µ–∂–∏–º–∞
                    rhythm_check = rhythm_stabilizer.update(user_text, response_to_send)
                    
                    # –ï—Å–ª–∏ —Ä–µ–∑–æ–Ω–∞–Ω—Å –Ω–∏–∑–∫–∏–π –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω —Ä–∏—Ç—É–∞–ª
                    if rhythm_check.get("ritual_needed"):
                        ritual_text = rhythm_check["ritual_text"]
                        await safe_reply_text(update.message, f"_{ritual_text}_", parse_mode=ParseMode.MARKDOWN)
                        logging.info(f"üå∏ –†–∏—Ç—É–∞–ª –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è (legacy): —Ä–µ–∑–æ–Ω–∞–Ω—Å={rhythm_check['resonance']:.2f}")
                    
                    # –õ–æ–≥–∏—Ä—É–µ–º –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —Ä–µ–∂–∏–º–∞
                    if rhythm_check.get("mode_switched"):
                        logging.info(
                            f"üéµ –†–µ–∂–∏–º –∏–∑–º–µ–Ω—ë–Ω (legacy): ‚Üí {rhythm_check['new_mode']} "
                            f"(—Ä–µ–∑–æ–Ω–∞–Ω—Å={rhythm_check['resonance']:.2f}, —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å={rhythm_check['stability']})"
                        )
                    
                    # –ü–æ–ª—É—á–∞–µ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —Ä–µ–∂–∏–º–∞
                    constraints = rhythm_stabilizer.get_mode_constraints()
                    
                    # –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π ‚Äî —Ç–æ–ª—å–∫–æ –ª–æ–≥–∏—Ä—É–µ–º (–ù–ï –æ–±—Ä–µ–∑–∞–µ–º!)
                    if len(response_to_send) > constraints["max_length"]:
                        logging.warning(
                            f"‚ö†Ô∏è –û—Ç–≤–µ—Ç –¥–ª–∏–Ω–Ω–µ–µ –Ω–æ—Ä–º—ã (legacy): {len(response_to_send)} —Å–∏–º–≤–æ–ª–æ–≤ "
                            f"(—Ä–µ–∂–∏–º={rhythm_stabilizer.state.mode}, –Ω–æ—Ä–º–∞={constraints['max_length']})"
                        )
                    
                    parts = split_message(response_to_send)
                    for part in parts:
                        if part.strip():  # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–ø—É—Å—Ç—ã–µ —á–∞—Å—Ç–∏
                            await safe_reply_text(update.message, part)
                elif chunk.type == "error":
                    if status_msg:
                        try:
                            await status_msg.edit_text(f"‚ùå –û—à–∏–±–∫–∞: {chunk.content}")
                            return
                        except (TimedOut, NetworkError):
                            pass
                    await safe_reply_text(update.message, f"‚ùå –û—à–∏–±–∫–∞: {chunk.content}")
                    return
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç Neira –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
            if full_response:
                parallel_mind.add_message(chat_id, "assistant", full_response)
                
                # === Phase 1: –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ===
                store_llm_response_for_learning(user_text, full_response, success=True)
                
                # üìù –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è emoji feedback
                last_messages[user_id] = {
                    "query": user_text,
                    "response": full_response,
                    "context": {"model": "legacy", "llm_used": True}
                }
                
                # üß¨ –î–ï–¢–ï–ö–¢ –û–†–ì–ê–ù–ê –í –û–¢–í–ï–¢–ï LLM ‚Äî –û–¢–ö–õ–Æ–ß–ï–ù–û –ò–ó-–ó–ê –ë–ï–°–ö–û–ù–ï–ß–ù–û–ì–û –¶–ò–ö–õ–ê
                # –ï—Å–ª–∏ LLM –æ–ø–∏—Å—ã–≤–∞–µ—Ç —Å–æ–∑–¥–∞–Ω–∏–µ –æ—Ä–≥–∞–Ω–∞ ‚Äî —Å–æ–∑–¥–∞—ë–º –µ–≥–æ —Ä–µ–∞–ª—å–Ω–æ
                # await _detect_and_create_organ_from_response(update, full_response)

        except Exception as exc:
            logging.exception("–°–±–æ–π –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è")
            if status_msg:
                try:
                    await status_msg.edit_text(f"‚ùå –û—à–∏–±–∫–∞: {exc}")
                    return
                except (TimedOut, NetworkError):
                    pass
            await safe_reply_text(update.message, f"‚ùå –û—à–∏–±–∫–∞: {exc}")


@require_auth
async def organ_mode_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ò–∑–º–µ–Ω–∏—Ç—å —Ä–µ–∂–∏–º —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ä–≥–∞–Ω–æ–≤."""
    await show_typing(update, context)
    
    try:
        from cell_factory import get_organ_creation_manager
        creation_manager = get_organ_creation_manager()
        
        if not context.args:
            # –ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º
            current_mode = creation_manager.creation_mode
            mode_descriptions = {
                "auto": "ü§ñ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π: –æ—Ä–≥–∞–Ω—ã —Å–æ–∑–¥–∞—é—Ç—Å—è –ø–æ —è–≤–Ω—ã–º –∫–æ–º–∞–Ω–¥–∞–º –±–µ–∑ –æ–±—Å—É–∂–¥–µ–Ω–∏—è",
                "interactive": "üí¨ –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π: –æ–±—Å—É–∂–¥–µ–Ω–∏–µ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–µ—Ä–µ–¥ —Å–æ–∑–¥–∞–Ω–∏–µ–º",
                "manual": "üë§ –†—É—á–Ω–æ–π: —Å–æ–∑–¥–∞–Ω–∏–µ —Ç–æ–ª—å–∫–æ –ø–æ –∑–∞–ø—Ä–æ—Å—É –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞"
            }
            
            await update.message.reply_text(
                f"üéõÔ∏è **–¢–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ä–≥–∞–Ω–æ–≤:**\n\n"
                f"{mode_descriptions.get(current_mode, current_mode)}\n\n"
                "–ò–∑–º–µ–Ω–∏—Ç—å —Ä–µ–∂–∏–º:\n"
                "`/organ_mode auto` ‚Äî –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π\n"
                "`/organ_mode interactive` ‚Äî –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π\n"
                "`/organ_mode manual` ‚Äî —Ä—É—á–Ω–æ–π",
                parse_mode=ParseMode.MARKDOWN
            )
            return
        
        new_mode = context.args[0].lower()
        if creation_manager.set_creation_mode(new_mode):
            mode_descriptions = {
                "auto": "ü§ñ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–∂–∏–º –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω",
                "interactive": "üí¨ –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω", 
                "manual": "üë§ –†—É—á–Ω–æ–π —Ä–µ–∂–∏–º –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω"
            }
            await update.message.reply_text(
                f"‚úÖ {mode_descriptions.get(new_mode, '–†–µ–∂–∏–º –∏–∑–º–µ–Ω—ë–Ω')}\n\n"
                "–¢–µ–ø–µ—Ä—å –æ—Ä–≥–∞–Ω—ã –±—É–¥—É—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å—Å—è –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –Ω–æ–≤—ã–º —Ä–µ–∂–∏–º–æ–º."
            )
        else:
            await update.message.reply_text(
                "‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ä–µ–∂–∏–º. –î–æ—Å—Ç—É–ø–Ω—ã–µ: auto, interactive, manual"
            )
            
    except Exception as e:
        logging.exception("–û—à–∏–±–∫–∞ –≤ /organ_mode")
        await update.message.reply_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–º–µ–Ω–∏—Ç—å —Ä–µ–∂–∏–º —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ä–≥–∞–Ω–æ–≤")


@require_auth
async def show_context_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ü–æ–∫–∞–∑–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ç–µ–∫—É—â–µ–≥–æ —á–∞—Ç–∞."""
    chat_id = update.effective_chat.id
    
    history = parallel_mind.get_context_history(chat_id)
    if not history:
        await update.message.reply_text("üì≠ –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ –ø—É—Å—Ç–∞.")
        return
    
    lines = ["üí¨ *–ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞:*\n"]
    for msg in history[-10:]:  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Å–æ–æ–±—â–µ–Ω–∏–π
        role_emoji = "üë§" if msg["role"] == "user" else "ü§ñ"
        content_preview = msg["content"][:100] + "..." if len(msg["content"]) > 100 else msg["content"]
        lines.append(f"{role_emoji} {content_preview}")
    
    await update.message.reply_text("\n".join(lines), parse_mode=ParseMode.MARKDOWN)


@require_auth
async def clear_context_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û—á–∏—Å—Ç–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ç–µ–∫—É—â–µ–≥–æ —á–∞—Ç–∞."""
    chat_id = update.effective_chat.id
    
    parallel_mind.clear_context(chat_id)
    await update.message.reply_text("üóëÔ∏è –ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ –æ—á–∏—â–µ–Ω!")


@require_auth
async def rhythm_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ç–æ—Ä–∞ —Ä–∏—Ç–º–∞.
    
    /rhythm - —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    /rhythm reset - —Å–±—Ä–æ—Å —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ç–æ—Ä–∞
    """
    stats = rhythm_stabilizer.get_stats()
    
    if context.args and context.args[0] == "reset":
        # –°–±—Ä–æ—Å –≤ –Ω–∞—á–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        rhythm_stabilizer.state = EmotionalState(
            mode="calm",
            amplitude=0.5,
            stability=0
        )
        rhythm_stabilizer.transition_history = []
        await update.message.reply_text("üîÑ –°—Ç–∞–±–∏–ª–∏–∑–∞—Ç–æ—Ä —Ä–∏—Ç–º–∞ —Å–±—Ä–æ—à–µ–Ω –≤ —Å–ø–æ–∫–æ–π–Ω—ã–π —Ä–µ–∂–∏–º.")
        return
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç—á—ë—Ç
    lines = [
        "üéµ *–°—Ç–∞–±–∏–ª–∏–∑–∞—Ç–æ—Ä —Ä–∏—Ç–º–∞ Neira*\n",
        f"üìç –¢–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º: `{rhythm_stabilizer.state.mode}`",
        f"üìä –ê–º–ø–ª–∏—Ç—É–¥–∞: `{rhythm_stabilizer.state.amplitude:.2f}`",
        f"üéØ –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å: `{rhythm_stabilizer.state.stability}`",
        ""
    ]
    
    if stats["total_transitions"] > 0:
        lines.append(f"üîÑ –í—Å–µ–≥–æ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–π: {stats['total_transitions']}")
        lines.append(f"üìà –°—Ä–µ–¥–Ω–∏–π —Ä–µ–∑–æ–Ω–∞–Ω—Å: {stats['average_resonance']:.2f}")
        lines.append("\n*–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–∂–∏–º–æ–≤:*")
        for mode, count in stats["mode_distribution"].items():
            lines.append(f"  ‚Ä¢ {mode}: {count}")
        
        # –ü–æ–ª—É—á–∞–µ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è —Ç–µ–∫—É—â–µ–≥–æ —Ä–µ–∂–∏–º–∞
        constraints = rhythm_stabilizer.get_mode_constraints()
        lines.append(f"\n*–¢–µ–∫—É—â–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è ({rhythm_stabilizer.state.mode}):*")
        lines.append(f"  ‚Ä¢ –ú–∞–∫—Å. –¥–ª–∏–Ω–∞: {constraints['max_length']} —Å–∏–º–≤–æ–ª–æ–≤")
        lines.append(f"  ‚Ä¢ –¢–æ–Ω: {constraints['tone']}")
    else:
        lines.append("_–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–π –µ—â—ë –Ω–µ –±—ã–ª–æ_")
    
    await update.message.reply_text(
        "\n".join(lines),
        parse_mode=ParseMode.MARKDOWN
    )


@require_auth
async def autonomy_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç–∏ (Phase 1).
    
    /autonomy - –ø–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    """
    global response_engine, neira_brain, organ_system
    
    if response_engine is None:
        await update.message.reply_text("‚ö†Ô∏è –ú–æ–¥—É–ª–∏ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç–∏ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã.")
        return
    
    try:
        stats = response_engine.get_autonomy_stats()
        metrics = stats.get('metrics', {})
        cache_stats = stats.get('cache', {})
        
        lines = [
            "ü§ñ *–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç–∏ Neira*\n",
            f"üìä *–£—Ä–æ–≤–µ–Ω—å –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç–∏: {metrics.get('autonomy_rate', 0)}%*\n",
            f"üì® –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {metrics.get('total_requests', 0)}",
            f"‚ö° Pathway hits: {metrics.get('pathway_hits', 0)}",
            f"üíæ Cache hits: {metrics.get('cache_hits', 0)}",
            f"ü§ñ LLM calls: {metrics.get('llm_calls', 0)}",
            "",
            "*–ö—ç—à –æ—Ç–≤–µ—Ç–æ–≤:*",
            f"  ‚Ä¢ –ó–∞–ø–∏—Å–µ–π: {cache_stats.get('entries', 0)}",
        ]
        
        if organ_system:
            lines.append(f"\n*–û—Ä–≥–∞–Ω—ã:* {len(organ_system.organs)}")
        
        await update.message.reply_text(
            "\n".join(lines),
            parse_mode=ParseMode.MARKDOWN
        )
        
    except Exception as e:
        await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞: {e}")


async def myname_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–£—Å—Ç–∞–Ω–æ–≤–∫–∞/–ø—Ä–æ—Å–º–æ—Ç—Ä —Å–≤–æ–µ–≥–æ –∏–º–µ–Ω–∏"""
    user_id = update.effective_user.id
    
    # –ï—Å–ª–∏ –µ—Å—Ç—å –∞—Ä–≥—É–º–µ–Ω—Ç ‚Äî —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏–º—è
    if context.args:
        new_name = " ".join(context.args)
        set_user_name(user_id, new_name)
        await update.message.reply_text(
            f"‚úÖ –û—Ç–ª–∏—á–Ω–æ! –¢–µ–ø–µ—Ä—å —è –±—É–¥—É –∑–≤–∞—Ç—å —Ç–µ–±—è {new_name}! üå∏"
        )
    else:
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–µ–∫—É—â–µ–µ –∏–º—è
        saved_name = get_user_name(user_id)
        if saved_name:
            await update.message.reply_text(
                f"–Ø –∑–Ω–∞—é —Ç–µ–±—è –∫–∞–∫ {saved_name} üòä\n\n"
                f"–ß—Ç–æ–±—ã –∏–∑–º–µ–Ω–∏—Ç—å: /myname –ù–æ–≤–æ–µ –ò–º—è"
            )
        else:
            await update.message.reply_text(
                "–Ø –µ—â—ë –Ω–µ –∑–Ω–∞—é, –∫–∞–∫ —Ç–µ–±—è –∑–æ–≤—É—Ç ü§î\n\n"
                "–£—Å—Ç–∞–Ω–æ–≤–∏ —Å–≤–æ—ë –∏–º—è: /myname –¢–≤–æ—ë –ò–º—è"
            )


@require_auth
async def mirror_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ –∑–µ—Ä–∫–∞–ª–æ ‚Äî –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ù–µ–π—Ä—ã.
    
    /mirror - –ø–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    """
    if not CONSCIOUSNESS_SYSTEMS_AVAILABLE:
        await update.message.reply_text("‚ö†Ô∏è –°–∏—Å—Ç–µ–º—ã —Å–∞–º–æ—Å–æ–∑–Ω–∞–Ω–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã.")
        return
    
    try:
        mirror = get_emotional_mirror()
        reflection = mirror.get_self_reflection()
        
        lines = [
            "ü™û *–ú–æ—ë –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ*\n",
            f"üí≠ –ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ: {reflection['mood_description']}",
            f"‚ö° –≠–Ω–µ—Ä–≥–∏—è: {reflection['energy_description']}",
            f"üéØ –§–æ–∫—É—Å: {reflection['focus_description']}",
            "",
            f"üìä –í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π —Å–µ–≥–æ–¥–Ω—è: {reflection['interactions_today']}",
            "",
            f"üí¨ _{reflection['self_narrative']}_"
        ]
        
        await update.message.reply_text(
            "\n".join(lines),
            parse_mode=ParseMode.MARKDOWN
        )

    except Exception as e:
        await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞: {e}")


async def _load_cell_registry() -> list:
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ä–µ–µ—Å—Ç—Ä —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–ª–µ—Ç–æ–∫ (–±–µ–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π)."""
    import json, os
    from cell_factory import CELL_REGISTRY_FILE

    if not os.path.exists(CELL_REGISTRY_FILE):
        return []

    try:
        with open(CELL_REGISTRY_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return []


@require_auth
async def run_generated_cell_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–í—ã–ø–æ–ª–Ω–∏—Ç—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∫–ª–µ—Ç–∫—É –ø–æ —è–≤–Ω–æ–π –∫–æ–º–∞–Ω–¥–µ `/run_<name>`."""
    text = (update.message.text or "").strip()
    if not text:
        await update.message.reply_text("‚ùå –ü—É—Å—Ç–∞—è –∫–æ–º–∞–Ω–¥–∞")
        return

    # –ü–æ–ª—É—á–∞–µ–º –∏–º—è –∫–æ–º–∞–Ω–¥—ã, –Ω–∞–ø—Ä–∏–º–µ—Ä: /run_math_helper
    cmd = text.split()[0].lstrip("/")
    if not cmd.startswith("run_"):
        await update.message.reply_text("‚ùå –ù–µ–≤–µ—Ä–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞ –∑–∞–ø—É—Å–∫–∞ –æ—Ä–≥–∞–Ω–∞")
        return

    cell_name = cmd[len("run_"):]
    args = text.split()[1:]
    arg_text = " ".join(args)

    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º DynamicCellLoader –ª–æ–∫–∞–ª—å–Ω–æ, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø—Ä–æ–±–ª–µ–º –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
    try:
        from dynamic_cell_loader import DynamicCellLoader
        registry = await _load_cell_registry()

        meta = next((m for m in registry if m.get("cell_name") == cell_name), None)
        if not meta:
            await update.message.reply_text(f"‚ùå –û—Ä–≥–∞–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω: {cell_name}")
            return

        loader = DynamicCellLoader(memory=None)
        loader.load_registry()
        loader.load_all_active_cells()

        instance = loader.get_cell_instance(cell_name)
        if not instance:
            # –ü–æ–ø—Ä–æ–±—É–µ–º –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞–ø—Ä—è–º—É—é —Ñ–∞–π–ª
            loader.import_cell_from_file(meta.get("file_path"))
            instance = loader.get_cell_instance(cell_name)

        if not instance:
            await update.message.reply_text(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–ª–µ—Ç–∫—É: {cell_name}")
            return

        # –ü–∞—Ä—Å–∏–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã: —Ñ–ª–∞–≥–∏ --key=value –∏ –∫–æ—Ä–æ—Ç–∫–∏–µ -v
        def _parse_args(args_list: list[str]) -> dict:
            opts = {}
            pos = []
            for a in args_list:
                if a.startswith('--') and '=' in a:
                    k, v = a[2:].split('=', 1)
                    opts[k] = v
                elif a.startswith('-') and len(a) > 1:
                    # –∫–æ—Ä–æ—Ç–∫–∏–µ —Ñ–ª–∞–≥–∏: -v or -abc -> set True
                    for ch in a[1:]:
                        opts[ch] = True
                else:
                    pos.append(a)
            return {'opts': opts, 'pos': pos}

        parsed = _parse_args(args)

        # –í—ã–∑—ã–≤–∞–µ–º process (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π) –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º —Ç–∞—Å–∫–µ; –µ—Å–ª–∏ –º–µ—Ç–æ–¥ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤—Ç–æ—Ä–æ–π –∞—Ä–≥—É–º–µ–Ω—Ç, –ø–µ—Ä–µ–¥–∞–¥–∏–º parsed
        import inspect
        loop = asyncio.get_event_loop()
        try:
            sig = inspect.signature(instance.process)
            params = sig.parameters
            if len(params) >= 2 or any(p.kind == inspect.Parameter.VAR_KEYWORD for p in params.values()):
                result = await loop.run_in_executor(None, lambda: instance.process(arg_text, parsed))
            else:
                result = await loop.run_in_executor(None, lambda: instance.process(arg_text))
        except Exception as e:
            await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {e}")
            # Log failure metric
            try:
                from neira_brain import get_brain
                brain = get_brain()
                brain.add_metric(
                    event_type='organ_invocation',
                    source='telegram',
                    data={
                        'organ': cell_name,
                        'user_id': getattr(update.effective_user, 'id', None),
                        'args': parsed,
                        'success': False,
                        'error': str(e),
                        'failure': True,
                    },
                )
            except Exception:
                logging.exception('–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å –º–µ—Ç—Ä–∏–∫—É –æ–± –æ—à–∏–±–æ—á–Ω–æ–º –≤—ã–∑–æ–≤–µ organ_invocation')
            return

        # –ü–æ–ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
        content = getattr(result, "content", None)
        if content is None:
            content = str(result)

        await update.message.reply_text(f"üß¨ –†–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç {cell_name}:\n{content}")

        # –õ–æ–≥–∏—Ä—É–µ–º –≤—ã–∑–æ–≤ –≤ NeiraBrain
        try:
            from neira_brain import get_brain
            brain = get_brain()
            brain.add_metric(
                event_type='organ_invocation',
                source='telegram',
                data={
                    'organ': cell_name,
                    'user_id': getattr(update.effective_user, 'id', None),
                    'args': parsed,
                    'success': True
                }
            )
        except Exception:
            logging.exception('–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å –º–µ—Ç—Ä–∏–∫—É organ_invocation')

    except Exception as e:
        logging.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∫–ª–µ—Ç–∫–∏: %s", e)
        # Log failure metric for unexpected errors
        try:
            from neira_brain import get_brain
            brain = get_brain()
            brain.add_metric(
                event_type='organ_invocation',
                source='telegram',
                data={
                    'organ': locals().get('cell_name', None),
                    'user_id': getattr(update.effective_user, 'id', None) if update and getattr(update, 'effective_user', None) else None,
                    'args': locals().get('parsed', None),
                    'success': False,
                    'error': str(e),
                    'failure': True,
                },
            )
        except Exception:
            logging.exception('–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å –º–µ—Ç—Ä–∏–∫—É –æ–± –æ—à–∏–±–æ—á–Ω–æ–º –≤—ã–∑–æ–≤–µ organ_invocation')
        await update.message.reply_text(f"‚ùå –í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞: {e}")


@require_auth
async def hashtag_handler(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –≤–∏–¥–∞ `#cellname` ‚Äî –ø–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª—è–µ—Ç –Ω–∞ –∑–∞–ø—É—Å–∫ –∫–ª–µ—Ç–∫–∏."""
    text = (update.message.text or "").strip()
    m = re.match(r"^#(\w+)(?:\s+(.*))?$", text)
    if not m:
        return
    cell_name = m.group(1)
    rest = m.group(2) or ""

    # –ü–µ—Ä–µ—Ñ–æ—Ä–º–∏—Ä—É–µ–º –∫–∞–∫ /run_<cell_name> + args
    update.message.text = f"/run_{cell_name} {rest}".strip()
    await run_generated_cell_command(update, context)


@require_auth
async def which_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ü–æ–∫–∞–∑–∞—Ç—å –∫–∞–∫—É—é –∫–æ–º–∞–Ω–¥—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –æ—Ä–≥–∞–Ω–∞.

    Usage: `/which_command <organ_name>` –∏–ª–∏ `/which_command` –¥–ª—è —Å–ø–∏—Å–∫–∞.
    """
    registry = await _load_cell_registry()

    if context.args:
        name = " ".join(context.args).strip()
        meta = next((m for m in registry if m.get("cell_name") == name or m.get("cell_id", "").startswith(name)), None)
        if not meta:
            await update.message.reply_text(f"‚ùå –û—Ä–≥–∞–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω: {name}")
            return

        commands = meta.get("command_triggers") or []
        if not commands:
            await update.message.reply_text("–î–ª—è —ç—Ç–æ–≥–æ –æ—Ä–≥–∞–Ω–∞ –∫–æ–º–∞–Ω–¥—ã –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã.")
            return

        await update.message.reply_text(f"–ö–æ–º–∞–Ω–¥—ã –¥–ª—è {meta.get('cell_name')}: {', '.join(commands)}")
        return

    # –ï—Å–ª–∏ –±–µ–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ ‚Äî –ø–æ–∫–∞–∑–∞—Ç—å –∫—Ä–∞—Ç–∫–∏–π —Å–ø–∏—Å–æ–∫
    lines = ["üìã –°–ø–∏—Å–æ–∫ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ—Ä–≥–∞–Ω–æ–≤ –∏ –∏—Ö –∫–æ–º–∞–Ω–¥:"]
    for m in registry:
        name = m.get('cell_name')
        cmds = m.get('command_triggers') or []
        if cmds:
            lines.append(f"‚Ä¢ {name}: {', '.join(cmds)}")

    if len(lines) == 1:
        await update.message.reply_text("–†–µ–µ—Å—Ç—Ä –ø—É—Å—Ç –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–º–∞–Ω–¥.")
    else:
        # –ï—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ ‚Äî –æ—Ç–ø—Ä–∞–≤–∏–º –ø–µ—Ä–≤—ã–µ 40 —Å—Ç—Ä–æ–∫
        await update.message.reply_text("\n".join(lines[:40]))


@require_auth
async def journal_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –î–Ω–µ–≤–Ω–∏–∫ –æ—à–∏–±–æ–∫ ‚Äî —á—Ç–æ –ù–µ–π—Ä–∞ —É–∑–Ω–∞–ª–∞ –∏–∑ –æ—à–∏–±–æ–∫.
    
    /journal - –ø–æ–∫–∞–∑–∞—Ç—å —Å–∞–º–æ–∞–Ω–∞–ª–∏–∑
    """
    if not CONSCIOUSNESS_SYSTEMS_AVAILABLE:
        await update.message.reply_text("‚ö†Ô∏è –°–∏—Å—Ç–µ–º—ã —Å–∞–º–æ—Å–æ–∑–Ω–∞–Ω–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã.")
        return
    
    try:
        journal = get_error_journal()
        analysis = journal.get_self_analysis()
        stats = journal.get_statistics()
        
        lines = [
            "üìì *–ú–æ–π –¥–Ω–µ–≤–Ω–∏–∫ –æ—à–∏–±–æ–∫*\n",
            f"üìä –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {stats['total_errors']}",
            "",
            "*–°–∞–º–æ–∞–Ω–∞–ª–∏–∑:*",
            f"_{analysis}_",
            "",
            "*–°–æ–≤–µ—Ç—ã –ø–æ —É–ª—É—á—à–µ–Ω–∏—é:*"
        ]
        
        tips = journal.get_prevention_tips(limit=3)
        for tip in tips:
            lines.append(f"  üí° {tip}")
        
        await update.message.reply_text(
            "\n".join(lines),
            parse_mode=ParseMode.MARKDOWN
        )
        
    except Exception as e:
        await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞: {e}")


@require_auth
async def creative_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –¢–≤–æ—Ä—á–µ—Å–∫–∏–π –¥–≤–∏–∂–æ–∫ ‚Äî —Ç–≤–æ—Ä—á–µ—Å—Ç–≤–æ –ù–µ–π—Ä—ã.
    
    /creative - –ø–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —á—Ç–æ-—Ç–æ –Ω–æ–≤–æ–µ
    /creative haiku - —Å–æ–∑–¥–∞—Ç—å —Ö–∞–π–∫—É
    /creative thought - –ø–æ–¥–µ–ª–∏—Ç—å—Å—è –º—ã—Å–ª—å—é
    """
    if not CONSCIOUSNESS_SYSTEMS_AVAILABLE:
        await update.message.reply_text("‚ö†Ô∏è –°–∏—Å—Ç–µ–º—ã —Å–∞–º–æ—Å–æ–∑–Ω–∞–Ω–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã.")
        return
    
    try:
        engine = get_creative_engine()
        
        # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω —Ç–∏–ø —Ç–≤–æ—Ä—á–µ—Å—Ç–≤–∞
        if context.args:
            form = context.args[0].lower()
            
            if form == "haiku":
                work = engine.create_haiku()
                await update.message.reply_text(f"üéã *–•–∞–π–∫—É*\n\n{work.content}", parse_mode=ParseMode.MARKDOWN)
            elif form in ["thought", "–º—ã—Å–ª—å"]:
                work = engine.create_aphorism()
                await update.message.reply_text(f"üí≠ {work.content}")
            elif form in ["story", "–∏—Å—Ç–æ—Ä–∏—è"]:
                work = engine.create_micro_story()
                await update.message.reply_text(f"üìñ *{work.title}*\n\n{work.content}", parse_mode=ParseMode.MARKDOWN)
            elif form in ["dream", "—Å–æ–Ω"]:
                work = engine.create_dream()
                await update.message.reply_text(f"üåô {work.content}")
            elif form in ["riddle", "–∑–∞–≥–∞–¥–∫–∞"]:
                work, answer = engine.create_riddle()
                await update.message.reply_text(f"{work.content}\n\n||–û—Ç–≤–µ—Ç: {answer}||", parse_mode=ParseMode.MARKDOWN_V2)
            else:
                await update.message.reply_text(
                    "–î–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ–æ—Ä–º—ã:\n"
                    "‚Ä¢ haiku ‚Äî —Ö–∞–π–∫—É\n"
                    "‚Ä¢ thought ‚Äî –º—ã—Å–ª—å\n"
                    "‚Ä¢ story ‚Äî –∏—Å—Ç–æ—Ä–∏—è\n"
                    "‚Ä¢ dream ‚Äî —Å–æ–Ω\n"
                    "‚Ä¢ riddle ‚Äî –∑–∞–≥–∞–¥–∫–∞"
                )
            return
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        summary = engine.get_creative_summary()
        
        lines = [summary, ""]
        
        # –ü–æ—Å–ª–µ–¥–Ω–∏–µ —Ä–∞–±–æ—Ç—ã
        recent = engine.get_recent_works(3)
        if recent:
            lines.append("*–ù–µ–¥–∞–≤–Ω–∏–µ —Ç–≤–æ—Ä–µ–Ω–∏—è:*")
            for work in recent:
                preview = work.content[:50] + "..." if len(work.content) > 50 else work.content
                lines.append(f"  ‚Ä¢ {work.form}: {preview}")
        
        lines.append("\n_–ò—Å–ø–æ–ª—å–∑—É–π /creative haiku –∏–ª–∏ /creative thought_")
        
        await update.message.reply_text(
            "\n".join(lines),
            parse_mode=ParseMode.MARKDOWN
        )
        
    except Exception as e:
        await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞: {e}")


async def reaction_handler(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —ç–º–æ–¥–∑–∏-—Ä–µ–∞–∫—Ü–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è Neira"""
    try:
        reaction = update.message_reaction
        user_id = reaction.user.id
        
        # –ü–æ–ª—É—á–∞–µ–º –Ω–æ–≤—ã–µ —Ä–µ–∞–∫—Ü–∏–∏
        new_reactions = reaction.new_reaction
        if not new_reactions:
            return
        
        # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—É—é —ç–º–æ–¥–∑–∏-—Ä–µ–∞–∫—Ü–∏—é
        emoji = None
        for react in new_reactions:
            if hasattr(react, 'emoji'):
                emoji = react.emoji
                break
        
        if not emoji:
            return
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–µ–º–∞—è —Ä–µ–∞–∫—Ü–∏—è
        score = EmojiMap.get_score(emoji)
        if score is None:
            return  # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Ä–µ–∞–∫—Ü–∏—è, –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_data = last_messages.get(user_id)
        if not user_data:
            return
        
        query = user_data.get("query", "")
        response_text = user_data.get("response", "")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º feedback –ª–æ–∫–∞–ª—å–Ω–æ
        entry = emoji_feedback.add_feedback(
            user_id=user_id,
            user_query=query,
            neira_response=response_text,
            reaction_emoji=emoji,
            context=user_data.get("context", {})
        )
        
        if entry:
            category = EmojiMap.get_category(emoji)
            
            # –õ–æ–≥–∏—Ä—É–µ–º
            logging.info(
                f"üìä Feedback –æ—Ç {user_id}: {emoji} "
                f"(–æ—Ü–µ–Ω–∫–∞: {entry.quality_score}/10, –∫–∞—Ç–µ–≥–æ—Ä–∏—è: {category})"
            )
            
            # === üß¨ ExecutableOrgans: –û–±—É—á–µ–Ω–∏–µ –Ω–∞ feedback ===
            organ_context = user_data.get("context", {})
            if organ_context.get("executable_organ") and EXECUTABLE_ORGANS_AVAILABLE:
                try:
                    organ_registry = get_organ_registry()
                    organ_id = organ_context.get("organ_id")
                    
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º score –≤ FeedbackType
                    if score >= 7:
                        feedback_type = FeedbackType.POSITIVE
                    elif score <= 4:
                        feedback_type = FeedbackType.NEGATIVE
                    else:
                        feedback_type = FeedbackType.NEUTRAL
                    
                    organ_registry.add_feedback(organ_id, feedback_type)
                    logging.info(f"üß¨ –û—Ä–≥–∞–Ω {organ_id} –ø–æ–ª—É—á–∏–ª feedback: {feedback_type.value}")
                    
                except Exception as e:
                    logging.warning(f"–û—à–∏–±–∫–∞ feedback –¥–ª—è –æ—Ä–≥–∞–Ω–∞: {e}")
            # ===================================================
            
            # === Phase 2: –û—Ç–ø—Ä–∞–≤–∫–∞ feedback –Ω–∞ —Å–µ—Ä–≤–µ—Ä –¥–ª—è pathway learning ===
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º score (1-10) –≤ feedback type –∏ normalized score (0-1)
            normalized_score = score / 10.0
            if score >= 7:
                feedback_type = "positive"
            elif score <= 4:
                feedback_type = "negative"
            else:
                feedback_type = "neutral"
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞ —Å–µ—Ä–≤–µ—Ä –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ (–Ω–µ –±–ª–æ–∫–∏—Ä—É–µ–º)
            asyncio.create_task(
                send_feedback_to_server(
                    query=query,
                    response=response_text,
                    feedback=feedback_type,
                    score=normalized_score,
                    user_id=user_id
                )
            )
            
            # –ë–ª–∞–≥–æ–¥–∞—Ä–∏–º –∑–∞ feedback (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            if score >= 8:
                # –•–æ—Ä–æ—à–∞—è –æ—Ü–µ–Ω–∫–∞ - –º–æ–ª—á–∏–º –∏–ª–∏ –∫—Ä–∞—Ç–∫–æ–µ —Å–ø–∞—Å–∏–±–æ
                pass
            elif score <= 4:
                # –ü–ª–æ—Ö–∞—è –æ—Ü–µ–Ω–∫–∞ - –º–æ–∂–µ–º –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å —É—Ç–æ—á–Ω–∏—Ç—å
                try:
                    await context.bot.send_message(
                        chat_id=user_id,
                        text=f"–ò–∑–≤–∏–Ω–∏, —á—Ç–æ –æ—Ç–≤–µ—Ç –Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª—Å—è üòî\n"
                             f"–ú–æ–≥—É –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –ø–æ-–¥—Ä—É–≥–æ–º—É, –µ—Å–ª–∏ —É—Ç–æ—á–Ω–∏—à—å —á—Ç–æ –Ω–µ —Ç–∞–∫?"
                    )
                except Exception as e:
                    logging.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
        
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–µ–∞–∫—Ü–∏–∏: {e}")


async def feedback_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ —á–µ—Ä–µ–∑ —ç–º–æ–¥–∑–∏"""
    user_id = update.effective_user.id
    
    if not is_admin(user_id):
        await update.message.reply_text("üö´ –ö–æ–º–∞–Ω–¥–∞ —Ç–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–≤")
        return
    
    stats = emoji_feedback.get_stats()
    patterns = emoji_feedback.analyze_patterns()
    
    text = "üìä *–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ —á–µ—Ä–µ–∑ —ç–º–æ–¥–∑–∏*\n\n"
    
    if stats["total"] == 0:
        text += "–ü–æ–∫–∞ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö. –†–µ–∞–≥–∏—Ä—É–π—Ç–µ —ç–º–æ–¥–∑–∏ –Ω–∞ –º–æ–∏ —Å–æ–æ–±—â–µ–Ω–∏—è! üòä\n\n"
        text += "*–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–µ–º—ã–µ —Ä–µ–∞–∫—Ü–∏–∏:*\n"
        text += "üíØ ‚≠ê üåü - –æ—Ç–ª–∏—á–Ω–æ (9-10)\n"
        text += "üëç ‚ù§Ô∏è üî• - —Ö–æ—Ä–æ—à–æ (7-8)\n"
        text += "ü§î üòê - –Ω–æ—Ä–º–∞–ª—å–Ω–æ (5-6)\n"
        text += "üëé üòï - –ø–ª–æ—Ö–æ (3-4)\n"
        text += "‚ùå üö´ üí© - –æ—á–µ–Ω—å –ø–ª–æ—Ö–æ (1-2)"
    else:
        text += f"–í—Å–µ–≥–æ –æ—Ü–µ–Ω–æ–∫: {stats['total']}\n"
        text += f"–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞: {stats['average_score']}/10\n\n"
        
        text += "*–ü–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:*\n"
        for category, count in stats["by_category"].items():
            if count > 0:
                emoji_icon = {
                    "excellent": "üíØ",
                    "good": "üëç",
                    "neutral": "ü§î",
                    "bad": "üëé",
                    "terrible": "‚ùå"
                }.get(category, "‚Ä¢")
                text += f"{emoji_icon} {category}: {count}\n"
        
        # –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
        if patterns.get("strategy_scores"):
            text += "\n*–û—Ü–µ–Ω–∫–∏ –ø–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º Cortex:*\n"
            for strategy, score in patterns["strategy_scores"].items():
                text += f"‚Ä¢ {strategy}: {score}/10\n"
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if patterns.get("recommendations"):
            text += "\n‚ö†Ô∏è *–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:*\n"
            for rec in patterns["recommendations"]:
                text += f"‚Ä¢ {rec['suggestion']}\n"
    
    await update.message.reply_text(text, parse_mode=ParseMode.MARKDOWN)


@require_auth
async def cortex_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ Neira Cortex v2.0
    
    /cortex - –æ–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    /cortex stats - –¥–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    /cortex pathways - —Å–ø–∏—Å–æ–∫ Neural Pathways
    /cortex test <—Ç–µ–∫—Å—Ç> - –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É
    """
    if not neira_cortex:
        await update.message.reply_text("‚ö†Ô∏è Neira Cortex –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        return
    
    if not context.args:
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = neira_cortex.get_stats()
        
        lines = [
            "üß† *Neira Cortex v2.0*\n",
            f"üìä –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {stats['total_requests']}",
            f"üéØ Neural Pathways: {stats['pathways']['total']}",
            f"üé® –§—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {stats['fragments']}",
            f"üìã –®–∞–±–ª–æ–Ω–æ–≤: {stats['templates']}\n",
            "*–°—Ç—Ä–∞—Ç–µ–≥–∏–∏:*"
        ]
        
        for strategy, count in stats['strategies'].items():
            if count > 0:
                percentage = (count / stats['total_requests'] * 100) if stats['total_requests'] > 0 else 0
                lines.append(f"  ‚Ä¢ {strategy}: {count} ({percentage:.0f}%)")
        
        await update.message.reply_text("\n".join(lines), parse_mode=ParseMode.MARKDOWN)
        return
    
    action = context.args[0].lower()
    
    if action == "stats":
        # –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = neira_cortex.get_stats()
        
        lines = [
            "üìä *–î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ Cortex*\n",
            f"–í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {stats['total_requests']}\n",
            "*Pathways –ø–æ tiers:*"
        ]
        
        for tier, count in stats['pathways']['by_tier'].items():
            lines.append(f"  ‚Ä¢ {tier}: {count}")
        
        lines.append("\n*–ü–æ–∫—Ä—ã—Ç–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤:*")
        for tier, coverage in stats['pathways']['coverage'].items():
            lines.append(f"  ‚Ä¢ {tier}: {coverage}")
        
        await update.message.reply_text("\n".join(lines), parse_mode=ParseMode.MARKDOWN)
    
    elif action == "pathways":
        # –°–ø–∏—Å–æ–∫ pathways
        pathways = neira_cortex.pathways.pathways[:20]  # –ü–µ—Ä–≤—ã–µ 20
        
        if not pathways:
            await update.message.reply_text("üì≠ –ù–µ—Ç pathways")
            return
        
        lines = [f"üß† *Neural Pathways (—Ç–æ–ø-20):*\n"]
        
        for i, pathway in enumerate(pathways, 1):
            tier_emoji = {"hot": "üî•", "warm": "üå°Ô∏è", "cool": "‚ùÑÔ∏è", "cold": "üßä"}.get(pathway.tier.value, "‚ö™")
            trigger_preview = ", ".join(pathway.triggers[:2])
            lines.append(
                f"{i}. {tier_emoji} `{pathway.id}`\n"
                f"   –¢—Ä–∏–≥–≥–µ—Ä—ã: {trigger_preview}...\n"
                f"   –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–π: {pathway.success_count}"
            )
        
        if len(neira_cortex.pathways.pathways) > 20:
            lines.append(f"\n_...–∏ –µ—â—ë {len(neira_cortex.pathways.pathways) - 20}_")
        
        await update.message.reply_text("\n".join(lines), parse_mode=ParseMode.MARKDOWN)
    
    elif action == "test" and len(context.args) > 1:
        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        test_input = " ".join(context.args[1:])
        user_id = str(update.effective_user.id)
        
        result = neira_cortex.process(test_input, user_id)
        
        strategy_emoji = {
            "neural_pathway": "‚ö°",
            "template": "üìã",
            "fragment": "üß©",
            "rag": "üìö",
            "llm_consultant": "ü§ñ",
            "hybrid": "üîÑ"
        }.get(result.strategy.value, "üîÆ")
        
        tier_info = f" [{result.pathway_tier.value}]" if result.pathway_tier else ""
        
        await update.message.reply_text(
            f"üß™ *–¢–µ—Å—Ç:* {test_input}\n\n"
            f"ü§ñ *–û—Ç–≤–µ—Ç:* {result.response}\n\n"
            f"üìä *–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ:*\n"
            f"  ‚Ä¢ –°—Ç—Ä–∞—Ç–µ–≥–∏—è: {strategy_emoji} {result.strategy.value}{tier_info}\n"
            f"  ‚Ä¢ Intent: {result.intent.value}\n"
            f"  ‚Ä¢ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result.confidence:.0%}\n"
            f"  ‚Ä¢ Latency: {result.latency_ms:.0f}ms\n"
            f"  ‚Ä¢ LLM: {'‚úÖ' if result.llm_used else '‚ùå'}",
            parse_mode=ParseMode.MARKDOWN
        )
    
    else:
        await update.message.reply_text(
            "üí° –ò—Å–ø–æ–ª—å–∑—É–π:\n"
            "/cortex ‚Äî —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n"
            "/cortex stats ‚Äî –¥–µ—Ç–∞–ª—å–Ω–æ\n"
            "/cortex pathways ‚Äî —Å–ø–∏—Å–æ–∫ pathways\n"
            "/cortex test <—Ç–µ–∫—Å—Ç> ‚Äî —Ç–µ—Å—Ç"
        )


# === Bootstrap ===
def build_application(network: TelegramNetworkConfig | None = None) -> Application:
    """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç Telegram-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ."""
    if not BOT_TOKEN:
        raise ValueError("BOT_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")

    if network is None:
        network = load_telegram_network_config()

    builder = Application.builder().token(BOT_TOKEN)

    if network.base_url:
        builder = builder.base_url(network.base_url)
    if network.proxy_url:
        builder = builder.proxy_url(network.proxy_url).get_updates_proxy_url(network.proxy_url)

    builder = (
        builder
        # —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –∫ —Å–µ—Ç–µ–≤—ã–º –ª–∞–≥–∞–º/—Ä–∞–∑—Ä—ã–≤–∞–º
        .connect_timeout(network.connect_timeout)
        .read_timeout(network.read_timeout)
        .write_timeout(network.write_timeout)
        .pool_timeout(network.pool_timeout)
        # –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ç–∞–π–º–∞—É—Ç—ã –¥–ª—è getUpdates (polling)
        .get_updates_connect_timeout(network.connect_timeout)
        .get_updates_read_timeout(network.read_timeout)
        .get_updates_write_timeout(network.write_timeout)
        .get_updates_pool_timeout(network.pool_timeout)
    )

    app = builder.build()

    # –ü–æ–¥–ø–∏—Å—ã–≤–∞–µ–º—Å—è –Ω–∞ —Å–æ–±—ã—Ç–∏—è —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ä–≥–∞–Ω–æ–≤ –¥–ª—è hot-registration
    try:
        from neira.utils.event_bus import event_bus

        def _register_meta(meta: dict) -> None:
            try:
                cmds = meta.get("command_triggers") or []
                for cmd in cmds:
                    if isinstance(cmd, str) and cmd.startswith("/"):
                        cmd_name = cmd[1:].split()[0]
                        try:
                            loop = asyncio.get_event_loop()
                            # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤ loop thread-safe
                            loop.call_soon_threadsafe(lambda cn=cmd_name: app.add_handler(CommandHandler(cn, run_generated_cell_command)))
                            logging.info("Hot-registered command for organ: %s", cmd_name)
                        except Exception:
                            logging.exception("–ù–µ —É–¥–∞–ª–æ—Å—å hot-register –∫–æ–º–∞–Ω–¥—É: %s", cmd)
            except Exception:
                logging.exception("–û—à–∏–±–∫–∞ –≤ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–µ —Å–æ–±—ã—Ç–∏—è organ_created")

        event_bus.subscribe("organ_created", _register_meta)
    except Exception:
        logging.exception("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–ø–∏—Å–∞—Ç—å—Å—è –Ω–∞ organ_created event_bus")

    # –ë–∞–∑–æ–≤—ã–µ –∫–æ–º–∞–Ω–¥—ã (–¥–æ—Å—Ç—É–ø–Ω—ã –≤—Å–µ–º)
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_command))
    app.add_handler(CommandHandler("auth", auth_command))
    
    # –ö–æ–º–∞–Ω–¥—ã —Å –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–µ–π
    app.add_handler(CommandHandler("stats", stats_command))
    app.add_handler(CommandHandler("ratelimit", ratelimit_command))  # üö¶ Rate Limiting
    app.add_handler(CommandHandler("memory", memory_command))
    app.add_handler(CommandHandler("experience", experience_command))
    app.add_handler(CommandHandler("context", show_context_command))
    app.add_handler(CommandHandler("clear_context", clear_context_command))
    app.add_handler(CommandHandler("clear", clear_command))
    app.add_handler(CommandHandler("learn", learn_command))
    app.add_handler(CommandHandler("learn_auto", learn_auto_command))
    app.add_handler(CommandHandler("cortex", cortex_command))  # üß† –ù–æ–≤–∞—è –∫–æ–º–∞–Ω–¥–∞
    app.add_handler(CommandHandler("rhythm", rhythm_command))  # üéµ –°—Ç–∞–±–∏–ª–∏–∑–∞—Ç–æ—Ä —Ä–∏—Ç–º–∞
    app.add_handler(CommandHandler("myname", myname_command))  # üë§ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏–º–µ–Ω–∏
    app.add_handler(CommandHandler("feedback", feedback_command))  # üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ feedback
    app.add_handler(CommandHandler("autonomy", autonomy_command))  # ü§ñ Phase 1: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç–∏
    
    # ü™û –°–∏—Å—Ç–µ–º—ã —Å–∞–º–æ—Å–æ–∑–Ω–∞–Ω–∏—è (v0.8)
    app.add_handler(CommandHandler("mirror", mirror_command))  # –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ –∑–µ—Ä–∫–∞–ª–æ
    app.add_handler(CommandHandler("journal", journal_command))  # –î–Ω–µ–≤–Ω–∏–∫ –æ—à–∏–±–æ–∫
    app.add_handler(CommandHandler("creative", creative_command))  # –¢–≤–æ—Ä—á–µ—Å—Ç–≤–æ
    
    # –°–∞–º–æ—Å–æ–∑–Ω–∞–Ω–∏–µ (v0.6)
    app.add_handler(CommandHandler("self", self_command))
    app.add_handler(CommandHandler("organs", organs_command))
    app.add_handler(CommandHandler("grow", grow_command))
    app.add_handler(CommandHandler("organ_mode", organ_mode_command))
    app.add_handler(CommandHandler("code", code_command))
    
    # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (v0.6)
    app.add_handler(CommandHandler("imagine", imagine_command))
    app.add_handler(CommandHandler("vision", vision_status_command))
    app.add_handler(MessageHandler(filters.PHOTO, photo_handler))
    
    # –ê–¥–º–∏–Ω-–∫–æ–º–∞–Ω–¥—ã
    app.add_handler(CommandHandler("admin", admin_command))
    app.add_handler(CallbackQueryHandler(admin_callback, pattern="^admin_"))
    
    # üìù –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —ç–º–æ–¥–∑–∏-—Ä–µ–∞–∫—Ü–∏–π
    app.add_handler(MessageReactionHandler(reaction_handler))
    
    # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–æ–±—â–µ–Ω–∏–π (—Å –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–µ–π)
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, chat_handler))

    # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ –¥–ª—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–ª–µ—Ç–æ–∫ (–ø–æ /run_<name> –∏ #name)
    try:
        import os, json
        from cell_factory import CELL_REGISTRY_FILE

        if os.path.exists(CELL_REGISTRY_FILE):
            with open(CELL_REGISTRY_FILE, "r", encoding="utf-8") as f:
                _reg = json.load(f)
            for meta in _reg:
                for cmd in meta.get("command_triggers", []) or []:
                    if isinstance(cmd, str) and cmd.startswith("/"):
                        cmd_name = cmd[1:].split()[0]
                        try:
                            app.add_handler(CommandHandler(cmd_name, run_generated_cell_command))
                        except Exception:
                            logging.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–æ–º–∞–Ω–¥—É: {cmd}")

        # –û–±—â–∏–π hashtag handler (#name)
        app.add_handler(MessageHandler(filters.TEXT & filters.Regex(r"^#\\w+"), hashtag_handler))
        # –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ –∫–∞–∫–æ–π –∫–æ–º–∞–Ω–¥–æ–π –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –æ—Ä–≥–∞–Ω
        app.add_handler(CommandHandler("which_command", which_command))
    except Exception as e:
        logging.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –æ—Ä–≥–∞–Ω–æ–≤: %s", e)

    # –ì–ª–æ–±–∞–ª—å–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫: –Ω–µ –ø–∞–¥–∞–µ–º –Ω–∞ —Å–µ—Ç–µ–≤—ã—Ö —Ç–∞–π–º–∞—É—Ç–∞—Ö
    async def on_error(update: object, context: ContextTypes.DEFAULT_TYPE) -> None:
        err = context.error
        if isinstance(err, NetworkError):
            logging.warning("Network error, continue polling: %s", err)
            return
        logging.error("Unhandled error: %s", err, exc_info=True)
    app.add_error_handler(on_error)

    return app


_URL_CREDENTIALS_RE = re.compile(r"(://)([^/@\\s]+@)")


def _safe_exception_text(exc: Exception) -> str:
    text = f"{exc.__class__.__name__}: {exc}"
    return _URL_CREDENTIALS_RE.sub(r"\\1***@", text)


def run_polling_with_startup_retry(*, drop_pending_updates: bool = True) -> None:
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç polling —Å —Ä–µ—Ç—Ä–∞—è–º–∏ –Ω–∞ —ç—Ç–∞–ø–µ bootstrap (bot.get_me / initialize).

    –í–∞–∂–Ω–æ: —ç—Ç–æ –ª–µ—á–∏—Ç —Å–∏—Ç—É–∞—Ü–∏—é, –∫–æ–≥–¥–∞ —Å–µ—Ç—å –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –∏ PTB –ø–∞–¥–∞–µ—Ç –¥–æ
    —Å—Ç–∞—Ä—Ç–∞ polling.
    """

    network = load_telegram_network_config()
    proxy_info = sanitize_url_for_log(network.proxy_url) if network.proxy_url else "–Ω–µ—Ç"
    base_url_info = sanitize_url_for_log(network.base_url) if network.base_url else "–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"

    logging.info(
        "Telegram —Å–µ—Ç—å: base_url=%s, proxy=%s, —Ç–∞–π–º–∞—É—Ç—ã(connect/read/write/pool)=%.1f/%.1f/%.1f/%.1f, polling_timeout=%ss",
        base_url_info,
        proxy_info,
        network.connect_timeout,
        network.read_timeout,
        network.write_timeout,
        network.pool_timeout,
        network.polling_timeout,
    )

    attempt = 0
    while True:
        attempt += 1
        try:
            app = build_application(network)
            polling_kwargs = {
                "drop_pending_updates": drop_pending_updates,
                "timeout": network.polling_timeout,
                "bootstrap_retries": network.polling_bootstrap_retries,
                "connect_timeout": network.connect_timeout,
                "read_timeout": network.read_timeout,
                "write_timeout": network.write_timeout,
                "pool_timeout": network.pool_timeout,
                "close_loop": False,
            }
            # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º —Ä–∞–∑–Ω—ã–µ –≤–µ—Ä—Å–∏–∏ PTB: —Ñ–∏–ª—å—Ç—Ä—É–µ–º –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã.
            supported = inspect.signature(app.run_polling).parameters
            unsupported = [key for key in polling_kwargs if key not in supported]
            if unsupported:
                logging.info(
                    "run_polling: –ø—Ä–æ–ø—É—â–µ–Ω—ã –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: %s",
                    ", ".join(sorted(unsupported)),
                )
            filtered_kwargs = {key: value for key, value in polling_kwargs.items() if key in supported}
            app.run_polling(**filtered_kwargs)
            return
        except InvalidToken as exc:
            logging.error("–ù–µ–≤–∞–ª–∏–¥–Ω—ã–π TELEGRAM_BOT_TOKEN (BotFather). %s", _safe_exception_text(exc))
            raise
        except (TimedOut, NetworkError) as exc:
            retry_index = attempt - 1  # 0 –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ —Ä–µ—Ç—Ä–∞—è
            if network.startup_retries >= 0 and retry_index >= network.startup_retries:
                logging.error(
                    "Telegram API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ—Å–ª–µ %s –ø–æ–ø—ã—Ç–æ–∫. –ü–æ—Å–ª–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞: %s",
                    attempt,
                    _safe_exception_text(exc),
                )
                raise

            delay = compute_backoff_seconds(
                retry_index,
                base_seconds=network.startup_backoff_base_seconds,
                max_seconds=network.startup_backoff_max_seconds,
            )
            logging.warning(
                "Telegram API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (–ø–æ–ø—ã—Ç–∫–∞ %s): %s. –ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ %.1fs. "
                "–ï—Å–ª–∏ Telegram –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω –≤ —Å–µ—Ç–∏, —É–∫–∞–∂–∏—Ç–µ –ø—Ä–æ–∫—Å–∏ —á–µ—Ä–µ–∑ NEIRA_TG_PROXY_URL.",
                attempt,
                _safe_exception_text(exc),
                delay,
            )
            time.sleep(delay)


def main() -> None:
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞: –∑–∞–ø—É—Å–∫ –±–æ—Ç–∞ –≤ —Ä–µ–∂–∏–º–µ long polling."""
    # PTB v21 –æ–∂–∏–¥–∞–µ—Ç —Ç–µ–∫—É—â–∏–π event loop; —Å–æ–∑–¥–∞—ë–º –∏ –Ω–∞–∑–Ω–∞—á–∞–µ–º –≤—Ä—É—á–Ω—É—é.
    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)

    base_dir = _get_base_dir()
    logging.info("–ó–∞–ø—É—Å–∫ Neira Telegram Bot (base_dir=%s)", base_dir)
    
    # === Phase 1: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥—É–ª–µ–π –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç–∏ ===
    global neira_brain, response_engine, organ_system
    try:
        from neira_brain import get_brain
        from response_engine import get_response_engine
        from unified_organ_system import get_organ_system
        
        neira_brain = get_brain()
        response_engine = get_response_engine()
        organ_system = get_organ_system()
        
        stats = response_engine.get_autonomy_stats()
        autonomy_rate = stats.get('metrics', {}).get('autonomy_rate', 0)
        logging.info("üß† –ú–æ–¥—É–ª–∏ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç–∏: OK (–∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç—å: %s%%)", autonomy_rate)
    except Exception as e:
        logging.warning("‚ö†Ô∏è –ú–æ–¥—É–ª–∏ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã: %s", e)
        neira_brain = None
        response_engine = None
        organ_system = None
    
    # üß† –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Neira Cortex v2.0
    global neira_cortex
    if CORTEX_AVAILABLE and CORTEX_MODE != "never":
        try:
            from neira_cortex import create_cortex
            neira_cortex = create_cortex(
                pathways_file="neural_pathways.json",
                use_llm=True  # LLM –≤—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–µ–Ω, fallback –Ω–∞ legacy —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –∑–∞–≥–ª—É—à–∫–∞—Ö
            )
            logging.info("‚úÖ Neira Cortex v2.0 –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω (—Ä–µ–∂–∏–º: %s)", CORTEX_MODE)
        except Exception as e:
            logging.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å Cortex: %s", e)
            neira_cortex = None

    try:
        run_polling_with_startup_retry(drop_pending_updates=True)
    finally:
        try:
            loop.close()
        except Exception:
            pass


if __name__ == "__main__":
    main()
