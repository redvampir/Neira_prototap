"""–¢–µ–ª–µ–≥—Ä–∞–º-–±–æ—Ç –¥–ª—è Neira v0.7: –æ–±—â–µ–Ω–∏–µ, –æ–±—É—á–µ–Ω–∏–µ, —Å–∞–º–æ—Å–æ–∑–Ω–∞–Ω–∏–µ, –∫–∞—Ä—Ç–∏–Ω–∫–∏ –∏ –∑–∞—â–∏—Ç–∞."""

import asyncio
import logging
import os
import hashlib
import secrets
import base64
import io
from pathlib import Path
from typing import Iterable, List, Set, Optional
from functools import wraps
from datetime import datetime

import sys

try:
    sys.stdout.reconfigure(encoding="utf-8", errors="replace")
    sys.stderr.reconfigure(encoding="utf-8", errors="replace")
except Exception:
    pass

import aiohttp
from dotenv import load_dotenv
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.constants import ChatAction, ParseMode
from telegram.error import TimedOut, NetworkError
from telegram.ext import (
    Application,
    CommandHandler,
    ContextTypes,
    MessageHandler,
    CallbackQueryHandler,
    filters,
)

# –õ–æ–∫–∞–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã
from backend.neira_wrapper import NeiraWrapper
from cell_factory import CellFactory
from parallel_thinking import parallel_mind
from enhanced_auth import auth_system
from memory_system import EMBED_MODEL
from autonomous_learning import AutonomousLearningSystem

# üß† Neira Cortex v2.0 - –ê–≤—Ç–æ–Ω–æ–º–Ω–∞—è –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞
try:
    from neira_cortex import NeiraCortex, ProcessingResult, ResponseStrategy
    CORTEX_AVAILABLE = True
except ImportError:
    CORTEX_AVAILABLE = False
    print("‚ö†Ô∏è Neira Cortex –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - –∏—Å–ø–æ–ª—å–∑—É–µ–º legacy —Ä–µ–∂–∏–º")


# === –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ===
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
)

load_dotenv()

BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
if not BOT_TOKEN:
    raise RuntimeError(
        "–ù–µ –∑–∞–¥–∞–Ω TELEGRAM_BOT_TOKEN. –£–∫–∞–∂–∏—Ç–µ –µ–≥–æ –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è "
        "–∏–ª–∏ –≤ —Ñ–∞–π–ª–µ .env (—Å–º. .env.example)."
    )

# === –ó–ê–©–ò–¢–ê: –ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä ===
# –•–µ—à –ø–∞—Ä–æ–ª—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞ (–∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–ª–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
# –í–ê–ñ–ù–û: –ò–∑–º–µ–Ω–∏—Ç–µ NEIRA_ADMIN_PASSWORD –≤ .env!
_ADMIN_PASSWORD = os.getenv("NEIRA_ADMIN_PASSWORD", "change_me_please")
_ADMIN_HASH = hashlib.sha256(_ADMIN_PASSWORD.encode()).hexdigest()
_ADMIN_ID: Optional[int] = None  # –ë—É–¥–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø—Ä–∏ –ø–µ—Ä–≤–æ–π –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏

# –ê–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ (Telegram user_id)
AUTHORIZED_USERS: Set[int] = set()

# –†–µ–∂–∏–º –¥–æ—Å—Ç—É–ø–∞: "open" (–≤—Å–µ), "whitelist" (—Ç–æ–ª—å–∫–æ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ), "admin_only"
ACCESS_MODE = os.getenv("NEIRA_TG_ACCESS", "whitelist")

# ID –∫–∞–Ω–∞–ª–æ–≤/–≥—Ä—É–ø–ø –≥–¥–µ –±–æ—Ç –æ—Ç–≤–µ—á–∞–µ—Ç –±–µ–∑ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)
# –ù–∞–ø—Ä–∏–º–µ—Ä: NEIRA_TG_CHANNELS=-1001234567890,-1009876543210
ALLOWED_CHANNELS: Set[int] = set()
_channels_env = os.getenv("NEIRA_TG_CHANNELS", "")
if _channels_env:
    for ch in _channels_env.split(","):
        try:
            ALLOWED_CHANNELS.add(int(ch.strip()))
        except ValueError:
            pass

# –û—Ç–≤–µ—á–∞—Ç—å —Ç–æ–ª—å–∫–æ –Ω–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –±–æ—Ç–∞ –≤ –≥—Ä—É–ø–ø–∞—Ö/–∫–∞–Ω–∞–ª–∞—Ö?
MENTION_ONLY = os.getenv("NEIRA_TG_MENTION_ONLY", "true").lower() == "true"

neira_wrapper = NeiraWrapper(verbose=False)
processing_lock = asyncio.Lock()

# === –°–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è ===
autonomous_learning_system: Optional[AutonomousLearningSystem] = None

# === üß† Neira Cortex v2.0 ===
neira_cortex: Optional['NeiraCortex'] = None
CORTEX_MODE = os.getenv("NEIRA_CORTEX_MODE", "auto")  # auto, always, never


# === –î–µ–∫–æ—Ä–∞—Ç–æ—Ä –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ ===
def require_auth(func):
    """–î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    @wraps(func)
    async def wrapper(update: Update, context: ContextTypes.DEFAULT_TYPE, *args, **kwargs):
        user_id = update.effective_user.id
        username = update.effective_user.username
        chat_id = update.effective_chat.id
        chat_type = update.effective_chat.type
        
        # –í —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã—Ö –∫–∞–Ω–∞–ª–∞—Ö/–≥—Ä—É–ø–ø–∞—Ö ‚Äî –±–µ–∑ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
        if chat_id in ALLOWED_CHANNELS:
            return await func(update, context, *args, **kwargs)
        
        # –ö–∞–Ω–∞–ª—ã –∏ —Å—É–ø–µ—Ä–≥—Ä—É–ø–ø—ã ‚Äî –ø—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —á–∞—Ç –≤ —Å–ø–∏—Å–∫–µ —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã—Ö
        if chat_type in ("channel", "supergroup", "group"):
            # –ï—Å–ª–∏ —á–∞—Ç –Ω–µ –≤ —Å–ø–∏—Å–∫–µ ‚Äî –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º (–Ω–µ —Å–ø–∞–º–∏–º –ø—Ä–æ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—é)
            if chat_id not in ALLOWED_CHANNELS and ACCESS_MODE != "open":
                return
        
        if ACCESS_MODE == "open":
            return await func(update, context, *args, **kwargs)
        
        if ACCESS_MODE == "admin_only" and user_id != _ADMIN_ID:
            if chat_type == "private":
                await update.message.reply_text("‚õî –î–æ—Å—Ç—É–ø —Ç–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞.")
            return
        
        if user_id in AUTHORIZED_USERS or user_id == _ADMIN_ID:
            return await func(update, context, *args, **kwargs)
        
        if chat_type == "private":
            await update.message.reply_text(
                "üîê –¢—Ä–µ–±—É–µ—Ç—Å—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è.\n"
                "–ò—Å–ø–æ–ª—å–∑—É–π /auth <–ª–æ–≥–∏–Ω> <–ø–∞—Ä–æ–ª—å>"
            )
    return wrapper


def is_admin(user_id: int) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–º."""
    return user_id == _ADMIN_ID


# === –£—Ç–∏–ª–∏—Ç—ã ===
def split_message(text: str, limit: int = 4000) -> List[str]:
    """–î–µ–ª–∏—Ç –¥–ª–∏–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ —á–∞—Å—Ç–∏, —á—Ç–æ–±—ã –Ω–µ —É–ø–µ—Ä–µ—Ç—å—Å—è –≤ –ª–∏–º–∏—Ç Telegram."""
    if len(text) <= limit:
        return [text]

    parts: List[str] = []
    current: List[str] = []
    current_len = 0

    for paragraph in text.split("\n"):
        # –ï—Å–ª–∏ –ø–∞—Ä–∞–≥—Ä–∞—Ñ —Å–∞–º –¥–ª–∏–Ω–Ω–µ–µ –ª–∏–º–∏—Ç–∞ ‚Äî —Ä–µ–∂–µ–º –µ–≥–æ –ø–æ—Å–ª–æ–≤–Ω–æ
        if len(paragraph) > limit:
            words = paragraph.split()
            for word in words:
                if current_len + len(word) + 1 > limit:
                    parts.append(" ".join(current))
                    current = [word]
                    current_len = len(word)
                else:
                    current.append(word)
                    current_len += len(word) + 1
            continue

        if current_len + len(paragraph) + 1 > limit:
            parts.append("\n".join(current))
            current = [paragraph]
            current_len = len(paragraph)
        else:
            current.append(paragraph)
            current_len += len(paragraph) + 1

    if current:
        parts.append("\n".join(current))

    # –§–∏–ª—å—Ç—Ä—É–µ–º –ø—É—Å—Ç—ã–µ —á–∞—Å—Ç–∏
    return [p.strip() for p in parts if p.strip()]


def format_stage(stage: str | None) -> str:
    """–ß–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —ç—Ç–∞–ø–∞."""
    mapping = {
        "analysis": "–ê–Ω–∞–ª–∏–∑",
        "planning": "–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ",
        "execution": "–ò—Å–ø–æ–ª–Ω–µ–Ω–∏–µ",
        "verification": "–ü—Ä–æ–≤–µ—Ä–∫–∞",
    }
    return mapping.get(stage or "", "–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞")


async def send_chunks(
    update: Update,
    context: ContextTypes.DEFAULT_TYPE,
    chunks: Iterable[str],
) -> None:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π, —Å–æ–±–ª—é–¥–∞—è –ª–∏–º–∏—Ç—ã Telegram."""
    chat_id = update.effective_chat.id
    for part in chunks:
        await context.bot.send_message(chat_id=chat_id, text=part)


async def show_typing(
    update: Update, context: ContextTypes.DEFAULT_TYPE
) -> None:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –¥–µ–π—Å—Ç–≤–∏–µ '–ø–µ—á–∞—Ç–∞–µ—Ç' –¥–ª—è UX."""
    await context.bot.send_chat_action(
        chat_id=update.effective_chat.id,
        action=ChatAction.TYPING,
    )


# === –†–∞–±–æ—Ç–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ ===
OLLAMA_API = "http://localhost:11434/api"
VISION_MODEL = "llava:7b"  # –ú–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –¥—Ä—É–≥—É—é)
SD_API = "http://127.0.0.1:7860/sdapi/v1"  # Stable Diffusion API


async def analyze_image_with_ollama(image_base64: str, prompt: str = "–û–ø–∏—à–∏ —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–¥—Ä–æ–±–Ω–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ") -> str:
    """–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ Ollama vision –º–æ–¥–µ–ª—å."""
    try:
        async with aiohttp.ClientSession() as session:
            payload = {
                "model": VISION_MODEL,
                "prompt": prompt,
                "images": [image_base64],
                "stream": False
            }
            async with session.post(f"{OLLAMA_API}/generate", json=payload, timeout=aiohttp.ClientTimeout(total=120)) as resp:
                if resp.status == 200:
                    result = await resp.json()
                    return result.get("response", "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.")
                else:
                    return f"–û—à–∏–±–∫–∞ API Ollama: {resp.status}"
    except aiohttp.ClientError as e:
        return f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Ollama: {e}"
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}"


async def check_vision_model() -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ vision –º–æ–¥–µ–ª–∏."""
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(f"{OLLAMA_API}/tags", timeout=aiohttp.ClientTimeout(total=5)) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    models = [m.get("name", "") for m in data.get("models", [])]
                    return any(VISION_MODEL in m or "llava" in m.lower() or "vision" in m.lower() for m in models)
    except:
        pass
    return False


async def generate_image_sd(prompt: str) -> Optional[bytes]:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ Stable Diffusion API."""
    try:
        async with aiohttp.ClientSession() as session:
            payload = {
                "prompt": prompt,
                "negative_prompt": "ugly, blurry, bad anatomy, bad hands, missing fingers, low quality",
                "steps": 20,
                "width": 512,
                "height": 512,
                "sampler_name": "Euler a",
                "cfg_scale": 7,
            }
            async with session.post(f"{SD_API}/txt2img", json=payload, timeout=aiohttp.ClientTimeout(total=180)) as resp:
                if resp.status == 200:
                    result = await resp.json()
                    images = result.get("images", [])
                    if images:
                        return base64.b64decode(images[0])
    except aiohttp.ClientError as e:
        logging.warning(f"SD API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ SD: {e}")
    return None


async def check_sd_available() -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ Stable Diffusion API."""
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(f"{SD_API}/sd-models", timeout=aiohttp.ClientTimeout(total=5)) as resp:
                return resp.status == 200
    except:
        return False


# === –ö–æ–º–∞–Ω–¥—ã ===
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ –∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –∑–∞–ø—É—Å–∫—É."""
    user_id = update.effective_user.id
    user_name = update.effective_user.first_name or "–¥—Ä—É–≥"
    
    is_authorized = user_id in AUTHORIZED_USERS or user_id == _ADMIN_ID or ACCESS_MODE == "open"
    
    if is_authorized:
        text = (
            f"–ü—Ä–∏–≤–µ—Ç, {user_name}! üëã –Ø Neira v1.0 –≤ Telegram.\n\n"
            "üöÄ *–ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç:*\n"
            "1Ô∏è‚É£ –ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ –º–Ω–µ —Å–æ–æ–±—â–µ–Ω–∏–µ ‚Äî —è –æ—Ç–≤–µ—á—É –∏ –∑–∞–ø–æ–º–Ω—é\n"
            "2Ô∏è‚É£ –û—Ç–ø—Ä–∞–≤—å —Ñ–æ—Ç–æ ‚Äî –æ–ø–∏—à—É —á—Ç–æ –≤–∏–∂—É\n"
            "3Ô∏è‚É£ –ó–∞–ø—É—Å—Ç–∏ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ: /learn\\_auto start\n\n"
            "‚ú® *–ß—Ç–æ —è —É–º–µ—é:*\n"
            "üß† –î–∏–∞–ª–æ–≥ —Å –ø–∞–º—è—Ç—å—é –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º\n"
            "üéì –ê–≤—Ç–æ–Ω–æ–º–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∏–∑ –Ω–∞–¥—ë–∂–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤\n"
            "üñºÔ∏è –ê–Ω–∞–ª–∏–∑ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n"
            "üß¨ –°–∞–º–æ—Å–æ–∑–Ω–∞–Ω–∏–µ –∏ —Ä–æ—Å—Ç –æ—Ä–≥–∞–Ω–æ–≤\n"
            "üíæ –†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç—å—é\n"
            "üîí –ó–∞—â–∏—Ç–∞ –æ—Ç –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π\n\n"
            "üìö *–û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:*\n"
            "/help ‚Äî –ø–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∫–æ–º–∞–Ω–¥\n"
            "/learn\\_auto start ‚Äî –∑–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ\n"
            "/memory stats ‚Äî —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞–º—è—Ç–∏\n"
            "/self ‚Äî —Å–∞–º–æ—Å–æ–∑–Ω–∞–Ω–∏–µ\n"
            "/stats ‚Äî —Å—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º\n\n"
            "üí° *–°–æ–≤–µ—Ç:* –ù–∞—á–Ω–∏ —Å `/learn_auto start` ‚Äî —è –±—É–¥—É —É—á–∏—Ç—å—Å—è —Å–∞–º–∞, "
            "–∫–æ–≥–¥–∞ –Ω–µ –∑–∞–Ω—è—Ç–∞ –¥–∏–∞–ª–æ–≥–∞–º–∏!"
        )
        if is_admin(user_id):
            text += "\n\nüëë –¢—ã –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä. –î–æ—Å—Ç—É–ø–Ω—ã /admin –∫–æ–º–∞–Ω–¥—ã."
    else:
        text = (
            f"–ü—Ä–∏–≤–µ—Ç, {user_name}! –Ø Neira ‚Äî AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ–º.\n\n"
            "üîê *–î–ª—è –¥–æ—Å—Ç—É–ø–∞ –Ω—É–∂–Ω–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è:*\n"
            "/auth <–ª–æ–≥–∏–Ω> <–ø–∞—Ä–æ–ª—å>\n\n"
            "–ü–æ–ø—Ä–æ—Å–∏ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞ –¥–∞—Ç—å —Ç–µ–±–µ –¥–æ—Å—Ç—É–ø.\n\n"
            "üìñ *–û –ø—Ä–æ–µ–∫—Ç–µ:*\n"
            "Neira ‚Äî —ç—Ç–æ AI —Å –ø–∞–º—è—Ç—å—é, —Å–∞–º–æ—Å–æ–∑–Ω–∞–Ω–∏–µ–º –∏ –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–º –æ–±—É—á–µ–Ω–∏–µ–º. "
            "–Ø –º–æ–≥—É –æ–±—É—á–∞—Ç—å—Å—è –∏–∑ –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ (Wikipedia, Python.org, arXiv) "
            "—Å –º–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤–æ–π –∑–∞—â–∏—Ç–æ–π –æ—Ç –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π."
        )
    
    await update.message.reply_text(text, parse_mode=ParseMode.MARKDOWN)


async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ü–æ–¥—Ä–æ–±–Ω–∞—è —Å–ø—Ä–∞–≤–∫–∞."""
    user_id = update.effective_user.id
    
    text = (
        "üìö *–ö–æ–º–∞–Ω–¥—ã Neira v0.7*\n\n"
        "*–û–±—â–µ–Ω–∏–µ:*\n"
        "–ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ ‚Äî Neira –æ—Ç–≤–µ—Ç–∏—Ç\n\n"
        "*–°–∞–º–æ—Å–æ–∑–Ω–∞–Ω–∏–µ:*\n"
        "/self ‚Äî –∫—Ç–æ —è —Ç–∞–∫–∞—è?\n"
        "/organs ‚Äî —Å–ø–∏—Å–æ–∫ –º–æ–∏—Ö –æ—Ä–≥–∞–Ω–æ–≤\n"
        "/grow ‚Äî –∫–∞–∫ –º–Ω–µ —Ä–∞—Å—Ç–∏?\n\n"
        "*üíæ –ü–∞–º—è—Ç—å (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ):*\n"
        "üìñ /memory ‚Äî –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞–ø–∏—Å–∏\n"
        "üìä /memory stats ‚Äî —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n"
        "üîç /memory search/semantic <—Ç–µ–∫—Å—Ç>\n"
        "üóëÔ∏è /memory delete last/text/old\n"
        "üßπ /memory dedupe ‚Äî –¥—É–±–ª–∏–∫–∞—Ç—ã\n"
        "üíæ /memory backup/restore\n"
        "üìå /memory pin/pinned ‚Äî –∑–∞–∫—Ä–µ–ø–∏—Ç—å\n"
        "üîß /memory filter confidence/source/recent\n"
        "üìÑ /memory export txt\n"
        "/experience ‚Äî –ª–∏—á–Ω–æ—Å—Ç—å\n"
        "/clear ‚Äî –ø–æ–ª–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞\n\n"
        "*üß† –ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞:*\n"
        "/context ‚Äî –∏—Å—Ç–æ—Ä–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞\n"
        "/clear\\_context ‚Äî –æ—á–∏—Å—Ç–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç\n\n"
        "*–û–±—É—á–µ–Ω–∏–µ:*\n"
        "/learn <—Ç–µ–º–∞> ‚Äî –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞\n\n"
        "*–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:*\n"
        "üì∑ –û—Ç–ø—Ä–∞–≤—å —Ñ–æ—Ç–æ ‚Äî –∞–Ω–∞–ª–∏–∑\n"
        "/imagine <–æ–ø–∏—Å–∞–Ω–∏–µ>\n"
        "/vision ‚Äî —Å—Ç–∞—Ç—É—Å\n\n"
        "*–ö–æ–¥:*\n"
        "/code list/read\n\n"
        "*üß¨ –°–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ:*\n"
        "#—Å–æ–∑–¥–∞–π\\_–æ—Ä–≥–∞–Ω <–æ–ø–∏—Å–∞–Ω–∏–µ>\n\n"
        "*üéì –ê–≤—Ç–æ–Ω–æ–º–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ (v1.0):*\n"
        "/learn\\_auto start ‚Äî –∑–∞–ø—É—Å—Ç–∏—Ç—å —Ñ–æ–Ω–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ\n"
        "/learn\\_auto stop ‚Äî –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å\n"
        "/learn\\_auto stats ‚Äî —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n"
        "/learn\\_auto quarantine ‚Äî –∫–∞—Ä–∞–Ω—Ç–∏–Ω –∑–Ω–∞–Ω–∏–π\n"
        "/learn\\_auto approve/reject <id> ‚Äî –ø—Ä–æ–≤–µ—Ä–∫–∞\n"
    )
    
    if is_admin(user_id):
        text += (
            "\n*üëë –ê–¥–º–∏–Ω-–∫–æ–º–∞–Ω–¥—ã:*\n"
            "/admin users ‚Äî —Å–ø–∏—Å–æ–∫ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö\n"
            "/admin add <identifier> ‚Äî –¥–æ–±–∞–≤–∏—Ç—å (@username –∏–ª–∏ user\\_id)\n"
            "/admin remove <user\\_id> ‚Äî —É–¥–∞–ª–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n"
            "/admin stats ‚Äî —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è\n"
            "/admin mode <open|whitelist|admin\\_only> ‚Äî —Ä–µ–∂–∏–º –¥–æ—Å—Ç—É–ø–∞\n"
        )
    
    await update.message.reply_text(text, parse_mode=ParseMode.MARKDOWN)


async def stats_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û—Ç—á—ë—Ç –æ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –º–æ–¥–µ–ª–µ–π –∏ –ø–∞–º—è—Ç–∏."""
    await show_typing(update, context)
    stats = neira_wrapper.get_stats()

    lines = [
        "–°—Ç–∞—Ç—É—Å Neira:",
        f"- –û–±—Ä–∞–±–æ—Ç–∫–∞: {'–¥–∞' if stats.get('is_processing') else '–Ω–µ—Ç'}",
    ]

    models = stats.get("models", {})
    local = models.get("local", {})
    cloud = models.get("cloud", {})

    lines.append(
        "- –õ–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏: "
        f"code={'OK' if local.get('code') else '–Ω–µ—Ç'}, "
        f"reason={'OK' if local.get('reason') else '–Ω–µ—Ç'}, "
        f"personality={'OK' if local.get('personality') else '–Ω–µ—Ç'}"
    )
    lines.append(
        "- –û–±–ª–∞—á–Ω—ã–µ: "
        f"code={'OK' if cloud.get('code') else '–Ω–µ—Ç'}, "
        f"universal={'OK' if cloud.get('universal') else '–Ω–µ—Ç'}, "
        f"vision={'OK' if cloud.get('vision') else '–Ω–µ—Ç'}"
    )

    memory = stats.get("memory", {})
    lines.append(
        f"- –ü–∞–º—è—Ç—å: –≤—Å–µ–≥–æ {memory.get('total', 0)}, –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–µ—Å—Å–∏–∏ "
        f"{memory.get('session_context', 0)}"
    )

    if "model_manager" in stats:
        manager = stats["model_manager"]
        lines.append(
            f"- ModelManager: –∞–∫—Ç–∏–≤–Ω–∞ {manager.get('current_model')}, "
            f"–ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–π {manager.get('switches', 0)}"
        )

    if "experience" in stats:
        exp = stats["experience"]
        lines.append(
            f"- –û–ø—ã—Ç: –≤—Å–µ–≥–æ {exp.get('total', 0)}, —Å—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ "
            f"{exp.get('avg_score', 0)}"
        )
    
    # üß† Cortex v2.0 —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    if neira_cortex:
        cortex_stats = neira_cortex.get_stats()
        lines.append(f"\nüß† *Neira Cortex v2.0:*")
        lines.append(f"- –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {cortex_stats['total_requests']}")
        
        # –¢–æ–ø-3 —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        top_strategies = sorted(
            cortex_stats['strategies'].items(),
            key=lambda x: x[1],
            reverse=True
        )[:3]
        lines.append("- –¢–æ–ø —Å—Ç—Ä–∞—Ç–µ–≥–∏–π:")
        for strategy, count in top_strategies:
            percentage = (count / cortex_stats['total_requests'] * 100) if cortex_stats['total_requests'] > 0 else 0
            lines.append(f"  ‚Ä¢ {strategy}: {count} ({percentage:.0f}%)")
        
        # –ü–æ–∫—Ä—ã—Ç–∏–µ pathways
        coverage = cortex_stats['pathways']['coverage']
        lines.append(f"- –ü–æ–∫—Ä—ã—Ç–∏–µ: HOT {coverage.get('hot', '0%')}, WARM {coverage.get('warm', '0%')}")

    await update.message.reply_text("\n".join(lines), parse_mode=ParseMode.MARKDOWN)


@require_auth
async def memory_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç—å—é Neira
    
    –ö–æ–º–∞–Ω–¥—ã:
    /memory - –ø–æ–∫–∞–∑–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 –∑–∞–ø–∏—Å–µ–π
    /memory stats - –¥–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    /memory search <—Ç–µ–∫—Å—Ç> - –Ω–∞–π—Ç–∏ –∑–∞–ø–∏—Å–∏
    /memory delete last <N> - —É–¥–∞–ª–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –∑–∞–ø–∏—Å–µ–π
    /memory delete text <—Ç–µ–∫—Å—Ç> - —É–¥–∞–ª–∏—Ç—å –∑–∞–ø–∏—Å–∏ —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ —Ç–µ–∫—Å—Ç
    /memory delete old <–¥–Ω–µ–π> - —É–¥–∞–ª–∏—Ç—å –∑–∞–ø–∏—Å–∏ —Å—Ç–∞—Ä—à–µ N –¥–Ω–µ–π
    /memory dedupe - —É–¥–∞–ª–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã
    /memory backup - —Å–æ–∑–¥–∞—Ç—å –±—ç–∫–∞–ø
    """
    if not context.args:
        # –ü–æ–∫–∞–∑–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞–ø–∏—Å–∏
        await show_typing(update, context)
        data = neira_wrapper.get_memory(limit=10)
        recent = data.get("recent", [])
        if not recent:
            await update.message.reply_text("üì≠ –ü–∞–º—è—Ç—å –ø—É—Å—Ç–∞.")
            return

        lines = ["üíæ *–ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 –∑–∞–ø–∏—Å–µ–π:*\n"]
        for i, item in enumerate(recent, 1):
            category = item.get('category', 'general')
            text = item.get('text', '')[:80]
            lines.append(f"{i}. `[{category}]` {text}...")
        
        lines.append(f"\n_–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {data.get('total', len(recent))}_")
        lines.append("_–ò—Å–ø–æ–ª—å–∑—É–π /memory stats –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏_")
        
        await update.message.reply_text("\n".join(lines), parse_mode=ParseMode.MARKDOWN)
        return
    
    action = context.args[0].lower()
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä –ø–∞–º—è—Ç–∏
    from memory_system import MemoryManager
    
    if not neira_wrapper.neira.memory.memory_system:
        await update.message.reply_text("‚ùå –°–∏—Å—Ç–µ–º–∞ –ø–∞–º—è—Ç–∏ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
        return
    
    memory_manager = MemoryManager(neira_wrapper.neira.memory.memory_system)
    
    if action == "stats":
        # –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = memory_manager.get_stats()
        lines = [
            "üìä *–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞–º—è—Ç–∏:*\n",
            f"üì¶ –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {stats['total']}",
            f"üìö –î–æ–ª–≥–æ—Å—Ä–æ—á–Ω–∞—è: {stats['by_type'].get('long_term', 0)}",
            f"‚ö° –ö—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω–∞—è: {stats['by_type'].get('short_term', 0)}",
            f"üìñ –≠–ø–∏–∑–æ–¥–∏—á–µ—Å–∫–∞—è: {stats['by_type'].get('episodic', 0)}",
            f"üß† –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è: {stats['by_type'].get('semantic', 0)}",
        ]
        
        if stats.get('oldest'):
            oldest = datetime.fromisoformat(stats['oldest']).strftime("%d.%m.%Y")
            newest = datetime.fromisoformat(stats['newest']).strftime("%d.%m.%Y %H:%M")
            lines.append(f"\nüìÖ –ü–µ—Ä–∏–æ–¥: {oldest} ‚Äî {newest}")
        
        lines.append(f"üéØ –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {stats['average_confidence']:.1%}")
        
        # –¢–æ–ø –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        if stats['by_category']:
            lines.append("\nüè∑Ô∏è *–ö–∞—Ç–µ–≥–æ—Ä–∏–∏:*")
            sorted_cats = sorted(stats['by_category'].items(), key=lambda x: x[1], reverse=True)
            for cat, count in sorted_cats[:5]:
                lines.append(f"  ‚Ä¢ {cat}: {count}")
        
        await update.message.reply_text("\n".join(lines), parse_mode=ParseMode.MARKDOWN)
    
    elif action == "search" and len(context.args) > 1:
        # –ü–æ–∏—Å–∫ –∑–∞–ø–∏—Å–µ–π
        query = " ".join(context.args[1:])
        results = memory_manager.search_by_text(query)
        
        if not results:
            await update.message.reply_text(f"üîç –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{query}'")
            return
        
        lines = [f"üîç *–ù–∞–π–¥–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(results)}*\n"]
        for i, entry in enumerate(results[:15], 1):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 15
            text = entry.text[:80] + "..." if len(entry.text) > 80 else entry.text
            lines.append(f"{i}. `[{entry.category}]` {text}")
        
        if len(results) > 15:
            lines.append(f"\n_...–∏ –µ—â—ë {len(results) - 15} –∑–∞–ø–∏—Å–µ–π_")
        
        await update.message.reply_text("\n".join(lines), parse_mode=ParseMode.MARKDOWN)
    
    elif action == "delete":
        # –¢—Ä–µ–±—É–µ—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
        if len(context.args) < 2:
            await update.message.reply_text(
                "‚ùì *–ö–æ–º–∞–Ω–¥—ã —É–¥–∞–ª–µ–Ω–∏—è:*\n"
                "/memory delete last <N> ‚Äî —É–¥–∞–ª–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –∑–∞–ø–∏—Å–µ–π\n"
                "/memory delete text <—Ç–µ–∫—Å—Ç> ‚Äî —É–¥–∞–ª–∏—Ç—å –∑–∞–ø–∏—Å–∏ —Å–æ —Å–ª–æ–≤–æ–º\n"
                "/memory delete old <–¥–Ω–µ–π> ‚Äî —É–¥–∞–ª–∏—Ç—å –∑–∞–ø–∏—Å–∏ —Å—Ç–∞—Ä—à–µ N –¥–Ω–µ–π\n"
                "/memory delete category <–∫–∞—Ç–µ–≥–æ—Ä–∏—è> ‚Äî —É–¥–∞–ª–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—é",
                parse_mode=ParseMode.MARKDOWN
            )
            return
        
        subaction = context.args[1].lower()
        
        if subaction == "last" and len(context.args) > 2:
            try:
                n = int(context.args[2])
                if n < 1 or n > 100:
                    await update.message.reply_text("‚ùå N –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –æ—Ç 1 –¥–æ 100")
                    return
                
                count = memory_manager.delete_last_n(n)
                await update.message.reply_text(
                    f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –∑–∞–ø–∏—Å–µ–π: {count}\n"
                    f"_–ò—Å–ø–æ–ª—å–∑—É–π /memory stats –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏_",
                    parse_mode=ParseMode.MARKDOWN
                )
            except ValueError:
                await update.message.reply_text("‚ùå N –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —á–∏—Å–ª–æ–º")
        
        elif subaction == "text" and len(context.args) > 2:
            query = " ".join(context.args[2:])
            count = memory_manager.delete_by_text(query)
            await update.message.reply_text(
                f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π —Å '{query}': {count}",
                parse_mode=ParseMode.MARKDOWN
            )
        
        elif subaction == "old" and len(context.args) > 2:
            try:
                days = int(context.args[2])
                if days < 1:
                    await update.message.reply_text("‚ùå –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º")
                    return
                
                count = memory_manager.delete_old_entries(days)
                await update.message.reply_text(
                    f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π —Å—Ç–∞—Ä—à–µ {days} –¥–Ω.: {count}",
                    parse_mode=ParseMode.MARKDOWN
                )
            except ValueError:
                await update.message.reply_text("‚ùå –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —á–∏—Å–ª–æ–º")
        
        elif subaction == "category" and len(context.args) > 2:
            category = context.args[2]
            count = memory_manager.delete_by_category(category)
            await update.message.reply_text(
                f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}': {count}",
                parse_mode=ParseMode.MARKDOWN
            )
        
        else:
            await update.message.reply_text("‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –ø–æ–¥–∫–æ–º–∞–Ω–¥–∞ —É–¥–∞–ª–µ–Ω–∏—è")
    
    elif action == "dedupe":
        # –£–¥–∞–ª–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã
        count = memory_manager.deduplicate()
        await update.message.reply_text(
            f"üßπ –£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {count}\n"
            f"_–î—É–±–ª–∏–∫–∞—Ç–∞–º–∏ —Å—á–∏—Ç–∞—é—Ç—Å—è –∑–∞–ø–∏—Å–∏ —Å >95% —Å—Ö–æ–∂–µ—Å—Ç—å—é_",
            parse_mode=ParseMode.MARKDOWN
        )
    
    elif action == "backup":
        # –°–æ–∑–¥–∞—Ç—å –±—ç–∫–∞–ø
        backup_path = memory_manager.create_backup()
        filename = os.path.basename(backup_path)
        await update.message.reply_text(
            f"üíæ –ë—ç–∫–∞–ø —Å–æ–∑–¥–∞–Ω: `{filename}`\n"
            f"_–°–æ—Ö—Ä–∞–Ω—ë–Ω –≤ –ø–∞–ø–∫—É backups/_",
            parse_mode=ParseMode.MARKDOWN
        )
    
    elif action == "restore" and len(context.args) > 1:
        # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∏–∑ –±—ç–∫–∞–ø–∞
        backup_name = context.args[1]
        success = memory_manager.restore_from_backup(backup_name)
        
        if success:
            await update.message.reply_text(
                f"‚úÖ –ü–∞–º—è—Ç—å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –∏–∑ `{backup_name}`\n"
                f"_–ò—Å–ø–æ–ª—å–∑—É–π /memory stats –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏_",
                parse_mode=ParseMode.MARKDOWN
            )
        else:
            await update.message.reply_text(
                f"‚ùå –ë—ç–∫–∞–ø `{backup_name}` –Ω–µ –Ω–∞–π–¥–µ–Ω\n"
                f"_–ò—Å–ø–æ–ª—å–∑—É–π /memory backups –¥–ª—è —Å–ø–∏—Å–∫–∞_",
                parse_mode=ParseMode.MARKDOWN
            )
    
    elif action == "backups":
        # –°–ø–∏—Å–æ–∫ –±—ç–∫–∞–ø–æ–≤
        backups = memory_manager.list_backups()
        
        if not backups:
            await update.message.reply_text("üì≠ –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –±—ç–∫–∞–ø–æ–≤")
            return
        
        lines = [f"üíæ *–î–æ—Å—Ç—É–ø–Ω—ã–µ –±—ç–∫–∞–ø—ã ({len(backups)}):*\n"]
        for i, backup in enumerate(backups[:10], 1):
            timestamp = datetime.fromisoformat(backup['timestamp']).strftime("%d.%m.%Y %H:%M")
            size_kb = backup['size'] // 1024
            lines.append(
                f"{i}. `{backup['filename']}`\n"
                f"   üìÖ {timestamp} | üì¶ {backup['total']} –∑–∞–ø–∏—Å–µ–π | üíæ {size_kb} KB"
            )
        
        if len(backups) > 10:
            lines.append(f"\n_...–∏ –µ—â—ë {len(backups) - 10} –±—ç–∫–∞–ø–æ–≤_")
        
        lines.append("\n_–ò—Å–ø–æ–ª—å–∑—É–π /memory restore <filename>_")
        await update.message.reply_text("\n".join(lines), parse_mode=ParseMode.MARKDOWN)
    
    elif action == "filter" and len(context.args) > 1:
        # –£–º–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã
        filter_type = context.args[1].lower()
        
        if filter_type == "confidence" and len(context.args) > 2:
            # /memory filter confidence <0.5
            filter_expr = context.args[2]
            
            # –ü–∞—Ä—Å–∏–º –æ–ø–µ—Ä–∞—Ç–æ—Ä –∏ –∑–Ω–∞—á–µ–Ω–∏–µ
            import re
            match = re.match(r'([<>=]+)([\d.]+)', filter_expr)
            if not match:
                await update.message.reply_text("‚ùå –§–æ—Ä–º–∞—Ç: /memory filter confidence <0.5")
                return
            
            operator = match.group(1)
            threshold = float(match.group(2))
            
            results = memory_manager.filter_by_confidence(operator, threshold)
            
            if not results:
                await update.message.reply_text(
                    f"üîç –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é {operator}{threshold}"
                )
                return
            
            lines = [f"üîç *–ù–∞–π–¥–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(results)}* (confidence {operator}{threshold})\n"]
            for i, entry in enumerate(results[:15], 1):
                text = entry.text[:60] + "..." if len(entry.text) > 60 else entry.text
                lines.append(f"{i}. [{entry.confidence:.0%}] {text}")
            
            if len(results) > 15:
                lines.append(f"\n_...–∏ –µ—â—ë {len(results) - 15}_")
            
            await update.message.reply_text("\n".join(lines), parse_mode=ParseMode.MARKDOWN)
        
        elif filter_type == "source" and len(context.args) > 2:
            # /memory filter source telegram
            source = context.args[2]
            results = memory_manager.filter_by_source(source)
            
            if not results:
                await update.message.reply_text(f"üîç –ù–µ—Ç –∑–∞–ø–∏—Å–µ–π –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ '{source}'")
                return
            
            lines = [f"üîç *–ó–∞–ø–∏—Å–µ–π –∏–∑ '{source}': {len(results)}*\n"]
            for i, entry in enumerate(results[:15], 1):
                text = entry.text[:60] + "..." if len(entry.text) > 60 else entry.text
                lines.append(f"{i}. `[{entry.category}]` {text}")
            
            if len(results) > 15:
                lines.append(f"\n_...–∏ –µ—â—ë {len(results) - 15}_")
            
            await update.message.reply_text("\n".join(lines), parse_mode=ParseMode.MARKDOWN)
        
        elif filter_type == "recent" and len(context.args) > 2:
            # /memory filter recent 24h
            time_str = context.args[2]
            hours = int(time_str.replace('h', ''))
            
            results = memory_manager.filter_by_timerange(hours)
            
            if not results:
                await update.message.reply_text(f"üîç –ù–µ—Ç –∑–∞–ø–∏—Å–µ–π –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ {hours}—á")
                return
            
            lines = [f"üîç *–ó–∞–ø–∏—Å–µ–π –∑–∞ {hours}—á: {len(results)}*\n"]
            for i, entry in enumerate(results[:15], 1):
                timestamp = datetime.fromisoformat(entry.timestamp).strftime("%H:%M")
                text = entry.text[:50] + "..." if len(entry.text) > 50 else entry.text
                lines.append(f"{i}. [{timestamp}] {text}")
            
            if len(results) > 15:
                lines.append(f"\n_...–∏ –µ—â—ë {len(results) - 15}_")
            
            await update.message.reply_text("\n".join(lines), parse_mode=ParseMode.MARKDOWN)
        
        else:
            await update.message.reply_text(
                "‚ùì *–§–∏–ª—å—Ç—Ä—ã:*\n"
                "/memory filter confidence <0.5\n"
                "/memory filter source telegram\n"
                "/memory filter recent 24h",
                parse_mode=ParseMode.MARKDOWN
            )
    
    elif action == "pin" and len(context.args) > 1:
        # –ó–∞–∫—Ä–µ–ø–∏—Ç—å –∑–∞–ø–∏—Å—å
        # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –∑–∞–ø–∏—Å—å –ø–æ –Ω–æ–º–µ—Ä—É –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ search
        try:
            entry_num = int(context.args[1]) - 1
            data = neira_wrapper.get_memory(limit=100)
            recent = data.get("recent", [])
            
            if entry_num < 0 or entry_num >= len(recent):
                await update.message.reply_text("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –Ω–æ–º–µ—Ä –∑–∞–ø–∏—Å–∏")
                return
            
            entry_id = recent[entry_num].get('id')
            if memory_manager.pin_entry(entry_id):
                await update.message.reply_text(
                    f"üìå –ó–∞–ø–∏—Å—å #{context.args[1]} –∑–∞–∫—Ä–µ–ø–ª–µ–Ω–∞\n"
                    f"_–ó–∞—â–∏—â–µ–Ω–∞ –æ—Ç —É–¥–∞–ª–µ–Ω–∏—è_",
                    parse_mode=ParseMode.MARKDOWN
                )
            else:
                await update.message.reply_text("‚ùå –ó–∞–ø–∏—Å—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        except (ValueError, IndexError):
            await update.message.reply_text("‚ùå –£–∫–∞–∂–∏—Ç–µ –Ω–æ–º–µ—Ä –∑–∞–ø–∏—Å–∏ –∏–∑ /memory")
    
    elif action == "unpin" and len(context.args) > 1:
        # –û—Ç–∫—Ä–µ–ø–∏—Ç—å –∑–∞–ø–∏—Å—å
        try:
            entry_num = int(context.args[1]) - 1
            data = neira_wrapper.get_memory(limit=100)
            recent = data.get("recent", [])
            
            if entry_num < 0 or entry_num >= len(recent):
                await update.message.reply_text("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –Ω–æ–º–µ—Ä –∑–∞–ø–∏—Å–∏")
                return
            
            entry_id = recent[entry_num].get('id')
            if memory_manager.unpin_entry(entry_id):
                await update.message.reply_text(
                    f"üìç –ó–∞–ø–∏—Å—å #{context.args[1]} –æ—Ç–∫—Ä–µ–ø–ª–µ–Ω–∞",
                    parse_mode=ParseMode.MARKDOWN
                )
            else:
                await update.message.reply_text("‚ùå –ó–∞–ø–∏—Å—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        except (ValueError, IndexError):
            await update.message.reply_text("‚ùå –£–∫–∞–∂–∏—Ç–µ –Ω–æ–º–µ—Ä –∑–∞–ø–∏—Å–∏ –∏–∑ /memory")
    
    elif action == "pinned":
        # –ü–æ–∫–∞–∑–∞—Ç—å –∑–∞–∫—Ä–µ–ø–ª—ë–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏
        pinned = memory_manager.get_pinned()
        
        if not pinned:
            await update.message.reply_text("üì≠ –ù–µ—Ç –∑–∞–∫—Ä–µ–ø–ª—ë–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π")
            return
        
        lines = [f"üìå *–ó–∞–∫—Ä–µ–ø–ª—ë–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏ ({len(pinned)}):*\n"]
        for i, entry in enumerate(pinned[:20], 1):
            text = entry.text[:60] + "..." if len(entry.text) > 60 else entry.text
            lines.append(f"{i}. `[{entry.category}]` {text}")
        
        if len(pinned) > 20:
            lines.append(f"\n_...–∏ –µ—â—ë {len(pinned) - 20}_")
        
        await update.message.reply_text("\n".join(lines), parse_mode=ParseMode.MARKDOWN)
    
    elif action == "export" and len(context.args) > 1:
        # –≠–∫—Å–ø–æ—Ä—Ç –≤ —Ç–µ–∫—Å—Ç
        export_type = context.args[1].lower()
        
        if export_type == "txt":
            # –≠–∫—Å–ø–æ—Ä—Ç –≤—Å–µ–π –ø–∞–º—è—Ç–∏
            category = context.args[2] if len(context.args) > 2 else None
            text_export = memory_manager.export_to_text(category)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"memory_export_{timestamp}.txt"
            filepath = os.path.join("backups", filename)
            os.makedirs("backups", exist_ok=True)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(text_export)
            
            await update.message.reply_text(
                f"üìÑ –≠–∫—Å–ø–æ—Ä—Ç —Å–æ–∑–¥–∞–Ω: `{filename}`\n"
                f"_–°–æ—Ö—Ä–∞–Ω—ë–Ω –≤ –ø–∞–ø–∫—É backups/_",
                parse_mode=ParseMode.MARKDOWN
            )
        else:
            await update.message.reply_text(
                "‚ùì *–≠–∫—Å–ø–æ—Ä—Ç:*\n"
                "/memory export txt ‚Äî –≤—Å—è –ø–∞–º—è—Ç—å\n"
                "/memory export txt <–∫–∞—Ç–µ–≥–æ—Ä–∏—è>",
                parse_mode=ParseMode.MARKDOWN
            )
    
    elif action == "semantic" and len(context.args) > 1:
        # –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫
        query = " ".join(context.args[1:])
        results = memory_manager.semantic_search(query, top_k=10)
        
        if not results:
            await update.message.reply_text(
                f"üîç –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞\n"
                f"_(–¢—Ä–µ–±—É–µ—Ç—Å—è Ollama —Å {EMBED_MODEL})_",
                parse_mode=ParseMode.MARKDOWN
            )
            return
        
        lines = [f"üß† *–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫:* '{query}'\n"]
        for i, (entry, score) in enumerate(results, 1):
            text = entry.text[:60] + "..." if len(entry.text) > 60 else entry.text
            lines.append(f"{i}. [{score:.0%}] {text}")
        
        await update.message.reply_text("\n".join(lines), parse_mode=ParseMode.MARKDOWN)
    
    else:
        await update.message.reply_text(
            "‚ùì *–ö–æ–º–∞–Ω–¥—ã –ø–∞–º—è—Ç–∏:*\n"
            "/memory ‚Äî –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞–ø–∏—Å–∏\n"
            "/memory stats ‚Äî —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n"
            "/memory search <—Ç–µ–∫—Å—Ç>\n"
            "/memory delete last <N>\n"
            "/memory delete text <—Ç–µ–∫—Å—Ç>\n"
            "/memory delete old <–¥–Ω–µ–π>\n"
            "/memory dedupe ‚Äî —É–¥–∞–ª–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã\n"
            "/memory backup ‚Äî —Å–æ–∑–¥–∞—Ç—å –±—ç–∫–∞–ø\n"
            "/memory backups ‚Äî —Å–ø–∏—Å–æ–∫ –±—ç–∫–∞–ø–æ–≤\n"
            "/memory restore <filename>\n"
            "/memory filter confidence <0.5\n"
            "/memory filter source telegram\n"
            "/memory filter recent 24h\n"
            "/memory pin <N> ‚Äî –∑–∞–∫—Ä–µ–ø–∏—Ç—å –∑–∞–ø–∏—Å—å\n"
            "/memory pinned ‚Äî –∑–∞–∫—Ä–µ–ø–ª—ë–Ω–Ω—ã–µ\n"
            "/memory export txt\n"
            "/memory semantic <–∑–∞–ø—Ä–æ—Å>",
            parse_mode=ParseMode.MARKDOWN
        )



async def experience_command(
    update: Update, context: ContextTypes.DEFAULT_TYPE
) -> None:
    """–ö—Ä–∞—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞ –ª–∏—á–Ω–æ—Å—Ç–∏ –∏ –æ–ø—ã—Ç–∞."""
    await show_typing(update, context)
    data = neira_wrapper.get_experience()
    if "error" in data:
        await update.message.reply_text(f"–ù–µ–¥–æ—Å—Ç—É–ø–Ω–æ: {data['error']}")
        return

    personality = data.get("personality", {})
    stats = data.get("stats", {})

    lines = [
        f"–õ–∏—á–Ω–æ—Å—Ç—å: {personality.get('name', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')} "
        f"(v{personality.get('version', 'N/A')})",
        f"–û–ø—ã—Ç–æ–≤: {stats.get('total', 0)}, —Å—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ {stats.get('avg_score', 0)}",
    ]

    strengths = personality.get("strengths") or []
    if strengths:
        lines.append("–°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã: " + ", ".join(strengths[:5]))

    weaknesses = personality.get("weaknesses") or []
    if weaknesses:
        lines.append("–°–ª–µ–ø—ã–µ –∑–æ–Ω—ã: " + ", ".join(weaknesses[:5]))

    await update.message.reply_text("\n".join(lines))


@require_auth
async def clear_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–°–±—Ä–∞—Å—ã–≤–∞–µ—Ç –ø–∞–º—è—Ç—å Neira (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö)."""
    user_id = update.effective_user.id
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞—â–∏—Ç–∞ - —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω –º–æ–∂–µ—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—á–∏—Å—Ç–∏—Ç—å –ø–∞–º—è—Ç—å
    if not is_admin(user_id):
        await update.message.reply_text("‚õî –ü–æ–ª–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É.")
        return
    
    await show_typing(update, context)
    result = neira_wrapper.clear_memory()
    status = result.get("status", "error")
    msg = result.get("message", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞")
    if status == "success":
        await update.message.reply_text("üóëÔ∏è –ü–∞–º—è—Ç—å –æ—á–∏—â–µ–Ω–∞.")
    else:
        await update.message.reply_text(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—á–∏—Å—Ç–∏—Ç—å –ø–∞–º—è—Ç—å: {msg}")


async def learn_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –æ–±—É—á–µ–Ω–∏–µ –ø–æ —Ç–µ–º–µ."""
    topic = " ".join(context.args).strip() if context.args else ""
    if not topic:
        await update.message.reply_text("üìñ –£–∫–∞–∂–∏—Ç–µ —Ç–µ–º—É: /learn <—Ç–µ–º–∞>")
        return

    await show_typing(update, context)
    async with processing_lock:
        try:
            result = neira_wrapper.neira.cmd_learn(topic)
            for chunk in split_message(result):
                await update.message.reply_text(chunk)
        except Exception as exc:
            logging.exception("–û—à–∏–±–∫–∞ –≤ /learn")
            await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞: {exc}")


# === –ö–æ–º–∞–Ω–¥—ã –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ ===
async def auth_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    global _ADMIN_ID
    
    if not context.args or len(context.args) < 2:
        await update.message.reply_text("üîê –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /auth 0 <–ø–∞—Ä–æ–ª—å>")
        return
    
    login = context.args[0]
    password = context.args[1]
    user_id = update.effective_user.id
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–æ–≥–∏–Ω "0" –∏ –ø–∞—Ä–æ–ª—å –∏–∑ .env
    if login == "0":
        attempt_hash = hashlib.sha256(password.encode()).hexdigest()
        
        if secrets.compare_digest(attempt_hash, _ADMIN_HASH):
            _ADMIN_ID = user_id
            AUTHORIZED_USERS.add(user_id)
            await update.message.reply_text(
                "üëë –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å, –ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä!\n"
                "–¢—ã –ø–æ–ª—É—á–∏–ª –ø–æ–ª–Ω—ã–π –¥–æ—Å—Ç—É–ø –∫ –ù–µ–π—Ä–µ.\n\n"
                "–ò—Å–ø–æ–ª—å–∑—É–π /admin –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è."
            )
            # –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –ø–∞—Ä–æ–ª–µ–º –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
            try:
                await update.message.delete()
            except:
                pass
            logging.info(f"Admin authorized: user_id={user_id}")
        else:
            await update.message.reply_text("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –ø–∞—Ä–æ–ª—å.")
            logging.warning(f"Failed auth attempt from user_id={user_id}")
    else:
        await update.message.reply_text("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –ª–æ–≥–∏–Ω.")
        logging.warning(f"Failed auth attempt with wrong login: {login}")


def escape_markdown(text: str) -> str:
    """–≠–∫—Ä–∞–Ω–∏—Ä—É–µ—Ç —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã Markdown."""
    special_chars = ['_', '*', '[', ']', '(', ')', '~', '`', '>', '#', '+', '-', '=', '|', '{', '}', '.', '!']
    for char in special_chars:
        text = text.replace(char, f'\\{char}')
    return text


# === –ö–æ–º–∞–Ω–¥—ã —Å–∞–º–æ—Å–æ–∑–Ω–∞–Ω–∏—è ===
async def self_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ü–æ–∫–∞–∑–∞—Ç—å —Å–∞–º–æ–æ–ø–∏—Å–∞–Ω–∏–µ –ù–µ–π—Ä—ã."""
    await show_typing(update, context)
    
    try:
        description = neira_wrapper.get_self_description()
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –±–µ–∑ Markdown —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –æ—à–∏–±–æ–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞
        await update.message.reply_text(f"üß† –ö—Ç–æ —è —Ç–∞–∫–∞—è?\n\n{description}")
    except Exception as e:
        logging.exception("–û—à–∏–±–∫–∞ –≤ /self")
        await update.message.reply_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ")


async def organs_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ü–æ–∫–∞–∑–∞—Ç—å –æ—Ä–≥–∞–Ω—ã –ù–µ–π—Ä—ã."""
    await show_typing(update, context)
    
    try:
        result = neira_wrapper.get_organs()
        
        if "error" in result:
            await update.message.reply_text(f"‚ùå {result['error']}")
            return
        
        organs = result.get("organs", {})
        by_status = result.get("by_status", {})
        
        lines = [f"üß¨ –ú–æ–∏ –æ—Ä–≥–∞–Ω—ã ({result.get('total', 0)} –≤—Å–µ–≥–æ):\n"]
        lines.append(f"‚úÖ –ê–∫—Ç–∏–≤–Ω—ã—Ö: {by_status.get('active', 0)}")
        lines.append(f"üå± –†–∞—Å—Ç—É—â–∏—Ö: {by_status.get('growing', 0)}")
        lines.append(f"üí§ –°–ø—è—â–∏—Ö: {by_status.get('dormant', 0)}\n")
        
        for key, organ in organs.items():
            status_emoji = {"active": "‚úÖ", "growing": "üå±", "dormant": "üí§"}.get(organ.get("status", ""), "‚ùì")
            lines.append(f"{status_emoji} {organ.get('name', key)} ‚Äî {organ.get('description', '–Ω–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è')[:50]}")
        
        await update.message.reply_text("\n".join(lines))
    except Exception as e:
        logging.exception("–û—à–∏–±–∫–∞ –≤ /organs")
        await update.message.reply_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –æ—Ä–≥–∞–Ω–æ–≤")


async def grow_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ü–æ–∫–∞–∑–∞—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Ä–æ—Å—Ç–∞."""
    await show_typing(update, context)
    
    try:
        growth = neira_wrapper.get_growth_capabilities()
        
        if "error" in growth:
            await update.message.reply_text(f"‚ùå {growth['error']}")
            return
        
        lines = ["üå± –ö–∞–∫ –º–Ω–µ —Ä–∞—Å—Ç–∏?\n"]
        
        capabilities = growth.get("capabilities", {})
        
        if isinstance(capabilities, dict):
            if "current_abilities" in capabilities:
                lines.append("–¢–µ–∫—É—â–∏–µ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏:")
                for ability in capabilities["current_abilities"][:5]:
                    lines.append(f"  ‚Ä¢ {ability}")
            
            if "potential_growth" in capabilities:
                lines.append("\n–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª —Ä–æ—Å—Ç–∞:")
                for potential in capabilities["potential_growth"][:5]:
                    lines.append(f"  üåø {potential}")
            
            if "how_to_grow" in capabilities:
                lines.append(f"\n–ö–∞–∫ –ø–æ–º–æ—á—å:\n{capabilities['how_to_grow']}")
        else:
            lines.append(str(capabilities))
        
        lines.append(f"\nüè≠ Cell Factory: {'‚úÖ' if growth.get('cell_factory_available') else '‚ùå'}")
        
        await update.message.reply_text("\n".join(lines))
    except Exception as e:
        logging.exception("–û—à–∏–±–∫–∞ –≤ /grow")
        await update.message.reply_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–æ—Å—Ç–µ")


@require_auth
async def code_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ö–æ–º–∞–Ω–¥—ã —Ä–∞–±–æ—Ç—ã —Å –∫–æ–¥–æ–º (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞)."""
    user_id = update.effective_user.id
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞
    if not is_admin(user_id):
        await update.message.reply_text("‚õî –ö–æ–º–∞–Ω–¥–∞ /code –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É.")
        return
    
    if not context.args:
        await update.message.reply_text(
            "üíª *–ö–æ–º–∞–Ω–¥—ã –∫–æ–¥–∞:*\n"
            "/code list ‚Äî —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤\n"
            "/code read <—Ñ–∞–π–ª> ‚Äî –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª",
            parse_mode=ParseMode.MARKDOWN
        )
        return
    
    action = context.args[0].lower()
    await show_typing(update, context)
    
    try:
        if action == "list":
            result = neira_wrapper.neira.cmd_code("list")
            await update.message.reply_text(f"üìÅ {result}")
        
        elif action == "read" and len(context.args) > 1:
            filename = context.args[1]
            result = neira_wrapper.neira.cmd_code("read", filename)
            for chunk in split_message(result, limit=4000):
                await update.message.reply_text(f"```\n{chunk}\n```", parse_mode=ParseMode.MARKDOWN)
        
        else:
            await update.message.reply_text("‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞")
    except Exception as e:
        logging.exception("–û—à–∏–±–∫–∞ –≤ /code")
        await update.message.reply_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –æ–ø–µ—Ä–∞—Ü–∏—é —Å —Ñ–∞–π–ª–æ–º")


# === –ö–æ–º–∞–Ω–¥—ã —Ä–∞–±–æ—Ç—ã —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ ===
@require_auth
async def imagine_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é."""
    prompt = " ".join(context.args).strip() if context.args else ""
    if not prompt:
        await update.message.reply_text(
            "üé® *–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π*\n\n"
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: `/imagine <–æ–ø–∏—Å–∞–Ω–∏–µ>`\n\n"
            "–ü—Ä–∏–º–µ—Ä—ã:\n"
            "‚Ä¢ `/imagine –∫—Ä–∞—Å–∏–≤—ã–π –∑–∞–∫–∞—Ç –Ω–∞–¥ –º–æ—Ä–µ–º`\n"
            "‚Ä¢ `/imagine –∫–∏–±–µ—Ä–ø–∞–Ω–∫ –≥–æ—Ä–æ–¥ –Ω–æ—á—å—é`\n"
            "‚Ä¢ `/imagine –º–∏–ª—ã–π –∫–æ—Ç—ë–Ω–æ–∫ –≤ —à–ª—è–ø–µ`",
            parse_mode=ParseMode.MARKDOWN
        )
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å SD
    sd_available = await check_sd_available()
    if not sd_available:
        await update.message.reply_text(
            "‚ùå Stable Diffusion –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.\n\n"
            "–î–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω—É–∂–Ω–æ:\n"
            "1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å AUTOMATIC1111 WebUI\n"
            "2. –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å —Ñ–ª–∞–≥–æ–º `--api`\n"
            "3. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é API –Ω–∞ http://127.0.0.1:7860"
        )
        return
    
    status_msg = await update.message.reply_text("üé® –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")
    
    try:
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ —Ä–∞–±–æ—Ç–∞–µ–º
        await context.bot.send_chat_action(
            chat_id=update.effective_chat.id,
            action=ChatAction.UPLOAD_PHOTO
        )
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º
        image_bytes = await generate_image_sd(prompt)
        
        if image_bytes:
            await status_msg.delete()
            await update.message.reply_photo(
                photo=io.BytesIO(image_bytes),
                caption=f"üé® *{prompt[:100]}*",
                parse_mode=ParseMode.MARKDOWN
            )
        else:
            await status_msg.edit_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.")
    except Exception as e:
        await status_msg.edit_text(f"‚ùå –û—à–∏–±–∫–∞: {e}")


@require_auth
async def photo_handler(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ö–æ–¥—è—â–∏—Ö —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π ‚Äî –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ vision –º–æ–¥–µ–ª—å."""
    if not update.message or not update.message.photo:
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å vision –º–æ–¥–µ–ª–∏
    vision_available = await check_vision_model()
    if not vision_available:
        await update.message.reply_text(
            "‚ùå Vision –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.\n\n"
            "–î–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω—É–∂–Ω–æ:\n"
            "1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –º–æ–¥–µ–ª—å: `ollama pull llava:7b`\n"
            "2. –ò–ª–∏ –¥—Ä—É–≥—É—é vision –º–æ–¥–µ–ª—å (llava, bakllava, etc.)"
        )
        return
    
    # –ü–æ–ª—É—á–∞–µ–º –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ —Ñ–æ—Ç–æ
    photo = update.message.photo[-1]  # –ü–æ—Å–ª–µ–¥–Ω–µ–µ = –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ
    
    status_msg = await update.message.reply_text("üëÅÔ∏è –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")
    
    try:
        await show_typing(update, context)
        
        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–æ—Ç–æ
        file = await context.bot.get_file(photo.file_id)
        photo_bytes = await file.download_as_bytearray()
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ base64
        image_base64 = base64.b64encode(photo_bytes).decode('utf-8')
        
        # –ü–æ–ª—É—á–∞–µ–º caption –∫–∞–∫ prompt, –∏–ª–∏ –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π
        caption = update.message.caption or ""
        if caption:
            prompt = f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç: {caption}\n\n–û—Ç–≤–µ—Ç—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏."
        else:
            prompt = "–û–ø–∏—à–∏ —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–¥—Ä–æ–±–Ω–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. –ß—Ç–æ —Ç—ã –≤–∏–¥–∏—à—å? –ö–∞–∫–∏–µ –¥–µ—Ç–∞–ª–∏ –≤–∞–∂–Ω—ã?"
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º
        result = await analyze_image_with_ollama(image_base64, prompt)
        
        await status_msg.delete()
        for chunk in split_message(result):
            await update.message.reply_text(chunk)
            
    except Exception as e:
        logging.exception("–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ñ–æ—Ç–æ")
        await status_msg.edit_text(f"‚ùå –û—à–∏–±–∫–∞: {e}")


async def vision_status_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º —Ä–∞–±–æ—Ç—ã —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏."""
    await show_typing(update, context)
    
    vision_ok = await check_vision_model()
    sd_ok = await check_sd_available()
    
    lines = [
        "üñºÔ∏è *–°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:*\n",
        f"üëÅÔ∏è Vision (–∞–Ω–∞–ª–∏–∑): {'‚úÖ ' + VISION_MODEL if vision_ok else '‚ùå –ù–µ–¥–æ—Å—Ç—É–ø–Ω–∞'}",
        f"üé® Stable Diffusion (–≥–µ–Ω–µ—Ä–∞—Ü–∏—è): {'‚úÖ –î–æ—Å—Ç—É–ø–Ω–∞' if sd_ok else '‚ùå –ù–µ–¥–æ—Å—Ç—É–ø–Ω–∞'}",
        "\n*–ö–æ–º–∞–Ω–¥—ã:*",
        "‚Ä¢ –û—Ç–ø—Ä–∞–≤—å —Ñ–æ—Ç–æ ‚Äî –∞–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è",
        "‚Ä¢ `/imagine <–æ–ø–∏—Å–∞–Ω–∏–µ>` ‚Äî –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–∞—Ä—Ç–∏–Ω–∫–∏",
    ]
    
    if not vision_ok:
        lines.append("\nüí° –£—Å—Ç–∞–Ω–æ–≤–∏ vision: `ollama pull llava:7b`")
    if not sd_ok:
        lines.append("\nüí° –ó–∞–ø—É—Å—Ç–∏ SD WebUI —Å `--api` —Ñ–ª–∞–≥–æ–º")
    
    await update.message.reply_text("\n".join(lines), parse_mode=ParseMode.MARKDOWN)


# === –ê–¥–º–∏–Ω-–∫–æ–º–∞–Ω–¥—ã ===
async def admin_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ê–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å."""
    global ACCESS_MODE
    
    user_id = update.effective_user.id
    if not is_admin(user_id):
        await update.message.reply_text("‚õî –¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞.")
        return
    
    if not context.args:
        # –ü–æ–∫–∞–∑–∞—Ç—å –º–µ–Ω—é
        keyboard = [
            [InlineKeyboardButton("üë• –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏", callback_data="admin_users")],
            [InlineKeyboardButton("üì¢ –ö–∞–Ω–∞–ª—ã", callback_data="admin_channels")],
            [InlineKeyboardButton("üîì Open", callback_data="admin_mode_open"),
             InlineKeyboardButton("üìã Whitelist", callback_data="admin_mode_whitelist"),
             InlineKeyboardButton("üëë Admin Only", callback_data="admin_mode_admin_only")],
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        await update.message.reply_text(
            f"üëë *–ê–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å*\n\n"
            f"–†–µ–∂–∏–º –¥–æ—Å—Ç—É–ø–∞: `{ACCESS_MODE}`\n"
            f"–ê–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–æ: {len(AUTHORIZED_USERS)} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n"
            f"–ö–∞–Ω–∞–ª–æ–≤/–≥—Ä—É–ø–ø: {len(ALLOWED_CHANNELS)}",
            reply_markup=reply_markup,
            parse_mode=ParseMode.MARKDOWN
        )
        return
    
    action = context.args[0].lower()
    
    if action == "users":
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ–±–µ —Å–∏—Å—Ç–µ–º—ã –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
        old_users_list = "\n".join(f"  ‚Ä¢ `{uid}` (—Å—Ç–∞—Ä–∞—è —Å–∏—Å—Ç–µ–º–∞)" for uid in AUTHORIZED_USERS) if AUTHORIZED_USERS else ""
        new_users = auth_system.get_all_users()
        new_users_list = "\n".join(
            f"  ‚Ä¢ `{u.user_id}`{' @' + u.username if u.username else ''} ‚Äî {u.name or '–±–µ–∑ –∏–º–µ–Ω–∏'}"
            for u in new_users
        ) if new_users else ""
        
        combined = f"{old_users_list}\n{new_users_list}".strip()
        if combined:
            await update.message.reply_text(
                f"üë• *–ê–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏:*\n{combined}",
                parse_mode=ParseMode.MARKDOWN
            )
        else:
            await update.message.reply_text("üì≠ –ù–µ—Ç –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π.")
    
    elif action == "channels":
        if ALLOWED_CHANNELS:
            channels_list = "\n".join(f"  ‚Ä¢ `{cid}`" for cid in ALLOWED_CHANNELS)
            await update.message.reply_text(
                f"üì¢ *–†–∞–∑—Ä–µ—à—ë–Ω–Ω—ã–µ –∫–∞–Ω–∞–ª—ã/–≥—Ä—É–ø–ø—ã:*\n{channels_list}",
                parse_mode=ParseMode.MARKDOWN
            )
        else:
            await update.message.reply_text("üì≠ –ù–µ—Ç —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤.")
    
    elif action == "add" and len(context.args) > 1:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—É—é —Å–∏—Å—Ç–µ–º—É –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
        identifier = " ".join(context.args[1:])
        try:
            user = auth_system.parse_user_identifier(identifier)
            if user:
                auth_system.add_user(user.user_id, user.username, user.name)
                username_part = f" (@{user.username})" if user.username else ""
                await update.message.reply_text(
                    f"‚úÖ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å `{user.user_id}`{username_part} –¥–æ–±–∞–≤–ª–µ–Ω.",
                    parse_mode=ParseMode.MARKDOWN
                )
            else:
                # Fallback –Ω–∞ —Å—Ç–∞—Ä—É—é —Å–∏—Å—Ç–µ–º—É (—á–∏—Å–ª–æ–≤–æ–π user_id)
                new_user_id = int(context.args[1])
                AUTHORIZED_USERS.add(new_user_id)
                await update.message.reply_text(
                    f"‚úÖ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å `{new_user_id}` –¥–æ–±–∞–≤–ª–µ–Ω (—Å—Ç–∞—Ä–∞—è —Å–∏—Å—Ç–µ–º–∞).",
                    parse_mode=ParseMode.MARKDOWN
                )
        except (ValueError, Exception) as e:
            await update.message.reply_text(
                f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {str(e)}\n"
                f"–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ: user_id, @username –∏–ª–∏ t.me/username"
            )
    
    elif action == "addchannel" and len(context.args) > 1:
        try:
            channel_id = int(context.args[1])
            ALLOWED_CHANNELS.add(channel_id)
            await update.message.reply_text(f"‚úÖ –ö–∞–Ω–∞–ª/–≥—Ä—É–ø–ø–∞ `{channel_id}` –¥–æ–±–∞–≤–ª–µ–Ω.", parse_mode=ParseMode.MARKDOWN)
        except ValueError:
            await update.message.reply_text("‚ùå ID –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —á–∏—Å–ª–æ–º (—Å –º–∏–Ω—É—Å–æ–º –¥–ª—è –≥—Ä—É–ø–ø).")
    
    elif action == "remove" and len(context.args) > 1:
        try:
            remove_id = int(context.args[1])
            AUTHORIZED_USERS.discard(remove_id)
            await update.message.reply_text(f"üóëÔ∏è –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å `{remove_id}` —É–¥–∞–ª—ë–Ω.", parse_mode=ParseMode.MARKDOWN)
        except ValueError:
            await update.message.reply_text("‚ùå user_id –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —á–∏—Å–ª–æ–º.")
    
    elif action == "removechannel" and len(context.args) > 1:
        try:
            channel_id = int(context.args[1])
            ALLOWED_CHANNELS.discard(channel_id)
            await update.message.reply_text(f"üóëÔ∏è –ö–∞–Ω–∞–ª/–≥—Ä—É–ø–ø–∞ `{channel_id}` —É–¥–∞–ª—ë–Ω.", parse_mode=ParseMode.MARKDOWN)
        except ValueError:
            await update.message.reply_text("‚ùå ID –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —á–∏—Å–ª–æ–º.")
    
    elif action == "thisgroup":
        chat_id = update.effective_chat.id
        chat_type = update.effective_chat.type
        if chat_type in ("group", "supergroup", "channel"):
            ALLOWED_CHANNELS.add(chat_id)
            await update.message.reply_text(
                f"‚úÖ –≠—Ç–æ—Ç —á–∞—Ç –¥–æ–±–∞–≤–ª–µ–Ω –≤ —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã–µ!\n"
                f"ID: `{chat_id}`",
                parse_mode=ParseMode.MARKDOWN
            )
        else:
            await update.message.reply_text("‚ùå –≠—Ç–∞ –∫–æ–º–∞–Ω–¥–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ –≤ –≥—Ä—É–ø–ø–∞—Ö/–∫–∞–Ω–∞–ª–∞—Ö.")
    
    elif action == "mode" and len(context.args) > 1:
        new_mode = context.args[1].lower()
        if new_mode in ("open", "whitelist", "admin_only"):
            ACCESS_MODE = new_mode
            await update.message.reply_text(f"‚úÖ –†–µ–∂–∏–º –¥–æ—Å—Ç—É–ø–∞: `{ACCESS_MODE}`", parse_mode=ParseMode.MARKDOWN)
        else:
            await update.message.reply_text("‚ùå –†–µ–∂–∏–º: open, whitelist –∏–ª–∏ admin_only")
    
    elif action == "stats":
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è
        stats = parallel_mind.get_stats()
        lines = [
            "üìä *–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è:*\n",
            f"üó®Ô∏è –ê–∫—Ç–∏–≤–Ω—ã—Ö —á–∞—Ç–æ–≤: {stats['total_contexts']}",
            f"üí¨ –í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {stats['total_messages']}",
            f"üë• –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {stats['unique_users']}",
        ]
        
        if stats['contexts']:
            lines.append("\n*–¢–æ–ø-5 –∞–∫—Ç–∏–≤–Ω—ã—Ö —á–∞—Ç–æ–≤:*")
            for i, ctx_info in enumerate(stats['contexts'][:5], 1):
                username_part = f" (@{ctx_info['username']})" if ctx_info.get('username') else ""
                lines.append(
                    f"{i}. Chat `{ctx_info['chat_id']}`{username_part} ‚Äî "
                    f"{ctx_info['message_count']} —Å–æ–æ–±—â–µ–Ω–∏–π"
                )
        
        await update.message.reply_text("\n".join(lines), parse_mode=ParseMode.MARKDOWN)
    
    else:
        await update.message.reply_text(
            "‚ùì *–ö–æ–º–∞–Ω–¥—ã:*\n"
            "/admin users ‚Äî —Å–ø–∏—Å–æ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n"
            "/admin channels ‚Äî —Å–ø–∏—Å–æ–∫ –∫–∞–Ω–∞–ª–æ–≤\n"
            "/admin add <identifier> ‚Äî –¥–æ–±–∞–≤–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n"
            "/admin addchannel <id> ‚Äî –¥–æ–±–∞–≤–∏—Ç—å –∫–∞–Ω–∞–ª\n"
            "/admin remove <id> ‚Äî —É–¥–∞–ª–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n"
            "/admin removechannel <id> ‚Äî —É–¥–∞–ª–∏—Ç—å –∫–∞–Ω–∞–ª\n"
            "/admin thisgroup ‚Äî –¥–æ–±–∞–≤–∏—Ç—å —ç—Ç–æ—Ç —á–∞—Ç\n"
            "/admin mode <—Ä–µ–∂–∏–º> ‚Äî –∏–∑–º–µ–Ω–∏—Ç—å —Ä–µ–∂–∏–º\n"
            "/admin stats ‚Äî —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è",
            parse_mode=ParseMode.MARKDOWN
        )


async def admin_callback(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞–∂–∞—Ç–∏–π –≤ –∞–¥–º–∏–Ω-–ø–∞–Ω–µ–ª–∏."""
    global ACCESS_MODE
    
    query = update.callback_query
    user_id = query.from_user.id
    
    if not is_admin(user_id):
        await query.answer("‚õî –¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞", show_alert=True)
        return
    
    await query.answer()
    data = query.data
    
    if data == "admin_users":
        if AUTHORIZED_USERS:
            users_list = "\n".join(f"  ‚Ä¢ `{uid}`" for uid in AUTHORIZED_USERS)
            text = f"üë• *–ê–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ:*\n{users_list}"
        else:
            text = "üì≠ –ù–µ—Ç –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π."
        await query.edit_message_text(text, parse_mode=ParseMode.MARKDOWN)
    
    elif data == "admin_channels":
        if ALLOWED_CHANNELS:
            channels_list = "\n".join(f"  ‚Ä¢ `{cid}`" for cid in ALLOWED_CHANNELS)
            text = f"üì¢ *–†–∞–∑—Ä–µ—à—ë–Ω–Ω—ã–µ –∫–∞–Ω–∞–ª—ã/–≥—Ä—É–ø–ø—ã:*\n{channels_list}"
        else:
            text = "üì≠ –ù–µ—Ç —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤."
        await query.edit_message_text(text, parse_mode=ParseMode.MARKDOWN)
    
    elif data.startswith("admin_mode_"):
        new_mode = data.replace("admin_mode_", "")
        ACCESS_MODE = new_mode
        await query.edit_message_text(
            f"‚úÖ –†–µ–∂–∏–º –¥–æ—Å—Ç—É–ø–∞ –∏–∑–º–µ–Ω—ë–Ω: `{ACCESS_MODE}`",
            parse_mode=ParseMode.MARKDOWN
        )


async def create_organ_background(update: Update, organ_description: str) -> None:
    """–§–æ–Ω–æ–≤–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –æ—Ä–≥–∞–Ω–∞ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏."""
    try:
        from experience import ExperienceSystem
        
        user_id = update.effective_user.id
        exp_system = ExperienceSystem()
        factory = CellFactory(experience=exp_system)
        
        await update.message.reply_text(
            "üß¨ –ù–∞—á–∏–Ω–∞—é —Å–æ–∑–¥–∞–≤–∞—Ç—å –Ω–æ–≤—ã–π –æ—Ä–≥–∞–Ω...\n"
            "üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏."
        )
        
        # –°–æ–∑–¥–∞–µ–º –æ—Ä–≥–∞–Ω —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
        result = factory.create_cell(
            pattern=organ_description,
            tasks=[{"description": organ_description, "status": "planned"}],
            author_id=user_id
        )
        
        if result.get("success"):
            # ‚úÖ –ë–ï–ó–û–ü–ê–°–ù–´–ô –û–†–ì–ê–ù
            cell = result["cell"]
            await update.message.reply_text(
                f"‚úÖ **–û—Ä–≥–∞–Ω —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ!**\n\n"
                f"üìù –ù–∞–∑–≤–∞–Ω–∏–µ: {cell.cell_name}\n"
                f"üìÑ –§–∞–π–ª: {cell.file_path}\n"
                f"üéØ –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ: {cell.description}\n\n"
                f"üí° –Ø –Ω–∞—É—á–∏–ª–∞—Å—å —Å–æ–∑–¥–∞–≤–∞—Ç—å –∫–æ–¥ –¥–ª—è —Å–µ–±—è!",
                parse_mode=ParseMode.MARKDOWN
            )
        
        elif result.get("quarantined"):
            # üîç –í –ö–ê–†–ê–ù–¢–ò–ù–ï
            threat = result["threat_level"]
            organ_id = result.get("organ_id")
            
            if threat == "dangerous":
                msg = (
                    f"‚ö†Ô∏è **–û—Ä–≥–∞–Ω —Ç—Ä–µ–±—É–µ—Ç –æ–¥–æ–±—Ä–µ–Ω–∏—è**\n\n"
                    f"–û—Ä–≥–∞–Ω —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –æ–ø–∞—Å–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏.\n"
                    f"ID: `{organ_id}`\n\n"
                    f"–ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä –º–æ–∂–µ—Ç –æ–¥–æ–±—Ä–∏—Ç—å:\n"
                    f"`/organs approve {organ_id}`"
                )
            else:
                msg = (
                    f"üîç **–û—Ä–≥–∞–Ω –≤ 24-—á–∞—Å–æ–≤–æ–º –∫–∞—Ä–∞–Ω—Ç–∏–Ω–µ**\n\n"
                    f"–û—Ä–≥–∞–Ω –±—É–¥–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω —á–µ—Ä–µ–∑ 24—á.\n"
                    f"ID: `{organ_id}`"
                )
            
            await update.message.reply_text(msg, parse_mode=ParseMode.MARKDOWN)
        
        else:
            # ‚ùå –ó–ê–ë–õ–û–ö–ò–†–û–í–ê–ù
            error = result.get("error", "–û—Ä–≥–∞–Ω —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–ø–∞—Å–Ω—ã–π –∫–æ–¥")
            await update.message.reply_text(f"‚ùå {error}")
    
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ä–≥–∞–Ω–∞: {e}")
        await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –æ—Ä–≥–∞–Ω–∞")


# === –ê–≤—Ç–æ–Ω–æ–º–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ ===
@require_auth
async def learn_auto_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–º –æ–±—É—á–µ–Ω–∏–µ–º Neira.
    
    –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    /learn_auto start - –∑–∞–ø—É—Å—Ç–∏—Ç—å —Ñ–æ–Ω–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ
    /learn_auto stop - –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å
    /learn_auto stats - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    /learn_auto quarantine - –ø–æ–∫–∞–∑–∞—Ç—å –∫–∞—Ä–∞–Ω—Ç–∏–Ω
    /learn_auto approve <id> - –æ–¥–æ–±—Ä–∏—Ç—å –∏–∑ –∫–∞—Ä–∞–Ω—Ç–∏–Ω–∞
    /learn_auto reject <id> - –æ—Ç–∫–ª–æ–Ω–∏—Ç—å
    """
    global autonomous_learning_system
    
    if not context.args:
        await update.message.reply_text(
            "üéì *–ê–≤—Ç–æ–Ω–æ–º–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ Neira v1.0*\n\n"
            "*–ö–æ–º–∞–Ω–¥—ã:*\n"
            "  `/learn_auto start` - –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ñ–æ–Ω–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ\n"
            "  `/learn_auto stop` - –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å\n"
            "  `/learn_auto stats` - –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n"
            "  `/learn_auto quarantine` - –ö–∞—Ä–∞–Ω—Ç–∏–Ω (–æ–∂–∏–¥–∞—é—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏)\n"
            "  `/learn_auto approve <id>` - –û–¥–æ–±—Ä–∏—Ç—å —Ñ–∞–∫—Ç\n"
            "  `/learn_auto reject <id>` - –û—Ç–∫–ª–æ–Ω–∏—Ç—å —Ñ–∞–∫—Ç\n\n"
            "*–ó–∞—â–∏—Ç–∞ –æ—Ç –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π:*\n"
            "  ‚úÖ Whitelist –Ω–∞–¥—ë–∂–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤\n"
            "  ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è\n"
            "  ‚úÖ –ö–∞—Ä–∞–Ω—Ç–∏–Ω –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º\n"
            "  ‚úÖ –ü–∞—Ç—Ç–µ—Ä–Ω—ã –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π\n"
            "  ‚úÖ –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ confidence (70%)\n\n"
            "*–ò—Å—Ç–æ—á–Ω–∏–∫–∏:*\n"
            "  ‚Ä¢ Wikipedia (ru/en) - 90%\n"
            "  ‚Ä¢ Python.org - 100%\n"
            "  ‚Ä¢ arXiv.org - 90%\n"
            "  ‚Ä¢ GitHub README - 90%\n",
            parse_mode=ParseMode.MARKDOWN
        )
        return
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º—É –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏
    if autonomous_learning_system is None:
        memory_ref = getattr(neira_wrapper.neira, "memory", None)
        if memory_ref is None:
            await update.message.reply_text("‚ö†Ô∏è –ü–∞–º—è—Ç—å Neira –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–µ –∑–∞–ø—É—â–µ–Ω–æ.")
            return
        autonomous_learning_system = AutonomousLearningSystem(
            memory_system=memory_ref,
            idle_threshold_minutes=30,
            admin_telegram_id=_ADMIN_ID
        )
        logging.info("‚úÖ Autonomous Learning System –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    action = context.args[0].lower()
    
    if action == "start":
        if autonomous_learning_system.running:
            await update.message.reply_text("‚ö†Ô∏è –û–±—É—á–µ–Ω–∏–µ —É–∂–µ –∑–∞–ø—É—â–µ–Ω–æ")
            return
        
        await autonomous_learning_system.start_autonomous_learning()
        await update.message.reply_text(
            "üéì *–ê–≤—Ç–æ–Ω–æ–º–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∑–∞–ø—É—â–µ–Ω–æ!*\n\n"
            "–ë—É–¥—É —É—á–∏—Ç—å—Å—è –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ –∫–æ–≥–¥–∞ –Ω–µ –∑–∞–Ω—è—Ç–∞ –¥–∏–∞–ª–æ–≥–∞–º–∏.\n"
            "–í—Å–µ –Ω–æ–≤—ã–µ –∑–Ω–∞–Ω–∏—è –ø—Ä–æ—Ö–æ–¥—è—Ç –ø—Ä–æ–≤–µ—Ä–∫—É –∏ –∫–∞—Ä–∞–Ω—Ç–∏–Ω.\n\n"
            "–ò—Å–ø–æ–ª—å–∑—É–π `/learn_auto stats` –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏.",
            parse_mode=ParseMode.MARKDOWN
        )
    
    elif action == "stop":
        if not autonomous_learning_system.running:
            await update.message.reply_text("‚ö†Ô∏è –û–±—É—á–µ–Ω–∏–µ –Ω–µ –∑–∞–ø—É—â–µ–Ω–æ")
            return
        
        await autonomous_learning_system.stop_autonomous_learning()
        stats = autonomous_learning_system.get_learning_stats()
        
        await update.message.reply_text(
            f"üõë *–ê–≤—Ç–æ–Ω–æ–º–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ*\n\n"
            f"üìä –ò—Ç–æ–≥–∏:\n"
            f"  ‚Ä¢ –°–µ—Å—Å–∏–π: {stats['learning_sessions']}\n"
            f"  ‚Ä¢ –ò–∑—É—á–µ–Ω–æ —Ñ–∞–∫—Ç–æ–≤: {stats['facts_learned']}\n"
            f"  ‚Ä¢ –û—Ç–∫–ª–æ–Ω–µ–Ω–æ: {stats['facts_rejected']}\n"
            f"  ‚Ä¢ –í –∫–∞—Ä–∞–Ω—Ç–∏–Ω–µ: {stats['quarantine']['total']}",
            parse_mode=ParseMode.MARKDOWN
        )
    
    elif action == "stats":
        stats = autonomous_learning_system.get_learning_stats()
        q = stats['quarantine']
        
        status_emoji = "üèÉ" if stats['running'] else "‚è∏Ô∏è"
        idle_status = "üí§ –í —Ä–µ–∂–∏–º–µ –æ–∂–∏–¥–∞–Ω–∏—è" if stats['is_idle'] else f"üí¨ –ê–∫—Ç–∏–≤–Ω–∞ ({stats['idle_minutes']:.1f} –º–∏–Ω –¥–æ idle)"
        
        await update.message.reply_text(
            f"üìä *–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è*\n\n"
            f"{status_emoji} –°—Ç–∞—Ç—É—Å: {'–†–∞–±–æ—Ç–∞–µ—Ç' if stats['running'] else '–û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ'}\n"
            f"{idle_status}\n\n"
            f"*–û–±—É—á–µ–Ω–∏–µ:*\n"
            f"  ‚Ä¢ –°–µ—Å—Å–∏–π: {stats['learning_sessions']}\n"
            f"  ‚Ä¢ –ò–∑—É—á–µ–Ω–æ —Ñ–∞–∫—Ç–æ–≤: {stats['facts_learned']}\n"
            f"  ‚Ä¢ –û—Ç–∫–ª–æ–Ω–µ–Ω–æ: {stats['facts_rejected']}\n"
            f"  ‚Ä¢ –ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ: {stats['sources_checked']}\n\n"
            f"*–ö–∞—Ä–∞–Ω—Ç–∏–Ω:*\n"
            f"  ‚Ä¢ –í—Å–µ–≥–æ: {q['total']}\n"
            f"  ‚Ä¢ –û–∂–∏–¥–∞—é—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏: {q['pending']}\n"
            f"  ‚Ä¢ –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {q['high_confidence']}\n"
            f"  ‚Ä¢ –¢—Ä–µ–±—É—é—Ç —Ä–µ–≤—å—é: {q['needs_review']}\n\n"
            f"*–ó–∞—â–∏—Ç–∞:*\n"
            f"  ‚Ä¢ Whitelist: {stats['whitelist_sources']} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤\n"
            f"  ‚Ä¢ Blacklist: {stats['blacklist_patterns']} –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤\n"
            f"  ‚Ä¢ –û–¥–æ–±—Ä–µ–Ω–æ –∏–∑ –∫–∞—Ä–∞–Ω—Ç–∏–Ω–∞: {stats['quarantine_approved']}\n"
            f"  ‚Ä¢ –û—Ç–∫–ª–æ–Ω–µ–Ω–æ: {stats['quarantine_rejected']}",
            parse_mode=ParseMode.MARKDOWN
        )
    
    elif action == "quarantine":
        if not autonomous_learning_system.quarantine:
            await update.message.reply_text("üì≠ –ö–∞—Ä–∞–Ω—Ç–∏–Ω –ø—É—Å—Ç")
            return
        
        lines = [f"üî¨ *–ö–∞—Ä–∞–Ω—Ç–∏–Ω –∑–Ω–∞–Ω–∏–π ({len(autonomous_learning_system.quarantine)}):*\n"]
        
        for i, entry in enumerate(autonomous_learning_system.quarantine[:10], 1):
            text_preview = entry.text[:80] + "..." if len(entry.text) > 80 else entry.text
            conf_emoji = "‚úÖ" if entry.confidence >= 0.9 else "‚ö†Ô∏è"
            
            lines.append(
                f"{i}. {conf_emoji} [{entry.confidence:.0%}] `{entry.id}`\n"
                f"   {text_preview}\n"
                f"   üìç {entry.source_url[:50]}...\n"
            )
        
        if len(autonomous_learning_system.quarantine) > 10:
            lines.append(f"\n_...–∏ –µ—â—ë {len(autonomous_learning_system.quarantine) - 10}_")
        
        lines.append(
            f"\nüí° –ò—Å–ø–æ–ª—å–∑—É–π `/learn_auto approve <id>` –¥–ª—è –æ–¥–æ–±—Ä–µ–Ω–∏—è"
        )
        
        await update.message.reply_text("\n".join(lines), parse_mode=ParseMode.MARKDOWN)
    
    elif action == "approve":
        if len(context.args) < 2:
            await update.message.reply_text("‚ö†Ô∏è –£–∫–∞–∂–∏ ID –∑–∞–ø–∏—Å–∏: `/learn_auto approve <id>`", parse_mode=ParseMode.MARKDOWN)
            return
        
        entry_id = context.args[1]
        success = autonomous_learning_system.manual_approve(entry_id)
        
        if success:
            await update.message.reply_text(f"‚úÖ –§–∞–∫—Ç `{entry_id}` –æ–¥–æ–±—Ä–µ–Ω –∏ –¥–æ–±–∞–≤–ª–µ–Ω –≤ –ø–∞–º—è—Ç—å", parse_mode=ParseMode.MARKDOWN)
        else:
            await update.message.reply_text(f"‚ùå –ó–∞–ø–∏—Å—å —Å ID `{entry_id}` –Ω–µ –Ω–∞–π–¥–µ–Ω–∞", parse_mode=ParseMode.MARKDOWN)
    
    elif action == "reject":
        if len(context.args) < 2:
            await update.message.reply_text("‚ö†Ô∏è –£–∫–∞–∂–∏ ID –∑–∞–ø–∏—Å–∏: `/learn_auto reject <id>`", parse_mode=ParseMode.MARKDOWN)
            return
        
        entry_id = context.args[1]
        success = autonomous_learning_system.manual_reject(entry_id)
        
        if success:
            await update.message.reply_text(f"‚ùå –§–∞–∫—Ç `{entry_id}` –æ—Ç–∫–ª–æ–Ω—ë–Ω", parse_mode=ParseMode.MARKDOWN)
        else:
            await update.message.reply_text(f"‚ùå –ó–∞–ø–∏—Å—å —Å ID `{entry_id}` –Ω–µ –Ω–∞–π–¥–µ–Ω–∞", parse_mode=ParseMode.MARKDOWN)
    
    else:
        await update.message.reply_text(f"‚ùì –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞: {action}")


# === –û—Å–Ω–æ–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–æ–±—â–µ–Ω–∏–π ===
@require_auth
async def chat_handler(
    update: Update, context: ContextTypes.DEFAULT_TYPE
) -> None:
    """–û–±—â–∏–π –¥–∏–∞–ª–æ–≥ —Å Neira —Å –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º —Å—Ç–∞–¥–∏–π."""
    if not update.message or not update.message.text:
        return

    user_text = update.message.text.strip()
    user_name = update.effective_user.first_name or "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å"
    user_id = update.effective_user.id
    chat_id = update.effective_chat.id
    chat_type = update.effective_chat.type
    bot_username = context.bot.username
    
    # üéì –û—Ç–º–µ—á–∞–µ–º –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –¥–ª—è –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
    global autonomous_learning_system
    if autonomous_learning_system:
        autonomous_learning_system.mark_activity()
    
    # –í –≥—Ä—É–ø–ø–∞—Ö/–∫–∞–Ω–∞–ª–∞—Ö: –æ—Ç–≤–µ—á–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∏–ª–∏ —Ä–µ–ø–ª–∞–∏
    if chat_type in ("group", "supergroup", "channel"):
        is_reply_to_bot = (
            update.message.reply_to_message and 
            update.message.reply_to_message.from_user and
            update.message.reply_to_message.from_user.id == context.bot.id
        )
        is_mention = f"@{bot_username}" in user_text if bot_username else False
        
        if MENTION_ONLY and not is_reply_to_bot and not is_mention:
            return  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –±–µ–∑ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è
        
        # –£–±–∏—Ä–∞–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –∏–∑ —Ç–µ–∫—Å—Ç–∞
        if is_mention and bot_username:
            user_text = user_text.replace(f"@{bot_username}", "").strip()
    
    if not user_text:
        return
    
    # üß† –ü–ê–†–ê–õ–õ–ï–õ–¨–ù–û–ï –ú–´–®–õ–ï–ù–ò–ï: —Å–æ–∑–¥–∞–µ–º/–ø–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —á–∞—Ç–∞
    chat_context = parallel_mind.get_or_create_context(
        chat_id=chat_id,
        user_id=user_id,
        username=update.effective_user.username,
        first_name=update.effective_user.first_name
    )
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ auth_system –µ—Å–ª–∏ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω
    if user_id in AUTHORIZED_USERS or auth_system.is_authorized(user_id, update.effective_user.username):
        auth_system.update_user_info(user_id, update.effective_user.first_name)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
    parallel_mind.add_message(chat_id, "user", user_text)
    
    # üß† CORTEX v2.0: –ê–≤—Ç–æ–Ω–æ–º–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
    global neira_cortex
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∂–∏–º –æ–±—Ä–∞–±–æ—Ç–∫–∏
    use_cortex = (
        CORTEX_MODE == "always" or 
        (CORTEX_MODE == "auto" and CORTEX_AVAILABLE and neira_cortex)
    )
    
    if use_cortex and neira_cortex:
        # === –ù–û–í–´–ô –ü–£–¢–¨: Neira Cortex v2.0 ===
        try:
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–µ—Ä–µ–∑ Cortex
            result = neira_cortex.process(user_text, str(user_id))
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –º–µ—Ç–∞–∏–Ω—Ñ–æ
            strategy_emoji = {
                ResponseStrategy.NEURAL_PATHWAY: "‚ö°",
                ResponseStrategy.TEMPLATE: "üìã",
                ResponseStrategy.FRAGMENT_ASSEMBLY: "üß©",
                ResponseStrategy.RAG: "üìö",
                ResponseStrategy.LLM_CONSULTANT: "ü§ñ",
                ResponseStrategy.HYBRID: "üîÑ"
            }.get(result.strategy, "üîÆ")
            
            tier_info = f" [{result.pathway_tier.value}]" if result.pathway_tier else ""
            llm_marker = " +LLM" if result.llm_used else ""
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç
            full_response = result.response
            
            if full_response and full_response.strip():
                parts = split_message(full_response)
                for part in parts:
                    if part.strip():
                        await update.message.reply_text(part)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
                parallel_mind.add_message(chat_id, "assistant", full_response)
                
                # –ú–µ—Ç–∞–∏–Ω—Ñ–æ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –º–æ–∂–Ω–æ –æ—Ç–∫–ª—é—á–∏—Ç—å)
                if os.getenv("NEIRA_SHOW_CORTEX_INFO", "false") == "true":
                    meta_info = (
                        f"{strategy_emoji} {result.strategy.value}{tier_info} | "
                        f"{result.latency_ms:.0f}ms{llm_marker}"
                    )
                    await update.message.reply_text(
                        f"__{meta_info}__",
                        parse_mode=ParseMode.MARKDOWN
                    )
            else:
                await update.message.reply_text(
                    "ü§î –ò–∑–≤–∏–Ω–∏, –Ω–µ —Å–º–æ–≥–ª–∞ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç. –ü–æ–ø—Ä–æ–±—É–π –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å."
                )
            
            return
            
        except Exception as cortex_error:
            logging.warning(f"Cortex –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–≤–∞–ª–∏–ª–∞—Å—å: {cortex_error}, –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ legacy")
            # Fallback –Ω–∞ legacy —Ä–µ–∂–∏–º –Ω–∏–∂–µ
    
    # === LEGACY –ü–£–¢–¨: –ß–µ—Ä–µ–∑ NeiraWrapper ===
    
    # üÜï –î–ï–¢–ï–ö–¢ –¢–ï–ì–û–í –î–õ–Ø –°–û–ó–î–ê–ù–ò–Ø –û–†–ì–ê–ù–û–í
    organ_tags = ["#—Å–æ–∑–¥–∞–π_–æ—Ä–≥–∞–Ω", "#grow_organ", "#create_organ", "#–Ω–æ–≤—ã–π_–æ—Ä–≥–∞–Ω"]
    should_create_organ = any(tag in user_text.lower() for tag in organ_tags)
    
    if should_create_organ:
        # –£–±–∏—Ä–∞–µ–º —Ç–µ–≥–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        clean_text = user_text
        for tag in organ_tags:
            clean_text = clean_text.replace(tag, "").replace(tag.upper(), "")
        clean_text = clean_text.strip()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ –æ—Ä–≥–∞–Ω–∞ –≤ —Ñ–æ–Ω–µ
        asyncio.create_task(create_organ_background(update, clean_text))
        
        # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—ã—á–Ω—ã–π –¥–∏–∞–ª–æ–≥
        user_text = clean_text if clean_text else "–°–æ–∑–¥–∞–π –¥–ª—è –º–µ–Ω—è –Ω–æ–≤—ã–π –æ—Ä–≥–∞–Ω"
    
    status_msg = await update.message.reply_text("üîÑ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É...")

    async with processing_lock:
        try:
            last_stage = ""
            full_response = ""
            async for chunk in neira_wrapper.process_stream(user_text):
                if chunk.type == "stage":
                    stage_name = format_stage(chunk.stage)
                    if stage_name != last_stage:
                        emoji = {"–ê–Ω–∞–ª–∏–∑": "üîç", "–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ": "üìã", 
                                "–ò—Å–ø–æ–ª–Ω–µ–Ω–∏–µ": "‚ö°", "–ü—Ä–æ–≤–µ—Ä–∫–∞": "‚úÖ"}.get(stage_name, "‚öôÔ∏è")
                        await status_msg.edit_text(f"{emoji} {stage_name}...")
                        last_stage = stage_name
                    await show_typing(update, context)
                elif chunk.type == "content":
                    await status_msg.delete()
                    full_response = chunk.content
                    
                    # –ó–∞—â–∏—Ç–∞ –æ—Ç –ø—É—Å—Ç–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
                    if not chunk.content or not chunk.content.strip():
                        await update.message.reply_text("ü§î –ò–∑–≤–∏–Ω–∏, –Ω–µ —Å–º–æ–≥–ª–∞ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç. –ü–æ–ø—Ä–æ–±—É–π –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å.")
                        return
                    
                    parts = split_message(chunk.content)
                    for part in parts:
                        if part.strip():  # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–ø—É—Å—Ç—ã–µ —á–∞—Å—Ç–∏
                            await update.message.reply_text(part)
                elif chunk.type == "error":
                    await status_msg.edit_text(f"‚ùå –û—à–∏–±–∫–∞: {chunk.content}")
                    return
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç Neira –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
            if full_response:
                parallel_mind.add_message(chat_id, "assistant", full_response)

        except Exception as exc:
            logging.exception("–°–±–æ–π –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è")
            try:
                await status_msg.edit_text(f"‚ùå –û—à–∏–±–∫–∞: {exc}")
            except Exception:
                # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞: {exc}")


@require_auth
async def context_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ü–æ–∫–∞–∑–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ç–µ–∫—É—â–µ–≥–æ —á–∞—Ç–∞."""
    chat_id = update.effective_chat.id
    
    history = parallel_mind.get_context_history(chat_id)
    if not history:
        await update.message.reply_text("üì≠ –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ –ø—É—Å—Ç–∞.")
        return
    
    lines = ["üí¨ *–ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞:*\n"]
    for msg in history[-10:]:  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Å–æ–æ–±—â–µ–Ω–∏–π
        role_emoji = "üë§" if msg["role"] == "user" else "ü§ñ"
        content_preview = msg["content"][:100] + "..." if len(msg["content"]) > 100 else msg["content"]
        lines.append(f"{role_emoji} {content_preview}")
    
    await update.message.reply_text("\n".join(lines), parse_mode=ParseMode.MARKDOWN)


@require_auth
async def clear_context_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û—á–∏—Å—Ç–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ç–µ–∫—É—â–µ–≥–æ —á–∞—Ç–∞."""
    chat_id = update.effective_chat.id
    
    parallel_mind.clear_context(chat_id)
    await update.message.reply_text("üóëÔ∏è –ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ –æ—á–∏—â–µ–Ω!")


@require_auth
async def cortex_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ Neira Cortex v2.0
    
    /cortex - –æ–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    /cortex stats - –¥–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    /cortex pathways - —Å–ø–∏—Å–æ–∫ Neural Pathways
    /cortex test <—Ç–µ–∫—Å—Ç> - –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É
    """
    if not neira_cortex:
        await update.message.reply_text("‚ö†Ô∏è Neira Cortex –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        return
    
    if not context.args:
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = neira_cortex.get_stats()
        
        lines = [
            "üß† *Neira Cortex v2.0*\n",
            f"üìä –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {stats['total_requests']}",
            f"üéØ Neural Pathways: {stats['pathways']['total']}",
            f"üé® –§—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {stats['fragments']}",
            f"üìã –®–∞–±–ª–æ–Ω–æ–≤: {stats['templates']}\n",
            "*–°—Ç—Ä–∞—Ç–µ–≥–∏–∏:*"
        ]
        
        for strategy, count in stats['strategies'].items():
            if count > 0:
                percentage = (count / stats['total_requests'] * 100) if stats['total_requests'] > 0 else 0
                lines.append(f"  ‚Ä¢ {strategy}: {count} ({percentage:.0f}%)")
        
        await update.message.reply_text("\n".join(lines), parse_mode=ParseMode.MARKDOWN)
        return
    
    action = context.args[0].lower()
    
    if action == "stats":
        # –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = neira_cortex.get_stats()
        
        lines = [
            "üìä *–î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ Cortex*\n",
            f"–í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {stats['total_requests']}\n",
            "*Pathways –ø–æ tiers:*"
        ]
        
        for tier, count in stats['pathways']['by_tier'].items():
            lines.append(f"  ‚Ä¢ {tier}: {count}")
        
        lines.append("\n*–ü–æ–∫—Ä—ã—Ç–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤:*")
        for tier, coverage in stats['pathways']['coverage'].items():
            lines.append(f"  ‚Ä¢ {tier}: {coverage}")
        
        await update.message.reply_text("\n".join(lines), parse_mode=ParseMode.MARKDOWN)
    
    elif action == "pathways":
        # –°–ø–∏—Å–æ–∫ pathways
        pathways = neira_cortex.pathways.pathways[:20]  # –ü–µ—Ä–≤—ã–µ 20
        
        if not pathways:
            await update.message.reply_text("üì≠ –ù–µ—Ç pathways")
            return
        
        lines = [f"üß† *Neural Pathways (—Ç–æ–ø-20):*\n"]
        
        for i, pathway in enumerate(pathways, 1):
            tier_emoji = {"hot": "üî•", "warm": "üå°Ô∏è", "cool": "‚ùÑÔ∏è", "cold": "üßä"}.get(pathway.tier.value, "‚ö™")
            trigger_preview = ", ".join(pathway.triggers[:2])
            lines.append(
                f"{i}. {tier_emoji} `{pathway.id}`\n"
                f"   –¢—Ä–∏–≥–≥–µ—Ä—ã: {trigger_preview}...\n"
                f"   –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–π: {pathway.success_count}"
            )
        
        if len(neira_cortex.pathways.pathways) > 20:
            lines.append(f"\n_...–∏ –µ—â—ë {len(neira_cortex.pathways.pathways) - 20}_")
        
        await update.message.reply_text("\n".join(lines), parse_mode=ParseMode.MARKDOWN)
    
    elif action == "test" and len(context.args) > 1:
        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        test_input = " ".join(context.args[1:])
        user_id = str(update.effective_user.id)
        
        result = neira_cortex.process(test_input, user_id)
        
        strategy_emoji = {
            "neural_pathway": "‚ö°",
            "template": "üìã",
            "fragment": "üß©",
            "rag": "üìö",
            "llm_consultant": "ü§ñ",
            "hybrid": "üîÑ"
        }.get(result.strategy.value, "üîÆ")
        
        tier_info = f" [{result.pathway_tier.value}]" if result.pathway_tier else ""
        
        await update.message.reply_text(
            f"üß™ *–¢–µ—Å—Ç:* {test_input}\n\n"
            f"ü§ñ *–û—Ç–≤–µ—Ç:* {result.response}\n\n"
            f"üìä *–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ:*\n"
            f"  ‚Ä¢ –°—Ç—Ä–∞—Ç–µ–≥–∏—è: {strategy_emoji} {result.strategy.value}{tier_info}\n"
            f"  ‚Ä¢ Intent: {result.intent.value}\n"
            f"  ‚Ä¢ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result.confidence:.0%}\n"
            f"  ‚Ä¢ Latency: {result.latency_ms:.0f}ms\n"
            f"  ‚Ä¢ LLM: {'‚úÖ' if result.llm_used else '‚ùå'}",
            parse_mode=ParseMode.MARKDOWN
        )
    
    else:
        await update.message.reply_text(
            "üí° –ò—Å–ø–æ–ª—å–∑—É–π:\n"
            "/cortex ‚Äî —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n"
            "/cortex stats ‚Äî –¥–µ—Ç–∞–ª—å–Ω–æ\n"
            "/cortex pathways ‚Äî —Å–ø–∏—Å–æ–∫ pathways\n"
            "/cortex test <—Ç–µ–∫—Å—Ç> ‚Äî —Ç–µ—Å—Ç"
        )


# === Bootstrap ===
def build_application() -> Application:
    """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç Telegram-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ."""
    if not BOT_TOKEN:
        raise ValueError("BOT_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
    
    app = (
        Application.builder()
        .token(BOT_TOKEN)
        # —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –∫ —Å–µ—Ç–µ–≤—ã–º –ª–∞–≥–∞–º/—Ä–∞–∑—Ä—ã–≤–∞–º
        .connect_timeout(15)
        .read_timeout(30)
        .write_timeout(30)
        .build()
    )

    # –ë–∞–∑–æ–≤—ã–µ –∫–æ–º–∞–Ω–¥—ã (–¥–æ—Å—Ç—É–ø–Ω—ã –≤—Å–µ–º)
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_command))
    app.add_handler(CommandHandler("auth", auth_command))
    
    # –ö–æ–º–∞–Ω–¥—ã —Å –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–µ–π
    app.add_handler(CommandHandler("stats", stats_command))
    app.add_handler(CommandHandler("memory", memory_command))
    app.add_handler(CommandHandler("experience", experience_command))
    app.add_handler(CommandHandler("context", context_command))
    app.add_handler(CommandHandler("clear_context", clear_context_command))
    app.add_handler(CommandHandler("clear", clear_command))
    app.add_handler(CommandHandler("learn", learn_command))
    app.add_handler(CommandHandler("learn_auto", learn_auto_command))
    app.add_handler(CommandHandler("cortex", cortex_command))  # üß† –ù–æ–≤–∞—è –∫–æ–º–∞–Ω–¥–∞
    
    # –°–∞–º–æ—Å–æ–∑–Ω–∞–Ω–∏–µ (v0.6)
    app.add_handler(CommandHandler("self", self_command))
    app.add_handler(CommandHandler("organs", organs_command))
    app.add_handler(CommandHandler("grow", grow_command))
    app.add_handler(CommandHandler("code", code_command))
    
    # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (v0.6)
    app.add_handler(CommandHandler("imagine", imagine_command))
    app.add_handler(CommandHandler("vision", vision_status_command))
    app.add_handler(MessageHandler(filters.PHOTO, photo_handler))
    
    # –ê–¥–º–∏–Ω-–∫–æ–º–∞–Ω–¥—ã
    app.add_handler(CommandHandler("admin", admin_command))
    app.add_handler(CallbackQueryHandler(admin_callback, pattern="^admin_"))
    
    # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–æ–±—â–µ–Ω–∏–π (—Å –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–µ–π)
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, chat_handler))

    # –ì–ª–æ–±–∞–ª—å–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫: –Ω–µ –ø–∞–¥–∞–µ–º –Ω–∞ —Å–µ—Ç–µ–≤—ã—Ö —Ç–∞–π–º–∞—É—Ç–∞—Ö
    async def on_error(update: object, context: ContextTypes.DEFAULT_TYPE) -> None:
        err = context.error
        if isinstance(err, NetworkError):
            logging.warning("Network error, continue polling: %s", err)
            return
        logging.error("Unhandled error: %s", err, exc_info=True)
    app.add_error_handler(on_error)

    return app


def main() -> None:
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞: –∑–∞–ø—É—Å–∫ –±–æ—Ç–∞ –≤ —Ä–µ–∂–∏–º–µ long polling."""
    # PTB v21 –æ–∂–∏–¥–∞–µ—Ç —Ç–µ–∫—É—â–∏–π event loop; —Å–æ–∑–¥–∞—ë–º –∏ –Ω–∞–∑–Ω–∞—á–∞–µ–º –≤—Ä—É—á–Ω—É—é.
    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)

    base_dir = Path(__file__).resolve().parent
    logging.info("–ó–∞–ø—É—Å–∫ Neira Telegram Bot (base_dir=%s)", base_dir)
    
    # üß† –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Neira Cortex v2.0
    global neira_cortex
    if CORTEX_AVAILABLE and CORTEX_MODE != "never":
        try:
            from neira_cortex import create_cortex
            neira_cortex = create_cortex(
                pathways_file="neural_pathways.json",
                use_llm=(CORTEX_MODE != "auto")  # LLM –¥–æ—Å—Ç—É–ø–µ–Ω —Ç–æ–ª—å–∫–æ –≤ always —Ä–µ–∂–∏–º–µ
            )
            logging.info("‚úÖ Neira Cortex v2.0 –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω (—Ä–µ–∂–∏–º: %s)", CORTEX_MODE)
        except Exception as e:
            logging.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å Cortex: %s", e)
            neira_cortex = None

    app = build_application()
    app.run_polling(drop_pending_updates=True)


if __name__ == "__main__":
    main()
